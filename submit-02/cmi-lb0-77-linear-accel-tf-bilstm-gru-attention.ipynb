{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":242954653,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**If you support the notebook, please upvoteâ€”Iâ€™d really appreciate it!**  \n**Also, if you have any questions, feel free to askâ€”Iâ€™ll be happy to answer. ğŸ˜Š**\n### UPDATE: Enhanced IMU Signal Processing with Gravity Removal & Dataset Split Adjustment\n\nThis version builds upon the enhancements from my previous notebook: **[LB 0.76 | IMU+THM/TOF | TF BiLSTM+GRU+Attention](https://www.kaggle.com/code/rktqwe/lb-0-76-imu-thm-tof-tf-bilstm-gru-attention)**. The key changes in *this* update are:\n\n1.  **Gravity Component Removal from Accelerometer Data (Key Improvement):**\n    *   **Purpose:** Raw accelerometer data measures both the device's linear acceleration (actual movement) and the constant pull of gravity. By isolating the linear acceleration, we aim to provide the model with cleaner, more motion-specific signals, potentially improving its ability to distinguish between subtle gestures.\n    *   **Method:**\n        *   We utilize quaternion rotation data (`rot_x`, `rot_y`, `rot_z`, `rot_w`) to determine the device's orientation in 3D space.\n        *   Using `scipy.spatial.transform.Rotation`, we project a standard gravity vector (`[0, 0, 9.81] m/sÂ²`) from the world frame into the sensor's coordinate frame for each timestamp.\n        *   This estimated gravity component in the sensor's frame is then subtracted from the raw `acc_x`, `acc_y`, `acc_z` readings.\n    *   **New Features Derived:**\n        *   `linear_acc_x`, `linear_acc_y`, `linear_acc_z`: Accelerometer readings with gravity removed. These now form the base acceleration features.\n        *   `linear_acc_mag`: Magnitude of the linear acceleration.\n        *   `linear_acc_mag_jerk`: Derivative (jerk) of the linear acceleration magnitude.\n    *   **Impact:** The `imu_cols_base` now uses these `linear_acc_x/y/z` features instead of the raw `acc_x/y/z`. The original `acc_mag` (which includes gravity) is retained as it might still offer complementary information.\n\n2.  **Train/Validation Split Adjustment:**\n    *   The `train_test_split` ratio for creating training and validation sets was changed from `test_size=0.1` (90% train, 10% validation) to `test_size=0.2` (80% train, 20% validation). This provides a larger validation set for more robust evaluation during training.\n  \n\n\n**This solution was developed by building upon the foundational work of two key contributors:**\n\n- **CMI25 | IMU+THM/TOF |TF BiLSTM+GRU+Attention|LB.75** by [yukiZ](https://www.kaggle.com/code/hideyukizushi/cmi25-imu-thm-tof-tf-bilstm-gru-attention-lb-75)\n- **imu-tof** by [Erich von Mainstein](https://www.kaggle.com/code/vonmainstein/imu-tof)\n\n**Special recognition for the exceptional exploratory data analysis:**\n\n- **Sensor PulseğŸ§ | Viz & EDA for BFRB Detection** by [Tarun Mishra](https://www.kaggle.com/code/tarundirector/sensor-pulse-viz-eda-for-bfrb-detection)\n\n### Implemented Enhancements\n\n#### 1. IMU Signal Processing Optimization (Core Improvement)\n\n**Implemented Features:**\n- Derived kinematic metrics:\n  - Acceleration vector magnitude (`acc_mag`)\n  - Scalar rotation angle (`rot_angle`)\n  - Acceleration derivative (`acc_mag_jerk`)\n  - Angular velocity (`rot_angle_vel`)\n- Initial learning rate reduction from `1e-3` to `5e-4`\n- Implemented cosine decay scheduling:\n  - Parameters: `first_decay_steps = 15 Ã— steps_per_epoch`\n\n**Unsuccessful Experiments (Reverted):**\n- Further LR Reduction: `LR_INIT = 2-e4` worsened score.\n- Dropout Rate Adjustments: No improvement over baseline dropout.\n- TOF/THEM Branch Architecture Change: Replacing simpler CNNs with `residual_se_cnn_blocks` was detrimental.","metadata":{}},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Importing the necessary Libraries**","metadata":{}},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate, GRU, GaussianNoise\n)\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport polars as pl\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom scipy.spatial.transform import Rotation as R\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:18.615907Z","iopub.execute_input":"2025-06-18T21:09:18.616167Z","iopub.status.idle":"2025-06-18T21:09:42.565487Z","shell.execute_reply.started":"2025-06-18T21:09:18.616145Z","shell.execute_reply":"2025-06-18T21:09:42.564501Z"}},"outputs":[{"name":"stderr","text":"2025-06-18 21:09:24.837341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750280965.158515      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750280965.245642      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Fix Seed**","metadata":{}},{"cell_type":"code","source":"import random\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nseed_everything(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:42.566439Z","iopub.execute_input":"2025-06-18T21:09:42.567107Z","iopub.status.idle":"2025-06-18T21:09:42.573875Z","shell.execute_reply.started":"2025-06-18T21:09:42.567060Z","shell.execute_reply":"2025-06-18T21:09:42.572766Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Configuration**","metadata":{}},{"cell_type":"code","source":"# (Competition metric will only be imported when TRAINing)\nTRAIN = True                     # â† set to True when you want to train\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\nPRETRAINED_DIR = Path(\"/kaggle/input/pretrained-model\")  # used when TRAIN=False\nEXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\nBATCH_SIZE = 64\nPAD_PERCENTILE = 95\nLR_INIT = 5e-4\nWD = 3e-3\nMIXUP_ALPHA = 0.4\nEPOCHS = 160\nPATIENCE = 40\n\n\nprint(\"â–¶ imports ready Â· tensorflow\", tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:42.575893Z","iopub.execute_input":"2025-06-18T21:09:42.577206Z","iopub.status.idle":"2025-06-18T21:09:42.630664Z","shell.execute_reply.started":"2025-06-18T21:09:42.577156Z","shell.execute_reply":"2025-06-18T21:09:42.629753Z"}},"outputs":[{"name":"stdout","text":"â–¶ imports ready Â· tensorflow 2.18.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Utility Functions**","metadata":{}},{"cell_type":"code","source":"#Tensor Manipulations\ndef time_sum(x):\n    return K.sum(x, axis=1)\n\ndef squeeze_last_axis(x):\n    return tf.squeeze(x, axis=-1)\n\ndef expand_last_axis(x):\n    return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\n# Residual CNN Block with SE\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    shortcut = x\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n                   kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    x = se_block(x)\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n                          kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:42.631825Z","iopub.execute_input":"2025-06-18T21:09:42.632205Z","iopub.status.idle":"2025-06-18T21:09:42.658931Z","shell.execute_reply.started":"2025-06-18T21:09:42.632170Z","shell.execute_reply":"2025-06-18T21:09:42.657862Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Data Helpers**","metadata":{}},{"cell_type":"code","source":"# Normalizes and cleans the time series sequence. \n\ndef preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n    return scaler.transform(mat).astype('float32')\n\n# MixUp the data argumentation in order to regularize the neural network. \n\nclass MixupGenerator(Sequence):\n    def __init__(self, X, y, batch_size, alpha=0.2):\n        self.X, self.y = X, y\n        self.batch = batch_size\n        self.alpha = alpha\n        self.indices = np.arange(len(X))\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx], self.y[idx]\n        lam = np.random.beta(self.alpha, self.alpha)\n        perm = np.random.permutation(len(Xb))\n        X_mix = lam * Xb + (1-lam) * Xb[perm]\n        y_mix = lam * yb + (1-lam) * yb[perm]\n        return X_mix, y_mix\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:42.660059Z","iopub.execute_input":"2025-06-18T21:09:42.660489Z","iopub.status.idle":"2025-06-18T21:09:42.685656Z","shell.execute_reply.started":"2025-06-18T21:09:42.660459Z","shell.execute_reply":"2025-06-18T21:09:42.684496Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def remove_gravity_from_acc(acc_data, rot_data):\n\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    else:\n        acc_values = acc_data\n\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    \n    gravity_world = np.array([0, 0, 9.81])\n\n    for i in range(num_samples):\n        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n            linear_accel[i, :] = acc_values[i, :] \n            continue\n\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except ValueError:\n             linear_accel[i, :] = acc_values[i, :]\n             \n    return linear_accel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:42.686714Z","iopub.execute_input":"2025-06-18T21:09:42.686964Z","iopub.status.idle":"2025-06-18T21:09:42.715510Z","shell.execute_reply.started":"2025-06-18T21:09:42.686946Z","shell.execute_reply":"2025-06-18T21:09:42.714496Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Model Definition - Two Branch Architecture**","metadata":{}},{"cell_type":"code","source":"def build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMU deep branch\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n\n    # TOF/Thermal lighter branch\n    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n\n    merged = Concatenate()([x1, x2])\n\n    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xc = GaussianNoise(0.09)(merged)\n    xc = Dense(16, activation='elu')(xc)\n    \n    x = Concatenate()([xa, xb, xc])\n    x = Dropout(0.4)(x)\n    x = attention_layer(x)\n\n    for units, drop in [(256, 0.5), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x); x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n    return Model(inp, out)\n\ntmp_model = build_two_branch_model(127,7,325,18)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:42.716786Z","iopub.execute_input":"2025-06-18T21:09:42.717132Z","iopub.status.idle":"2025-06-18T21:09:43.557565Z","shell.execute_reply.started":"2025-06-18T21:09:42.717070Z","shell.execute_reply":"2025-06-18T21:09:43.556615Z"}},"outputs":[{"name":"stderr","text":"2025-06-18 21:09:42.789065: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Training / Inference Pipeline**","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    print(\"â–¶ TRAIN MODE â€“ loading dataset â€¦\")\n    df = pd.read_csv(RAW_DIR / \"train.csv\")\n\n    train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n    df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n\n    le = LabelEncoder()\n    df['gesture_int'] = le.fit_transform(df['gesture'])\n    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n    gesture_classes = le.classes_\n\n    print(\"  Calculating base engineered IMU features (magnitude, angle)...\")\n    df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n    df['rot_angle'] = 2 * np.arccos(df['rot_w'].clip(-1, 1))\n    \n    print(\"  Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag...\")\n    df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n    df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n\n    print(\"  Removing gravity and calculating linear acceleration features...\")\n    \n    linear_accel_list = []\n    for _, group in df.groupby('sequence_id'):\n        acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n        rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n        linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n        linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n    \n    df_linear_accel = pd.concat(linear_accel_list)\n    df = pd.concat([df, df_linear_accel], axis=1)\n\n    df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n    df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n\n    meta_cols = { ... }\n\n    imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n    imu_cols_base.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n    \n    imu_engineered_features = [\n        'acc_mag', 'rot_angle',\n        'acc_mag_jerk', 'rot_angle_vel',\n        'linear_acc_mag', 'linear_acc_mag_jerk'\n    ]\n    imu_cols = imu_cols_base + imu_engineered_features\n    imu_cols = list(dict.fromkeys(imu_cols))\n\n    thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n    \n    tof_aggregated_cols_template = []\n    for i in range(1, 6):\n        tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n\n    final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n    imu_dim_final = len(imu_cols)\n    tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n    \n    print(f\"  IMU (incl. engineered & derivatives) {imu_dim_final} | THM + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n\n    print(\"  Building sequences with aggregated TOF and preparing data for scaler...\")\n    seq_gp = df.groupby('sequence_id') \n    \n    all_steps_for_scaler_list = []\n    X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n\n    for seq_id, seq_df_orig in seq_gp:\n        seq_df = seq_df_orig.copy()\n\n        for i in range(1, 6):\n            pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n            tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n            seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n            seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n            seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n            seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n        \n        mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n        \n        all_steps_for_scaler_list.append(mat_unscaled)\n        X_list_unscaled.append(mat_unscaled)\n        y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n        lens.append(len(mat_unscaled))\n\n    print(\"  Fitting StandardScaler...\")\n    all_steps_concatenated = np.concatenate(all_steps_for_scaler_list, axis=0)\n    scaler = StandardScaler().fit(all_steps_concatenated)\n    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n    del all_steps_for_scaler_list, all_steps_concatenated\n\n    print(\"  Scaling and padding sequences...\")\n    X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n    del X_list_unscaled\n\n    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n    np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n    \n    X = pad_sequences(X_scaled_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    del X_scaled_list\n    \n    y_int_for_stratify = np.array(y_list_int_for_stratify)\n    y = to_categorical(y_int_for_stratify, num_classes=len(le.classes_))\n\n    print(\"  Splitting data and preparing for training...\")\n    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=82, stratify=y_int_for_stratify)\n\n    cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_int_for_stratify)\n    class_weight = dict(enumerate(cw_vals))\n\n    model = build_two_branch_model(pad_len, imu_dim_final, tof_thm_aggregated_dim_final, len(le.classes_), wd=WD)\n    \n    steps = len(X_tr) // BATCH_SIZE\n    lr_sched = tf.keras.optimizers.schedules.CosineDecayRestarts(5e-4, first_decay_steps=15 * steps) \n    \n    model.compile(optimizer=Adam(lr_sched),\n                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n                  metrics=['accuracy'])\n\n    train_gen = MixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, alpha=MIXUP_ALPHA)\n    cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_accuracy', mode='max')\n    \n    print(\"  Starting model training...\")\n    model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val),\n              class_weight=class_weight, callbacks=[cb], verbose=1)\n\n    model.save(EXPORT_DIR / \"gesture_two_branch_mixup.h5\")\n    print(\"âœ” Training done â€“ artefacts saved in\", EXPORT_DIR)\n\n    from cmi_2025_metric_copy_for_import import CompetitionMetric\n    preds_val = model.predict(X_val).argmax(1)\n    true_val_int  = y_val.argmax(1)\n    \n    h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n        pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n        pd.DataFrame({'gesture': le.classes_[preds_val]}))\n    print(\"Holdâ€‘out Hâ€‘F1 =\", round(h_f1, 4))\n\nelse:\n    print(\"â–¶ INFERENCE MODE â€“ loading artefacts from\", PRETRAINED_DIR)\n    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n    pad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n    scaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n\n    temp_imu_cols = [c for c in final_feature_cols if c.startswith('acc_') or c.startswith('rot_')]\n    imu_dim_final = len(temp_imu_cols)\n    tof_thm_aggregated_dim_final = len(final_feature_cols) - imu_dim_final\n\n    custom_objs = {\n        'time_sum': time_sum,\n        'squeeze_last_axis': squeeze_last_axis,\n        'expand_last_axis': expand_last_axis,\n        'se_block': se_block,\n        'residual_se_cnn_block': residual_se_cnn_block,\n        'attention_layer': attention_layer,\n    }\n    model = load_model(PRETRAINED_DIR / \"gesture_two_branch_mixup.h5\",\n                       compile=False, custom_objects=custom_objs)\n    print(\"  Model, scaler, feature_cols, pad_len loaded â€“ ready for evaluation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T21:09:43.558755Z","iopub.execute_input":"2025-06-18T21:09:43.559107Z","iopub.status.idle":"2025-06-18T22:33:32.273211Z","shell.execute_reply.started":"2025-06-18T21:09:43.559076Z","shell.execute_reply":"2025-06-18T22:33:32.271548Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"â–¶ TRAIN MODE â€“ loading dataset â€¦\n  Calculating base engineered IMU features (magnitude, angle)...\n  Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag...\n  Removing gravity and calculating linear acceleration features...\n  IMU (incl. engineered & derivatives) 13 | THM + Aggregated TOF 25 | total 38 features\n  Building sequences with aggregated TOF and preparing data for scaler...\n  Fitting StandardScaler...\n  Scaling and padding sequences...\n  Splitting data and preparing for training...\n  Starting model training...\nEpoch 1/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.1112 - loss: 9.7435","output_type":"stream"},{"name":"stderr","text":"2025-06-18 21:15:12.288051: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 352ms/step - accuracy: 0.1116 - loss: 9.7372 - val_accuracy: 0.3090 - val_loss: 7.9338\nEpoch 2/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.2638 - loss: 7.5092 - val_accuracy: 0.4157 - val_loss: 6.3034\nEpoch 3/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.3319 - loss: 6.2980 - val_accuracy: 0.4647 - val_loss: 5.2979\nEpoch 4/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 327ms/step - accuracy: 0.3926 - loss: 5.4353 - val_accuracy: 0.5230 - val_loss: 4.6156\nEpoch 5/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 332ms/step - accuracy: 0.4353 - loss: 4.8186 - val_accuracy: 0.5144 - val_loss: 4.1745\nEpoch 6/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 325ms/step - accuracy: 0.4661 - loss: 4.4143 - val_accuracy: 0.5543 - val_loss: 3.8170\nEpoch 7/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.4628 - loss: 4.1537 - val_accuracy: 0.5543 - val_loss: 3.5901\nEpoch 8/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 325ms/step - accuracy: 0.4829 - loss: 3.9232 - val_accuracy: 0.5825 - val_loss: 3.4057\nEpoch 9/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 350ms/step - accuracy: 0.5060 - loss: 3.6999 - val_accuracy: 0.5874 - val_loss: 3.2948\nEpoch 10/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 333ms/step - accuracy: 0.5328 - loss: 3.5871 - val_accuracy: 0.6205 - val_loss: 3.1455\nEpoch 11/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.5437 - loss: 3.5135 - val_accuracy: 0.6235 - val_loss: 3.0701\nEpoch 12/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.5464 - loss: 3.4282 - val_accuracy: 0.6315 - val_loss: 3.0264\nEpoch 13/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 328ms/step - accuracy: 0.5721 - loss: 3.3271 - val_accuracy: 0.6401 - val_loss: 2.9961\nEpoch 14/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.5545 - loss: 3.3392 - val_accuracy: 0.6364 - val_loss: 2.9832\nEpoch 15/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.5662 - loss: 3.2787 - val_accuracy: 0.5635 - val_loss: 3.0903\nEpoch 16/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.4904 - loss: 3.3994 - val_accuracy: 0.5353 - val_loss: 2.9662\nEpoch 17/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.5456 - loss: 3.1272 - val_accuracy: 0.5782 - val_loss: 2.7304\nEpoch 18/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.5280 - loss: 3.0049 - val_accuracy: 0.5929 - val_loss: 2.5551\nEpoch 19/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.5623 - loss: 2.8325 - val_accuracy: 0.6045 - val_loss: 2.4524\nEpoch 20/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.5632 - loss: 2.6734 - val_accuracy: 0.5960 - val_loss: 2.3837\nEpoch 21/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 326ms/step - accuracy: 0.5628 - loss: 2.6656 - val_accuracy: 0.6248 - val_loss: 2.2464\nEpoch 22/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.5835 - loss: 2.4705 - val_accuracy: 0.6211 - val_loss: 2.1693\nEpoch 23/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.6232 - loss: 2.3296 - val_accuracy: 0.5984 - val_loss: 2.1466\nEpoch 24/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 324ms/step - accuracy: 0.6110 - loss: 2.3490 - val_accuracy: 0.6383 - val_loss: 2.0054\nEpoch 25/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.6176 - loss: 2.2770 - val_accuracy: 0.5960 - val_loss: 2.0342\nEpoch 26/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.6197 - loss: 2.1750 - val_accuracy: 0.6432 - val_loss: 1.9218\nEpoch 27/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 331ms/step - accuracy: 0.6033 - loss: 2.2760 - val_accuracy: 0.6401 - val_loss: 1.9483\nEpoch 28/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 326ms/step - accuracy: 0.6472 - loss: 2.1362 - val_accuracy: 0.6726 - val_loss: 1.8573\nEpoch 29/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.6608 - loss: 2.0388 - val_accuracy: 0.6652 - val_loss: 1.8168\nEpoch 30/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 329ms/step - accuracy: 0.6393 - loss: 2.0623 - val_accuracy: 0.6695 - val_loss: 1.7441\nEpoch 31/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 328ms/step - accuracy: 0.6652 - loss: 2.0401 - val_accuracy: 0.6787 - val_loss: 1.7614\nEpoch 32/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.6621 - loss: 2.0500 - val_accuracy: 0.6910 - val_loss: 1.7349\nEpoch 33/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.6641 - loss: 2.0442 - val_accuracy: 0.6775 - val_loss: 1.7001\nEpoch 34/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 328ms/step - accuracy: 0.6908 - loss: 1.9302 - val_accuracy: 0.6922 - val_loss: 1.6832\nEpoch 35/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 329ms/step - accuracy: 0.6901 - loss: 1.9265 - val_accuracy: 0.6934 - val_loss: 1.6294\nEpoch 36/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7270 - loss: 1.8315 - val_accuracy: 0.7112 - val_loss: 1.6183\nEpoch 37/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 353ms/step - accuracy: 0.7303 - loss: 1.7628 - val_accuracy: 0.7094 - val_loss: 1.6061\nEpoch 38/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 330ms/step - accuracy: 0.7183 - loss: 1.8211 - val_accuracy: 0.7198 - val_loss: 1.5895\nEpoch 39/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 332ms/step - accuracy: 0.7504 - loss: 1.7330 - val_accuracy: 0.7204 - val_loss: 1.5750\nEpoch 40/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 357ms/step - accuracy: 0.7357 - loss: 1.7447 - val_accuracy: 0.7198 - val_loss: 1.5659\nEpoch 41/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 331ms/step - accuracy: 0.7436 - loss: 1.7245 - val_accuracy: 0.7247 - val_loss: 1.5599\nEpoch 42/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.7547 - loss: 1.7727 - val_accuracy: 0.7296 - val_loss: 1.5532\nEpoch 43/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.7302 - loss: 1.8571 - val_accuracy: 0.7290 - val_loss: 1.5539\nEpoch 44/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 326ms/step - accuracy: 0.7207 - loss: 1.8432 - val_accuracy: 0.7296 - val_loss: 1.5522\nEpoch 45/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.7291 - loss: 1.8368 - val_accuracy: 0.4384 - val_loss: 2.2767\nEpoch 46/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.6077 - loss: 2.0871 - val_accuracy: 0.5898 - val_loss: 1.8961\nEpoch 47/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.6078 - loss: 2.1340 - val_accuracy: 0.6352 - val_loss: 1.7777\nEpoch 48/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.6558 - loss: 2.0079 - val_accuracy: 0.6162 - val_loss: 1.8014\nEpoch 49/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.6370 - loss: 2.0360 - val_accuracy: 0.6045 - val_loss: 1.8378\nEpoch 50/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.6524 - loss: 1.9428 - val_accuracy: 0.6481 - val_loss: 1.7648\nEpoch 51/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 336ms/step - accuracy: 0.6611 - loss: 1.9046 - val_accuracy: 0.6088 - val_loss: 1.8050\nEpoch 52/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 357ms/step - accuracy: 0.6815 - loss: 1.9066 - val_accuracy: 0.6284 - val_loss: 1.7914\nEpoch 53/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 332ms/step - accuracy: 0.6799 - loss: 1.9672 - val_accuracy: 0.6284 - val_loss: 1.7499\nEpoch 54/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 329ms/step - accuracy: 0.6665 - loss: 1.9026 - val_accuracy: 0.6493 - val_loss: 1.6754\nEpoch 55/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 327ms/step - accuracy: 0.6831 - loss: 1.8450 - val_accuracy: 0.6677 - val_loss: 1.6279\nEpoch 56/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7040 - loss: 1.8842 - val_accuracy: 0.6554 - val_loss: 1.6866\nEpoch 57/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 354ms/step - accuracy: 0.6878 - loss: 1.8718 - val_accuracy: 0.6475 - val_loss: 1.6923\nEpoch 58/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 332ms/step - accuracy: 0.6570 - loss: 1.9558 - val_accuracy: 0.6726 - val_loss: 1.6342\nEpoch 59/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 355ms/step - accuracy: 0.6913 - loss: 1.8660 - val_accuracy: 0.6689 - val_loss: 1.6365\nEpoch 60/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 334ms/step - accuracy: 0.6955 - loss: 1.8655 - val_accuracy: 0.6321 - val_loss: 1.7623\nEpoch 61/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 329ms/step - accuracy: 0.6733 - loss: 1.8755 - val_accuracy: 0.6763 - val_loss: 1.6123\nEpoch 62/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.6909 - loss: 1.8411 - val_accuracy: 0.6842 - val_loss: 1.5962\nEpoch 63/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 331ms/step - accuracy: 0.7185 - loss: 1.8047 - val_accuracy: 0.7039 - val_loss: 1.5588\nEpoch 64/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 330ms/step - accuracy: 0.7109 - loss: 1.8066 - val_accuracy: 0.6781 - val_loss: 1.5858\nEpoch 65/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7207 - loss: 1.8012 - val_accuracy: 0.6677 - val_loss: 1.6095\nEpoch 66/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.7202 - loss: 1.7640 - val_accuracy: 0.7026 - val_loss: 1.5607\nEpoch 67/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 350ms/step - accuracy: 0.7296 - loss: 1.7549 - val_accuracy: 0.6861 - val_loss: 1.5926\nEpoch 68/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7355 - loss: 1.7386 - val_accuracy: 0.7008 - val_loss: 1.5356\nEpoch 69/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.7310 - loss: 1.7742 - val_accuracy: 0.6242 - val_loss: 1.6866\nEpoch 70/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.7350 - loss: 1.7004 - val_accuracy: 0.7057 - val_loss: 1.5178\nEpoch 71/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7400 - loss: 1.7007 - val_accuracy: 0.6714 - val_loss: 1.5681\nEpoch 72/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.7136 - loss: 1.8021 - val_accuracy: 0.7131 - val_loss: 1.5048\nEpoch 73/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7431 - loss: 1.7103 - val_accuracy: 0.7118 - val_loss: 1.4947\nEpoch 74/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7124 - loss: 1.7836 - val_accuracy: 0.7155 - val_loss: 1.4780\nEpoch 75/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.7598 - loss: 1.6588 - val_accuracy: 0.7216 - val_loss: 1.4568\nEpoch 76/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - accuracy: 0.7701 - loss: 1.5819 - val_accuracy: 0.7069 - val_loss: 1.4763\nEpoch 77/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7672 - loss: 1.6863 - val_accuracy: 0.6941 - val_loss: 1.4960\nEpoch 78/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7580 - loss: 1.6603 - val_accuracy: 0.7278 - val_loss: 1.4437\nEpoch 79/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 330ms/step - accuracy: 0.7446 - loss: 1.6486 - val_accuracy: 0.7278 - val_loss: 1.4636\nEpoch 80/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.7770 - loss: 1.6106 - val_accuracy: 0.7321 - val_loss: 1.4484\nEpoch 81/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 326ms/step - accuracy: 0.7842 - loss: 1.6114 - val_accuracy: 0.7296 - val_loss: 1.4372\nEpoch 82/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7967 - loss: 1.5767 - val_accuracy: 0.7321 - val_loss: 1.4283\nEpoch 83/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.8056 - loss: 1.5391 - val_accuracy: 0.7259 - val_loss: 1.4393\nEpoch 84/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7940 - loss: 1.5956 - val_accuracy: 0.7149 - val_loss: 1.5054\nEpoch 85/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.8060 - loss: 1.5570 - val_accuracy: 0.7284 - val_loss: 1.4110\nEpoch 86/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.8163 - loss: 1.4958 - val_accuracy: 0.7253 - val_loss: 1.4403\nEpoch 87/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7885 - loss: 1.5653 - val_accuracy: 0.7345 - val_loss: 1.4108\nEpoch 88/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.8145 - loss: 1.5605 - val_accuracy: 0.7364 - val_loss: 1.3831\nEpoch 89/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7960 - loss: 1.5536 - val_accuracy: 0.7388 - val_loss: 1.3882\nEpoch 90/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - accuracy: 0.7954 - loss: 1.5957 - val_accuracy: 0.7351 - val_loss: 1.4198\nEpoch 91/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.8374 - loss: 1.4519 - val_accuracy: 0.7462 - val_loss: 1.3745\nEpoch 92/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.8459 - loss: 1.4735 - val_accuracy: 0.7523 - val_loss: 1.3632\nEpoch 93/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.8578 - loss: 1.4998 - val_accuracy: 0.7505 - val_loss: 1.3651\nEpoch 94/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 324ms/step - accuracy: 0.8048 - loss: 1.5522 - val_accuracy: 0.7492 - val_loss: 1.3699\nEpoch 95/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 321ms/step - accuracy: 0.7889 - loss: 1.5817 - val_accuracy: 0.7560 - val_loss: 1.3616\nEpoch 96/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.8446 - loss: 1.4647 - val_accuracy: 0.7584 - val_loss: 1.3490\nEpoch 97/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 320ms/step - accuracy: 0.8149 - loss: 1.5496 - val_accuracy: 0.7529 - val_loss: 1.3500\nEpoch 98/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.8242 - loss: 1.5008 - val_accuracy: 0.7523 - val_loss: 1.3555\nEpoch 99/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.8232 - loss: 1.5207 - val_accuracy: 0.7529 - val_loss: 1.3466\nEpoch 100/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.8508 - loss: 1.4957 - val_accuracy: 0.7511 - val_loss: 1.3450\nEpoch 101/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 322ms/step - accuracy: 0.8377 - loss: 1.4216 - val_accuracy: 0.7517 - val_loss: 1.3443\nEpoch 102/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.8663 - loss: 1.4619 - val_accuracy: 0.7529 - val_loss: 1.3457\nEpoch 103/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.8109 - loss: 1.6124 - val_accuracy: 0.7523 - val_loss: 1.3470\nEpoch 104/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 330ms/step - accuracy: 0.8413 - loss: 1.4707 - val_accuracy: 0.7204 - val_loss: 1.4471\nEpoch 105/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7519 - loss: 1.6206 - val_accuracy: 0.5935 - val_loss: 1.9431\nEpoch 106/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.6931 - loss: 1.8787 - val_accuracy: 0.6266 - val_loss: 1.7342\nEpoch 107/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.6709 - loss: 1.9261 - val_accuracy: 0.6554 - val_loss: 1.6423\nEpoch 108/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.6582 - loss: 1.8980 - val_accuracy: 0.6481 - val_loss: 1.7181\nEpoch 109/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.7096 - loss: 1.8054 - val_accuracy: 0.6732 - val_loss: 1.6837\nEpoch 110/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7073 - loss: 1.7471 - val_accuracy: 0.6867 - val_loss: 1.6262\nEpoch 111/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 345ms/step - accuracy: 0.7043 - loss: 1.8404 - val_accuracy: 0.6652 - val_loss: 1.6568\nEpoch 112/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 350ms/step - accuracy: 0.7437 - loss: 1.6632 - val_accuracy: 0.6738 - val_loss: 1.6692\nEpoch 113/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 335ms/step - accuracy: 0.7381 - loss: 1.6967 - val_accuracy: 0.6781 - val_loss: 1.6442\nEpoch 114/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 368ms/step - accuracy: 0.7326 - loss: 1.7381 - val_accuracy: 0.6701 - val_loss: 1.6095\nEpoch 115/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 334ms/step - accuracy: 0.7475 - loss: 1.6736 - val_accuracy: 0.6891 - val_loss: 1.5911\nEpoch 116/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 333ms/step - accuracy: 0.7306 - loss: 1.7544 - val_accuracy: 0.6996 - val_loss: 1.6085\nEpoch 117/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 331ms/step - accuracy: 0.7342 - loss: 1.7143 - val_accuracy: 0.6652 - val_loss: 1.6539\nEpoch 118/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 334ms/step - accuracy: 0.7304 - loss: 1.7597 - val_accuracy: 0.6928 - val_loss: 1.5612\nEpoch 119/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 326ms/step - accuracy: 0.7572 - loss: 1.6420 - val_accuracy: 0.6941 - val_loss: 1.5985\nEpoch 120/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7400 - loss: 1.7147 - val_accuracy: 0.7026 - val_loss: 1.5766\nEpoch 121/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 326ms/step - accuracy: 0.7521 - loss: 1.7107 - val_accuracy: 0.6793 - val_loss: 1.6036\nEpoch 122/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 325ms/step - accuracy: 0.7142 - loss: 1.7628 - val_accuracy: 0.6573 - val_loss: 1.6684\nEpoch 123/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7244 - loss: 1.7512 - val_accuracy: 0.6965 - val_loss: 1.5699\nEpoch 124/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 321ms/step - accuracy: 0.7268 - loss: 1.7128 - val_accuracy: 0.6965 - val_loss: 1.5831\nEpoch 125/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 321ms/step - accuracy: 0.7803 - loss: 1.6166 - val_accuracy: 0.6793 - val_loss: 1.6217\nEpoch 126/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7847 - loss: 1.5169 - val_accuracy: 0.6885 - val_loss: 1.6008\nEpoch 127/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7857 - loss: 1.5669 - val_accuracy: 0.7069 - val_loss: 1.5575\nEpoch 128/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 324ms/step - accuracy: 0.7422 - loss: 1.7445 - val_accuracy: 0.7051 - val_loss: 1.5411\nEpoch 129/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 322ms/step - accuracy: 0.7773 - loss: 1.6457 - val_accuracy: 0.7094 - val_loss: 1.5495\nEpoch 130/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 323ms/step - accuracy: 0.7779 - loss: 1.5802 - val_accuracy: 0.6855 - val_loss: 1.6195\nEpoch 131/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 330ms/step - accuracy: 0.7628 - loss: 1.6954 - val_accuracy: 0.6781 - val_loss: 1.5830\nEpoch 132/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7486 - loss: 1.6849 - val_accuracy: 0.6959 - val_loss: 1.5722\nEpoch 133/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - accuracy: 0.7812 - loss: 1.6176 - val_accuracy: 0.6830 - val_loss: 1.5906\nEpoch 134/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.7467 - loss: 1.6788 - val_accuracy: 0.7259 - val_loss: 1.4970\nEpoch 135/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 331ms/step - accuracy: 0.7800 - loss: 1.5926 - val_accuracy: 0.6738 - val_loss: 1.5893\nEpoch 136/160\n\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 336ms/step - accuracy: 0.7584 - loss: 1.7253 - val_accuracy: 0.6971 - val_loss: 1.5495\nEpoch 136: early stopping\nRestoring model weights from the end of the best epoch: 96.\nâœ” Training done â€“ artefacts saved in .\n","output_type":"stream"},{"name":"stderr","text":"2025-06-18 22:33:26.016202: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step\nHoldâ€‘out Hâ€‘F1 = 0.8514\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Predict**","metadata":{}},{"cell_type":"code","source":"def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    df_seq = sequence.to_pandas()\n\n    df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2)\n    df_seq['rot_angle'] = 2 * np.arccos(df_seq['rot_w'].clip(-1, 1))\n    df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0)\n    df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0)\n\n    acc_cols_for_gravity_removal = ['acc_x', 'acc_y', 'acc_z']\n    rot_cols_for_gravity_removal = ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n\n    if not all(col in df_seq.columns for col in acc_cols_for_gravity_removal + rot_cols_for_gravity_removal):\n        print(f\"Warning: Missing raw acc/rot columns for gravity removal in predict for sequence. Using raw acc as linear.\")\n        df_seq['linear_acc_x'] = df_seq.get('acc_x', 0)\n        df_seq['linear_acc_y'] = df_seq.get('acc_y', 0)\n        df_seq['linear_acc_z'] = df_seq.get('acc_z', 0)\n    else:\n        acc_data_seq = df_seq[acc_cols_for_gravity_removal]\n        rot_data_seq = df_seq[rot_cols_for_gravity_removal]\n        linear_accel_seq_arr = remove_gravity_from_acc(acc_data_seq, rot_data_seq)\n        \n        df_seq['linear_acc_x'] = linear_accel_seq_arr[:, 0]\n        df_seq['linear_acc_y'] = linear_accel_seq_arr[:, 1]\n        df_seq['linear_acc_z'] = linear_accel_seq_arr[:, 2]\n    \n    df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n    df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n    \n    for i in range(1, 6): \n        pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n        if not all(col in df_seq.columns for col in pixel_cols_tof):\n            print(f\"Warning: Missing some TOF pixel columns for tof_{i} in predict. Filling aggregates with 0.\")\n            df_seq[f'tof_{i}_mean'] = 0\n            df_seq[f'tof_{i}_std']  = 0\n            df_seq[f'tof_{i}_min']  = 0\n            df_seq[f'tof_{i}_max']  = 0\n            continue\n\n        tof_sensor_data = df_seq[pixel_cols_tof].replace(-1, np.nan)\n        df_seq[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n        df_seq[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n        df_seq[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n        df_seq[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n        \n    if 'tof_range_across_sensors' in final_feature_cols:\n        tof_mean_cols_for_contrast = [f'tof_{i}_mean' for i in range(1, 6) if f'tof_{i}_mean' in df_seq.columns]\n        thm_cols_for_contrast = [f'thm_{i}' for i in range(1, 6) if f'thm_{i}' in df_seq.columns]\n\n        if tof_mean_cols_for_contrast:\n            tof_values_for_contrast = df_seq[tof_mean_cols_for_contrast]\n            df_seq['tof_range_across_sensors'] = tof_values_for_contrast.max(axis=1) - tof_values_for_contrast.min(axis=1)\n            df_seq['tof_std_across_sensors'] = tof_values_for_contrast.std(axis=1)\n        else:\n            df_seq['tof_range_across_sensors'] = 0\n            df_seq['tof_std_across_sensors'] = 0\n\n        if thm_cols_for_contrast:\n            thm_values_for_contrast = df_seq[thm_cols_for_contrast]\n            df_seq['thm_range_across_sensors'] = thm_values_for_contrast.max(axis=1) - thm_values_for_contrast.min(axis=1)\n            df_seq['thm_std_across_sensors'] = thm_values_for_contrast.std(axis=1)\n        else:\n            df_seq['thm_range_across_sensors'] = 0\n            df_seq['thm_std_across_sensors'] = 0\n        \n    df_seq_final_features = pd.DataFrame(index=df_seq.index)\n    for col_name in final_feature_cols:\n        if col_name in df_seq.columns:\n            df_seq_final_features[col_name] = df_seq[col_name]\n        else:\n            print(f\"CRITICAL ERROR IN PREDICT: Feature '{col_name}' expected by model (from final_feature_cols) was NOT generated in df_seq. Filling with 0. THIS IS LIKELY A BUG.\")\n            df_seq_final_features[col_name] = 0 \n            \n    mat_unscaled = df_seq_final_features.ffill().bfill().fillna(0).values.astype('float32')\n    \n    mat_scaled = scaler.transform(mat_unscaled)\n    \n    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    \n    idx = int(model.predict(pad_input, verbose=0).argmax(1)[0])\n    return str(gesture_classes[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:33:32.280006Z","iopub.execute_input":"2025-06-18T22:33:32.280468Z","iopub.status.idle":"2025-06-18T22:33:32.308972Z","shell.execute_reply.started":"2025-06-18T22:33:32.280422Z","shell.execute_reply":"2025-06-18T22:33:32.307652Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### ã€‹ã€‹ã€‹**Submit Inference server**","metadata":{}},{"cell_type":"code","source":"import kaggle_evaluation.cmi_inference_server\ninference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        data_paths=(\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T22:33:32.309978Z","iopub.execute_input":"2025-06-18T22:33:32.310269Z","iopub.status.idle":"2025-06-18T22:33:34.575354Z","shell.execute_reply.started":"2025-06-18T22:33:32.310248Z","shell.execute_reply":"2025-06-18T22:33:34.574150Z"}},"outputs":[{"name":"stderr","text":"2025-06-18 22:33:33.875596: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Submission Details\nNotebook Inference Server Never Started\nYour submission notebook may not have started the inference server that is called to obtain predictions. This could mean you forgot to start it, or the notebook crashed. See more debugging tips\n\nCMI_LB0.77_Linear_Accel_TF_BiLSTM+GRU+Attention - Version 1\n\nNotebook Inference Server Never Started Â· 20m ago","metadata":{}}]}