{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":12139340,"sourceType":"datasetVersion","datasetId":7645099},{"sourceId":12293285,"sourceType":"datasetVersion","datasetId":7748073},{"sourceId":12328761,"sourceType":"datasetVersion","datasetId":7771623},{"sourceId":12411879,"sourceType":"datasetVersion","datasetId":7827797},{"sourceId":12573306,"sourceType":"datasetVersion","datasetId":7932089},{"sourceId":240649816,"sourceType":"kernelVersion"},{"sourceId":242954653,"sourceType":"kernelVersion"},{"sourceId":246893721,"sourceType":"kernelVersion"},{"sourceId":251413288,"sourceType":"kernelVersion"},{"sourceId":470587,"sourceType":"modelInstanceVersion","modelInstanceId":379625,"modelId":398856},{"sourceId":471764,"sourceType":"modelInstanceVersion","modelInstanceId":380358,"modelId":400086}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":247.48334,"end_time":"2025-07-25T09:36:55.435213","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-25T09:32:47.951873","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"oeiginal Notebook:\n\nhttps://www.kaggle.com/code/nina2025/h-blend","metadata":{}},{"cell_type":"markdown","source":"#### [CMI - Detect Behavior with Sensor Data](https://www.kaggle.com/competitions/cmi-detect-behavior-with-sensor-data/code?competitionId=102335&sortBy=scoreDescending&excludeNonAccessedDatasources=true)\n\n\n| &nbsp; | &nbsp; | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n| - | - | :-: | :- | :-: | :-: | -: |\n|[Model 1](#Model_1)|0.820|&nbsp;v.6&nbsp;| [CMI25 IMU+THM/TOF TF BlendingModel](https://www.kaggle.com/code/hideyukizushi/cmi25-imu-thm-tof-tf-blendingmodel-lb-82)|grandmaster| [yukiZ](https://www.kaggle.com/hideyukizushi)|Japan|\n|[Model 2](#Model_2)|0.829|&nbsp;v.7&nbsp;|[5fold single bert model](https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model) |&nbsp; expert &nbsp;| [wasupandceacar](https://www.kaggle.com/wasupandceacar)|United States|\n|[Model 3](#Model_3)|0.835|&nbsp;v.10&nbsp;|[Gated GRU + Hybrid Ensemble_v02](https://www.kaggle.com/code/pepushi/gated-gru-hybrid-ensemble-v02) |&nbsp; expert &nbsp;|[uhey](https://www.kaggle.com/pepushi)|Japan|\n|[Model 4](#Model_3)|0.835|&nbsp;v.10&nbsp;|[Gated GRU + Hybrid Ensemble_v02](https://www.kaggle.com/code/pepushi/gated-gru-hybrid-ensemble-v02)|&nbsp; expert &nbsp;|[uhey](https://www.kaggle.com/pepushi)|Japan|\n|  |  |  |  |  |  |  |\n|h-blend|[?](https://www.kaggle.com/code/nina2025/h-blend?scriptVersionId=255645344) | v.33 |12[**-**](https://)08[**-**](https://)2025 &nbsp;&nbsp;[ 0.211 + 0.248 + 0.267 + 0.274 ]|[ 70 x 30 ](#predict)|[  +0.0021,-0.0002,-0.0007,-0.0012 ]|\n|  |  |  |  |  |  |  |\n|h-blend|[?](https://www.kaggle.com/code/nina2025/cmi-ensemble-of-3-solutions-without-mnl-select/) | v.35 |13[**-**](https://)08[**-**](https://)2025 &nbsp;&nbsp;[ 0.19 + 0.25 + 0.27 + 0.29 ]|[ 70 x 30 ](#predict)|[  +0.0031,-0.0003,-0.0007,-0.0021 ]|\n|h-blend|[?](https://www.kaggle.com/code/nina2025/cmi-ensemble-of-3-solutions-without-mnl-select/) | v.36 |13[**-**](https://)08[**-**](https://)2025 &nbsp;&nbsp;[ 0.20 + 0.25 + 0.27 + 0.28 ]|[ 70 x 30 ](#predict)|[  +0.0041,-0.0004,-0.0012,-0.0025 ]|\n|h-blend|[?](https://www.kaggle.com/code/nina2025/cmi-ensemble-of-3-solutions-without-mnl-select/) | v.37 |13[**-**](https://)08[**-**](https://)2025 &nbsp;&nbsp;[ 0.22 + 0.25 + 0.27 + 0.26 ]|[ 70 x 30 ](#predict)|[  +0.0051,-0.0005,-0.0017,-0.0029 ]|\n","metadata":{"_cell_guid":"246965b6-e352-428a-b6a3-afd4e3101787","_uuid":"e1e9079e-a531-4b94-96a8-ee07efff2cdc","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.005969,"end_time":"2025-07-25T09:32:52.680013","exception":false,"start_time":"2025-07-25T09:32:52.674044","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"The difference between&nbsp; Model.3 &nbsp;&&nbsp; Model.4 &nbsp;is only in one operation:\n\nweights = {'A': 0.60, 'B': 0.15, 'C': 0.25}  &nbsp; & &nbsp;  weights = {'A': 0.50, 'B': 0.20, 'C': 0.30}\n\n--------------------------------------------------------------------------------------------\n\nps. &nbsp; We would like to thank all the people and participants of our community - from contributors to grandmasters - for supporting us with their attention and interest in what we are doing! Thank you very much!\n\nps.ps  &nbsp; We have removed all the works that we have completed so far, because yesterday the main system gave us a warning for some alleged \"plagiarism\" in the RSNA competition. All we did was copy two top works, without changing a single symbol there, and began our work as here - began to prepare the search space - in order to see how this system will work there. But alas, someone pressed the \"panic\" button!\n\nps.ps.ps  &nbsp; We left only this one work, in gratitude to you! Maybe someone will find it useful. \n\nWith respect, and wishes for prosperity, \n\nNina, (Far & Away)","metadata":{}},{"cell_type":"markdown","source":"\n| &nbsp; | &nbsp; | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n| - | - | :-: | :- | :-: | :-: | -: |\n|[Model 2](#Model_2)|0.829|&nbsp;v.7&nbsp;|[5fold single bert model](https://www.kaggle.com/code/wasupandceacar/lb-0-82-5fold-single-bert-model) |&nbsp; expert &nbsp;| [wasupandceacar](https://www.kaggle.com/wasupandceacar)|United States|\n|[Model 3](#Model_3)|0.835|&nbsp;v.10&nbsp;|[Gated GRU + Hybrid Ensemble_v02](https://www.kaggle.com/code/pepushi/gated-gru-hybrid-ensemble-v02) |&nbsp; expert &nbsp;|[uhey](https://www.kaggle.com/pepushi)|Japan|\n|[Model 4](#Model_3)|0.835|&nbsp;v.10&nbsp;|[Gated GRU + Hybrid Ensemble_v02](https://www.kaggle.com/code/pepushi/gated-gru-hybrid-ensemble-v02)|&nbsp; expert &nbsp;|[uhey](https://www.kaggle.com/pepushi)|Japan|\n\n\n| &nbsp; | &nbsp; | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n| - | - | :-: | :- | :-: | :-: | -: |\n|[Model 1](#Model_1)|0.820|&nbsp;v.6&nbsp;| [CMI25 IMU+THM/TOF TF BlendingModel](https://www.kaggle.com/code/hideyukizushi/cmi25-imu-thm-tof-tf-blendingmodel-lb-82)|grandmaster| [yukiZ](https://www.kaggle.com/hideyukizushi)|Japan|\n|[Model 3](#Model_3)|0.835|&nbsp;v.10&nbsp;|[Gated GRU + Hybrid Ensemble_v02](https://www.kaggle.com/code/pepushi/gated-gru-hybrid-ensemble-v02) |&nbsp; expert &nbsp;|[uhey](https://www.kaggle.com/pepushi)|Japan|\n|[Model 4](#Model_3)|0.835|&nbsp;v.10&nbsp;|[Gated GRU + Hybrid Ensemble_v02](https://www.kaggle.com/code/pepushi/gated-gru-hybrid-ensemble-v02)|&nbsp; expert &nbsp;|[uhey](https://www.kaggle.com/pepushi)|Japan|","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"markdown","source":"# Model_1","metadata":{"_cell_guid":"a4d23588-2c6d-4a6b-bff7-278e3792f557","_uuid":"35446c71-3c04-4ea7-bb72-fd2280265520","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.004107,"end_time":"2025-07-25T09:32:52.689377","exception":false,"start_time":"2025-07-25T09:32:52.68527","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nimport random\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate, GRU, GaussianNoise\n)\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport polars as pl\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom scipy.spatial.transform import Rotation as R\n\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed_everything(seed=42)\n# (Competition metric will only be imported when TRAINing)\nTRAIN = False                     # ← set to True when you want to train\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\nPRETRAINED_DIR = Path(\"/kaggle/input/cmi-d-111\")\nEXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\nBATCH_SIZE = 64\nPAD_PERCENTILE = 95\nLR_INIT = 5e-4\nWD = 3e-3\nMIXUP_ALPHA = 0.4\nEPOCHS = 160\nPATIENCE = 40\n\nprint(\"▶ imports ready · tensorflow\", tf.__version__)\n\n#Tensor Manipulations\ndef time_sum(x):\n    return K.sum(x, axis=1)\n\ndef squeeze_last_axis(x):\n    return tf.squeeze(x, axis=-1)\n\ndef expand_last_axis(x):\n    return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\n# Residual CNN Block with SE\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    shortcut = x\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n                   kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    x = se_block(x)\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n                          kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context\n\n# Normalizes and cleans the time series sequence. \n\ndef preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n    return scaler.transform(mat).astype('float32')\n\n# MixUp the data argumentation in order to regularize the neural network. \n\nclass MixupGenerator(Sequence):\n    def __init__(self, X, y, batch_size, alpha=0.2):\n        self.X, self.y = X, y\n        self.batch = batch_size\n        self.alpha = alpha\n        self.indices = np.arange(len(X))\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx], self.y[idx]\n        lam = np.random.beta(self.alpha, self.alpha)\n        perm = np.random.permutation(len(Xb))\n        X_mix = lam * Xb + (1-lam) * Xb[perm]\n        y_mix = lam * yb + (1-lam) * yb[perm]\n        return X_mix, y_mix\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)\n\n\ndef remove_gravity_from_acc(acc_data, rot_data):\n\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    else:\n        acc_values = acc_data\n\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    \n    gravity_world = np.array([0, 0, 9.81])\n\n    for i in range(num_samples):\n        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n            linear_accel[i, :] = acc_values[i, :] \n            continue\n\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except ValueError:\n             linear_accel[i, :] = acc_values[i, :]\n             \n    return linear_accel\n\ndef calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = quat_values.shape[0]\n    angular_vel = np.zeros((num_samples, 3))\n\n    for i in range(num_samples - 1):\n        q_t = quat_values[i]\n        q_t_plus_dt = quat_values[i+1]\n\n        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n            continue\n\n        try:\n            rot_t = R.from_quat(q_t)\n            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n\n            # Calculate the relative rotation\n            delta_rot = rot_t.inv() * rot_t_plus_dt\n            \n            # Convert delta rotation to angular velocity vector\n            # The rotation vector (Euler axis * angle) scaled by 1/dt\n            # is a good approximation for small delta_rot\n            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n        except ValueError:\n            # If quaternion is invalid, angular velocity remains zero\n            pass\n            \n    return angular_vel\n    \ndef calculate_angular_distance(rot_data):\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = quat_values.shape[0]\n    angular_dist = np.zeros(num_samples)\n\n    for i in range(num_samples - 1):\n        q1 = quat_values[i]\n        q2 = quat_values[i+1]\n\n        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n            continue\n        try:\n            # Преобразование кватернионов в объекты Rotation\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n\n            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n            # где p* - сопряженный кватернион q\n            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n            # Угол этого относительного вращения - это и есть угловое расстояние.\n            relative_rotation = r1.inv() * r2\n            \n            # Угол rotation vector соответствует угловому расстоянию\n            # Норма rotation vector - это угол в радианах\n            angle = np.linalg.norm(relative_rotation.as_rotvec())\n            angular_dist[i] = angle\n        except ValueError:\n            angular_dist[i] = 0 # В случае недействительных кватернионов\n            pass\n            \n    return angular_dist\n\ndef build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMU deep branch\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n\n    # TOF/Thermal lighter branch\n    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n\n    merged = Concatenate()([x1, x2])\n\n    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xc = GaussianNoise(0.09)(merged)\n    xc = Dense(16, activation='elu')(xc)\n    \n    x = Concatenate()([xa, xb, xc])\n    x = Dropout(0.4)(x)\n    x = attention_layer(x)\n\n    for units, drop in [(256, 0.5), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x); x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n    return Model(inp, out)\n\ntmp_model = build_two_branch_model(127,7,325,18)\nprint(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\nfinal_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\npad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\nscaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\ngesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n\n\ncustom_objs = {\n    'time_sum': time_sum, 'squeeze_last_axis': squeeze_last_axis, 'expand_last_axis': expand_last_axis,\n    'se_block': se_block, 'residual_se_cnn_block': residual_se_cnn_block, 'attention_layer': attention_layer,\n}\n\n# ----------------------------------------------------------------- #\n# Load any Models\n# * is 2 Train Model Load\n# ----------------------------------------------------------------- #\n\nmodels1 = []\nprint(f\"  Loading models for ensemble inference...\")\nfor fold in range(10):\n    MODEL_DIR = \"/kaggle/input/cmi-d-111\"\n    \n    model_path = f\"{MODEL_DIR}/D-111_{fold}.h5\"\n    print(\">>>LoadModel>>>\",model_path)\n    model = load_model(model_path, compile=False, custom_objects=custom_objs)\n    models1.append(model)\nprint(\"-\"*50)\n\nfor fold in range(10):\n    MODEL_DIR = \"/kaggle/input/cmi-d-111\"\n    \n    model_path = f\"{MODEL_DIR}/v0629_{fold}.h5\"\n    print(\">>>LoadModel>>>\",model_path)\n    model = load_model(model_path, compile=False, custom_objects=custom_objs)\n    models1.append(model)\nprint(\"-\"*50)\nprint(f\"[INFO]NumUseModels:{len(models1)}\")","metadata":{"_cell_guid":"e28baf78-1483-43c8-99c6-79fa005c6ee0","_uuid":"ce7454ad-b4eb-4fac-9b37-9c3e580dd6cd","execution":{"iopub.status.busy":"2025-08-13T02:52:51.431925Z","iopub.execute_input":"2025-08-13T02:52:51.432716Z","iopub.status.idle":"2025-08-13T02:53:32.357739Z","shell.execute_reply.started":"2025-08-13T02:52:51.432687Z","shell.execute_reply":"2025-08-13T02:53:32.357042Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":30.815059,"end_time":"2025-07-25T09:33:23.508606","exception":false,"start_time":"2025-07-25T09:32:52.693547","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[{"name":"stderr","text":"2025-08-13 02:52:58.719351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755053579.084469      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755053579.189679      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"▶ imports ready · tensorflow 2.18.0\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1755053597.497576      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1755053597.498511      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"▶ INFERENCE MODE – loading artefacts from /kaggle/input/cmi-d-111\n  Loading models for ensemble inference...\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_0.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_1.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_2.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_3.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_4.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_5.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_6.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_7.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_8.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/D-111_9.h5\n--------------------------------------------------\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_0.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_1.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_2.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_3.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_4.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_5.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_6.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_7.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_8.h5\n>>>LoadModel>>> /kaggle/input/cmi-d-111/v0629_9.h5\n--------------------------------------------------\n[INFO]NumUseModels:20\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# predict_1\n\ndef predict1(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    df_seq = sequence.to_pandas()\n    linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n    df_seq['linear_acc_x'], df_seq['linear_acc_y'], df_seq['linear_acc_z'] = linear_accel[:, 0], linear_accel[:, 1], linear_accel[:, 2]\n    df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n    df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n    angular_vel = calculate_angular_velocity_from_quat(df_seq)\n    df_seq['angular_vel_x'], df_seq['angular_vel_y'], df_seq['angular_vel_z'] = angular_vel[:, 0], angular_vel[:, 1], angular_vel[:, 2]\n    df_seq['angular_distance'] = calculate_angular_distance(df_seq)\n    \n    for i in range(1, 6):\n        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n        df_seq[f'tof_{i}_mean'], df_seq[f'tof_{i}_std'], df_seq[f'tof_{i}_min'], df_seq[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n        \n    mat_unscaled = df_seq[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n    mat_scaled = scaler.transform(mat_unscaled)\n    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    \n    all_preds = [model.predict(pad_input, verbose=0)[0] for model in models1] # 主出力のみ取得\n    avg_pred = np.mean(all_preds, axis=0)\n    return avg_pred\n    # return str(gesture_classes[avg_pred.argmax()])","metadata":{"_cell_guid":"0c943402-c7d9-4f0d-8cc2-12dcef0b8fd2","_uuid":"23319942-689e-4e97-b7c4-f296516431c0","execution":{"iopub.status.busy":"2025-08-13T02:53:32.359159Z","iopub.execute_input":"2025-08-13T02:53:32.359632Z","iopub.status.idle":"2025-08-13T02:53:32.368913Z","shell.execute_reply.started":"2025-08-13T02:53:32.359611Z","shell.execute_reply":"2025-08-13T02:53:32.368084Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.015049,"end_time":"2025-07-25T09:33:23.529305","exception":false,"start_time":"2025-07-25T09:33:23.514256","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Model_2","metadata":{"papermill":{"duration":0.004974,"end_time":"2025-07-25T09:33:23.539553","exception":false,"start_time":"2025-07-25T09:33:23.534579","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport torch\nimport kagglehub\nfrom pathlib import Path\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom scipy.spatial.transform import Rotation as R\nfrom collections import defaultdict\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom tqdm.notebook import tqdm\nfrom torch.amp import autocast\nimport pandas as pd\nimport polars as pl\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom transformers import BertConfig, BertModel\n\n\ndef remove_gravity_from_acc(acc_data, rot_data):\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    else:\n        acc_values = acc_data\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    gravity_world = np.array([0, 0, 9.81])\n    for i in range(num_samples):\n        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n            linear_accel[i, :] = acc_values[i, :] \n            continue\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except ValueError:\n             linear_accel[i, :] = acc_values[i, :]\n    return linear_accel\n\ndef calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n    num_samples = quat_values.shape[0]\n    angular_vel = np.zeros((num_samples, 3))\n    for i in range(num_samples - 1):\n        q_t = quat_values[i]\n        q_t_plus_dt = quat_values[i+1]\n        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n            continue\n        try:\n            rot_t = R.from_quat(q_t)\n            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n            delta_rot = rot_t.inv() * rot_t_plus_dt\n            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n        except ValueError:\n            pass\n    return angular_vel\n\ndef calculate_angular_distance(rot_data):\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n    num_samples = quat_values.shape[0]\n    angular_dist = np.zeros(num_samples)\n    for i in range(num_samples - 1):\n        q1 = quat_values[i]\n        q2 = quat_values[i+1]\n        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n            angular_dist[i] = 0\n            continue\n        try:\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n            relative_rotation = r1.inv() * r2\n            angle = np.linalg.norm(relative_rotation.as_rotvec())\n            angular_dist[i] = angle\n        except ValueError:\n            angular_dist[i] = 0 # В случае недействительных кватернионов\n            pass\n    return angular_dist\n\n\nclass CMIFeDataset(Dataset):\n    def __init__(self, data_path, config):\n        self.config = config\n        self.init_feature_names(data_path)\n        df = self.generate_features(pd.read_csv(data_path, usecols=set(self.base_cols+self.feature_cols)))\n        self.generate_dataset(df)\n\n    def init_feature_names(self, data_path):\n        self.imu_engineered_features = [\n            'acc_mag', 'rot_angle',\n            'acc_mag_jerk', 'rot_angle_vel',\n            'linear_acc_mag', 'linear_acc_mag_jerk',\n            'angular_vel_x', 'angular_vel_y', 'angular_vel_z',\n            'angular_distance'\n        ]\n\n        self.tof_mode = self.config.get(\"tof_mode\", \"stats\")\n        self.tof_region_stats = ['mean', 'std', 'min', 'max']\n        self.tof_cols = self.generate_tof_feature_names()\n\n        columns = pd.read_csv(data_path, nrows=0).columns.tolist()\n        imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n        imu_cols_base.extend([c for c in columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n        self.imu_cols = list(dict.fromkeys(imu_cols_base + self.imu_engineered_features))\n        self.thm_cols = [c for c in columns if c.startswith('thm_')]\n        self.feature_cols = self.imu_cols + self.thm_cols + self.tof_cols\n        self.imu_dim = len(self.imu_cols)\n        self.thm_dim = len(self.thm_cols)\n        self.tof_dim = len(self.tof_cols)\n        self.base_cols = ['acc_x', 'acc_y', 'acc_z',\n                          'rot_x', 'rot_y', 'rot_z', 'rot_w',\n                          'sequence_id', 'subject', \n                          'sequence_type', 'gesture', 'orientation'] + [c for c in columns if c.startswith('thm_')] + [f\"tof_{i}_v{p}\" for i in range(1, 6) for p in range(64)]\n        self.fold_cols = ['subject', 'sequence_type', 'gesture', 'orientation']\n\n    def generate_tof_feature_names(self):\n        features = []\n        if self.config.get(\"tof_raw\", False):\n            for i in range(1, 6):\n                features.extend([f\"tof_{i}_v{p}\" for p in range(64)])\n        for i in range(1, 6):\n            if self.tof_mode != 0:\n                for stat in self.tof_region_stats:\n                    features.append(f'tof_{i}_{stat}')\n                if self.tof_mode > 1:\n                    for r in range(self.tof_mode):\n                        for stat in self.tof_region_stats:\n                            features.append(f'tof{self.tof_mode}_{i}_region_{r}_{stat}')\n                if self.tof_mode == -1:\n                    for mode in [2, 4, 8, 16, 32]:\n                        for r in range(mode):\n                            for stat in self.tof_region_stats:\n                                features.append(f'tof{mode}_{i}_region_{r}_{stat}')\n        return features\n\n    def compute_features(self, df):\n        df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n        df['rot_angle'] = 2 * np.arccos(df['rot_w'].clip(-1, 1))\n        df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n        df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n            \n        linear_accel_list = []\n        for _, group in df.groupby('sequence_id'):\n            acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n            linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n            linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n        df_linear_accel = pd.concat(linear_accel_list)\n        df = pd.concat([df, df_linear_accel], axis=1)\n        df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n        df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n    \n        angular_vel_list = []\n        for _, group in df.groupby('sequence_id'):\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n            angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n            angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n        df_angular_vel = pd.concat(angular_vel_list)\n        df = pd.concat([df, df_angular_vel], axis=1)\n    \n        angular_distance_list = []\n        for _, group in df.groupby('sequence_id'):\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n            angular_dist_group = calculate_angular_distance(rot_data_group)\n            angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n        df_angular_distance = pd.concat(angular_distance_list)\n        df = pd.concat([df, df_angular_distance], axis=1)\n\n        if self.tof_mode != 0:\n            new_columns = {}\n            for i in range(1, 6):\n                pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n                tof_data = df[pixel_cols].replace(-1, np.nan)\n                new_columns.update({\n                    f'tof_{i}_mean': tof_data.mean(axis=1),\n                    f'tof_{i}_std': tof_data.std(axis=1),\n                    f'tof_{i}_min': tof_data.min(axis=1),\n                    f'tof_{i}_max': tof_data.max(axis=1)\n                })\n                if self.tof_mode > 1:\n                    region_size = 64 // self.tof_mode\n                    for r in range(self.tof_mode):\n                        region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                        new_columns.update({\n                            f'tof{self.tof_mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                        })\n                if self.tof_mode == -1:\n                    for mode in [2, 4, 8, 16, 32]:\n                        region_size = 64 // mode\n                        for r in range(mode):\n                            region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                            new_columns.update({\n                                f'tof{mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                                f'tof{mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                                f'tof{mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                                f'tof{mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                            })\n            df = pd.concat([df, pd.DataFrame(new_columns)], axis=1)\n        return df\n        \n    def generate_features(self, df):\n        self.le = LabelEncoder()\n        df['gesture_int'] = self.le.fit_transform(df['gesture'])\n        self.class_num = len(self.le.classes_)\n        \n        if all(c in df.columns for c in self.imu_engineered_features) and all(c in df.columns for c in self.tof_cols):\n            print(\"Have precomputed, skip compute.\")\n        else:\n            print(\"Not precomputed, do compute.\")\n            df = self.compute_features(df)\n\n        if self.config.get(\"save_precompute\", False):\n            df.to_csv(self.config.get(\"save_filename\", \"train.csv\"))\n        return df\n\n    def scale(self, data_unscaled):\n        scaler_function = self.config.get(\"scaler_function\", StandardScaler())\n        scaler = scaler_function.fit(np.concatenate(data_unscaled, axis=0))\n        return [scaler.transform(x) for x in data_unscaled], scaler\n\n    def pad(self, data_scaled, cols):\n        pad_data = np.zeros((len(data_scaled), self.pad_len, len(cols)), dtype='float32')\n        for i, seq in enumerate(data_scaled):\n            seq_len = min(len(seq), self.pad_len)\n            pad_data[i, :seq_len] = seq[:seq_len]\n        return pad_data\n\n    def get_nan_value(self, data, ratio):\n        max_value = data.max().max()\n        nan_value = -max_value * ratio\n        return nan_value\n\n    def generate_dataset(self, df):\n        seq_gp = df.groupby('sequence_id') \n        imu_unscaled, thm_unscaled, tof_unscaled = [], [], []\n        classes, lens = [], []\n        self.imu_nan_value = self.get_nan_value(df[self.imu_cols], self.config[\"nan_ratio\"][\"imu\"])\n        self.thm_nan_value = self.get_nan_value(df[self.thm_cols], self.config[\"nan_ratio\"][\"thm\"])\n        self.tof_nan_value = self.get_nan_value(df[self.tof_cols], self.config[\"nan_ratio\"][\"tof\"])\n\n        self.fold_feats = defaultdict(list)\n        for seq_id, seq_df in seq_gp:\n            imu_data = seq_df[self.imu_cols]\n            if self.config[\"fbfill\"][\"imu\"]:\n                imu_data = imu_data.ffill().bfill()\n            imu_unscaled.append(imu_data.fillna(self.imu_nan_value).values.astype('float32'))\n\n            thm_data = seq_df[self.thm_cols]\n            if self.config[\"fbfill\"][\"thm\"]:\n                thm_data = thm_data.ffill().bfill()\n            thm_unscaled.append(thm_data.fillna(self.thm_nan_value).values.astype('float32'))\n\n            tof_data = seq_df[self.tof_cols]\n            if self.config[\"fbfill\"][\"tof\"]:\n                tof_data = tof_data.ffill().bfill()\n            tof_unscaled.append(tof_data.fillna(self.tof_nan_value).values.astype('float32'))\n            \n            classes.append(seq_df['gesture_int'].iloc[0])\n            lens.append(len(imu_data))\n\n            for col in self.fold_cols:\n                self.fold_feats[col].append(seq_df[col].iloc[0])\n            \n        self.dataset_indices = classes\n        self.pad_len = int(np.percentile(lens, self.config.get(\"percent\", 95)))\n        if self.config.get(\"one_scale\", True):\n            x_unscaled = [np.concatenate([imu, thm, tof], axis=1) for imu, thm, tof in zip(imu_unscaled, thm_unscaled, tof_unscaled)]\n            x_scaled, self.x_scaler = self.scale(x_unscaled)\n            x = self.pad(x_scaled, self.imu_cols+self.thm_cols+self.tof_cols)\n            self.imu = x[..., :self.imu_dim]\n            self.thm = x[..., self.imu_dim:self.imu_dim+self.thm_dim]\n            self.tof = x[..., self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim]\n        else:\n            imu_scaled, self.imu_scaler = self.scale(imu_unscaled)\n            thm_scaled, self.thm_scaler = self.scale(thm_unscaled)\n            tof_scaled, self.tof_scaler = self.scale(tof_unscaled)\n            self.imu = self.pad(imu_scaled, self.imu_cols)\n            self.thm = self.pad(thm_scaled, self.thm_cols)\n            self.tof = self.pad(tof_scaled, self.tof_cols)\n        self.precompute_scaled_nan_values()\n        self.class_ = F.one_hot(torch.from_numpy(np.array(classes)).long(), num_classes=len(self.le.classes_)).float().numpy()\n        self.class_weight = torch.FloatTensor(compute_class_weight('balanced', classes=np.arange(len(self.le.classes_)), y=classes))\n\n    def precompute_scaled_nan_values(self):\n        dummy_df = pd.DataFrame(\n            np.array([[self.imu_nan_value]*len(self.imu_cols) + \n                     [self.thm_nan_value]*len(self.thm_cols) +\n                     [self.tof_nan_value]*len(self.tof_cols)]),\n            columns=self.imu_cols + self.thm_cols + self.tof_cols\n        )\n        \n        if self.config.get(\"one_scale\", True):\n            scaled = self.x_scaler.transform(dummy_df)\n            self.imu_scaled_nan = scaled[0, :self.imu_dim].mean()\n            self.thm_scaled_nan = scaled[0, self.imu_dim:self.imu_dim+self.thm_dim].mean()\n            self.tof_scaled_nan = scaled[0, self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim].mean()\n        else:\n            self.imu_scaled_nan = self.imu_scaler.transform(dummy_df[self.imu_cols])[0].mean()\n            self.thm_scaled_nan = self.thm_scaler.transform(dummy_df[self.thm_cols])[0].mean()\n            self.tof_scaled_nan = self.tof_scaler.transform(dummy_df[self.tof_cols])[0].mean()\n\n    def get_scaled_nan_tensors(self, imu, thm, tof):\n        return torch.full(imu.shape, self.imu_scaled_nan, device=imu.device), \\\n            torch.full(thm.shape, self.thm_scaled_nan, device=thm.device), \\\n            torch.full(tof.shape, self.tof_scaled_nan, device=tof.device)\n\n    def inference_process(self, sequence):\n        df_seq = sequence.to_pandas().copy()\n        if not all(c in df_seq.columns for c in self.imu_engineered_features):\n            df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2)\n            df_seq['rot_angle'] = 2 * np.arccos(df_seq['rot_w'].clip(-1, 1))\n            df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0)\n            df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0)\n            if all(col in df_seq.columns for col in ['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', 'rot_w']):\n                linear_accel = remove_gravity_from_acc(\n                    df_seq[['acc_x', 'acc_y', 'acc_z']], \n                    df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n                )\n                df_seq[['linear_acc_x', 'linear_acc_y', 'linear_acc_z']] = linear_accel\n            else:\n                df_seq['linear_acc_x'] = df_seq.get('acc_x', 0)\n                df_seq['linear_acc_y'] = df_seq.get('acc_y', 0)\n                df_seq['linear_acc_z'] = df_seq.get('acc_z', 0)\n            df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n            df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n            if all(col in df_seq.columns for col in ['rot_x', 'rot_y', 'rot_z', 'rot_w']):\n                angular_vel = calculate_angular_velocity_from_quat(df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']])\n                df_seq[['angular_vel_x', 'angular_vel_y', 'angular_vel_z']] = angular_vel\n            else:\n                df_seq[['angular_vel_x', 'angular_vel_y', 'angular_vel_z']] = 0\n            if all(col in df_seq.columns for col in ['rot_x', 'rot_y', 'rot_z', 'rot_w']):\n                df_seq['angular_distance'] = calculate_angular_distance(df_seq[['rot_x', 'rot_y', 'rot_z', 'rot_w']])\n            else:\n                df_seq['angular_distance'] = 0\n\n        if self.tof_mode != 0:\n            new_columns = {} \n            for i in range(1, 6):\n                pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n                tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n                new_columns.update({\n                    f'tof_{i}_mean': tof_data.mean(axis=1),\n                    f'tof_{i}_std': tof_data.std(axis=1),\n                    f'tof_{i}_min': tof_data.min(axis=1),\n                    f'tof_{i}_max': tof_data.max(axis=1)\n                })\n                if self.tof_mode > 1:\n                    region_size = 64 // self.tof_mode\n                    for r in range(self.tof_mode):\n                        region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                        new_columns.update({\n                            f'tof{self.tof_mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                            f'tof{self.tof_mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                        })\n                if self.tof_mode == -1:\n                    for mode in [2, 4, 8, 16, 32]:\n                        region_size = 64 // mode\n                        for r in range(mode):\n                            region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                            new_columns.update({\n                                f'tof{mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                                f'tof{mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                                f'tof{mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                                f'tof{mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                            })\n            df_seq = pd.concat([df_seq, pd.DataFrame(new_columns)], axis=1)\n        \n        imu_unscaled = df_seq[self.imu_cols]\n        if self.config[\"fbfill\"][\"imu\"]:\n            imu_unscaled = imu_unscaled.ffill().bfill()\n        imu_unscaled = imu_unscaled.fillna(self.imu_nan_value).values.astype('float32')\n\n        thm_unscaled = df_seq[self.thm_cols]\n        if self.config[\"fbfill\"][\"thm\"]:\n            thm_unscaled = thm_unscaled.ffill().bfill()\n        thm_unscaled = thm_unscaled.fillna(self.thm_nan_value).values.astype('float32')\n\n        tof_unscaled = df_seq[self.tof_cols]\n        if self.config[\"fbfill\"][\"tof\"]:\n            tof_unscaled = tof_unscaled.ffill().bfill()\n        tof_unscaled = tof_unscaled.fillna(self.tof_nan_value).values.astype('float32')\n        \n        if self.config.get(\"one_scale\", True):\n            x_unscaled = np.concatenate([imu_unscaled, thm_unscaled, tof_unscaled], axis=1)\n            x_scaled = self.x_scaler.transform(x_unscaled)\n            imu_scaled = x_scaled[..., :self.imu_dim]\n            thm_scaled = x_scaled[..., self.imu_dim:self.imu_dim+self.thm_dim]\n            tof_scaled = x_scaled[..., self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim]\n        else:\n            imu_scaled = self.imu_scaler.transform(imu_unscaled)\n            thm_scaled = self.thm_scaler.transform(thm_unscaled)\n            tof_scaled = self.tof_scaler.transform(tof_unscaled)\n\n        combined = np.concatenate([imu_scaled, thm_scaled, tof_scaled], axis=1)\n        padded = np.zeros((self.pad_len, combined.shape[1]), dtype='float32')\n        seq_len = min(combined.shape[0], self.pad_len)\n        padded[:seq_len] = combined[:seq_len]\n        imu = padded[..., :self.imu_dim]\n        thm = padded[..., self.imu_dim:self.imu_dim+self.thm_dim]\n        tof = padded[..., self.imu_dim+self.thm_dim:self.imu_dim+self.thm_dim+self.tof_dim]\n        \n        return torch.from_numpy(imu).float().unsqueeze(0), torch.from_numpy(thm).float().unsqueeze(0), torch.from_numpy(tof).float().unsqueeze(0)\n\n    def __getitem__(self, idx):\n        return self.imu[idx], self.thm[idx], self.tof[idx], self.class_[idx]\n\n    def __len__(self):\n        return len(self.class_)\n\nclass CMIFoldDataset:\n    def __init__(self, data_path, config, full_dataset_function, n_folds=5, random_seed=0):\n        self.full_dataset = full_dataset_function(data_path=data_path, config=config)\n        self.imu_dim = self.full_dataset.imu_dim\n        self.thm_dim = self.full_dataset.thm_dim\n        self.tof_dim = self.full_dataset.tof_dim\n        self.le = self.full_dataset.le\n        self.class_names = self.full_dataset.le.classes_\n        self.class_weight = self.full_dataset.class_weight\n        self.n_folds = n_folds\n        self.skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n        self.folds = list(self.skf.split(np.arange(len(self.full_dataset)), np.array(self.full_dataset.dataset_indices)))\n    \n    def get_fold_datasets(self, fold_idx):\n        if self.folds is None or fold_idx >= self.n_folds:\n            return None, None\n        fold_train_idx, fold_valid_idx = self.folds[fold_idx]\n        return Subset(self.full_dataset, fold_train_idx), Subset(self.full_dataset, fold_valid_idx)\n\n    def print_fold_stats(self):\n        def get_label_counts(subset):\n            counts = {name: 0 for name in self.class_names}\n            if subset is None:\n                return counts\n            for idx in subset.indices:\n                label_idx = self.full_dataset.dataset_indices[idx]\n                counts[self.class_names[label_idx]] += 1\n            return counts\n        \n        print(\"\\n交叉验证折叠统计:\")\n        for fold_idx in range(self.n_folds):\n            train_fold, valid_fold = self.get_fold_datasets(fold_idx)\n            train_counts = get_label_counts(train_fold)\n            valid_counts = get_label_counts(valid_fold)\n                \n            print(f\"\\nFold {fold_idx + 1}:\")\n            print(f\"{'类别':<50} {'训练集':<10} {'验证集':<10}\")\n            for name in self.class_names:\n                print(f\"{name:<50} {train_counts[name]:<10} {valid_counts[name]:<10}\")\n\n\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction = 8):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, channels // reduction, bias=True)\n        self.fc2 = nn.Linear(channels // reduction, channels, bias=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # x: (B, C, L)\n        se = F.adaptive_avg_pool1d(x, 1).squeeze(-1)      # -> (B, C)\n        se = F.relu(self.fc1(se), inplace=True)          # -> (B, C//r)\n        se = self.sigmoid(self.fc2(se)).unsqueeze(-1)    # -> (B, C, 1)\n        return x * se                \n\nclass ResNetSEBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, wd = 1e-4):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels,\n                               kernel_size=3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.conv2 = nn.Conv1d(out_channels, out_channels,\n                               kernel_size=3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        # SE\n        self.se = SEBlock(out_channels)\n        \n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv1d(in_channels, out_channels, kernel_size=1,\n                          padding=0, bias=False),\n                nn.BatchNorm1d(out_channels)\n            )\n        else:\n            self.shortcut = nn.Identity()\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x) :\n        identity = self.shortcut(x)              # (B, out, L)\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.se(out)                       # (B, out, L)\n        out = out + identity\n        return self.relu(out)\n\nclass CMIModel(nn.Module):\n    def __init__(self, imu_dim, thm_dim, tof_dim, n_classes, **kwargs):\n        super().__init__()\n        self.imu_branch = nn.Sequential(\n            self.residual_se_cnn_block(imu_dim, kwargs[\"imu1_channels\"], kwargs[\"imu1_layers\"],\n                                       drop=kwargs[\"imu1_dropout\"]),\n            self.residual_se_cnn_block(kwargs[\"imu1_channels\"], kwargs[\"feat_dim\"], kwargs[\"imu2_layers\"],\n                                       drop=kwargs[\"imu2_dropout\"])\n        )\n\n        self.thm_branch = nn.Sequential(\n            nn.Conv1d(thm_dim, kwargs[\"thm1_channels\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"thm1_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"thm1_dropout\"]),\n            \n            nn.Conv1d(kwargs[\"thm1_channels\"], kwargs[\"feat_dim\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"feat_dim\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"thm2_dropout\"])\n        )\n        \n        self.tof_branch = nn.Sequential(\n            nn.Conv1d(tof_dim, kwargs[\"tof1_channels\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"tof1_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"tof1_dropout\"]),\n            \n            nn.Conv1d(kwargs[\"tof1_channels\"], kwargs[\"feat_dim\"], kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm1d(kwargs[\"feat_dim\"]),\n            nn.ReLU(inplace=True),\n            nn.MaxPool1d(2, ceil_mode=True),\n            nn.Dropout(kwargs[\"tof2_dropout\"])\n        )\n\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, kwargs[\"feat_dim\"]))\n        self.bert = BertModel(BertConfig(\n            hidden_size=kwargs[\"feat_dim\"],\n            num_hidden_layers=kwargs[\"bert_layers\"],\n            num_attention_heads=kwargs[\"bert_heads\"],\n            intermediate_size=kwargs[\"feat_dim\"]*4\n        ))\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(kwargs[\"feat_dim\"], kwargs[\"cls1_channels\"], bias=False),\n            nn.BatchNorm1d(kwargs[\"cls1_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.Dropout(kwargs[\"cls1_dropout\"]),\n            nn.Linear(kwargs[\"cls1_channels\"], kwargs[\"cls2_channels\"], bias=False),\n            nn.BatchNorm1d(kwargs[\"cls2_channels\"]),\n            nn.ReLU(inplace=True),\n            nn.Dropout(kwargs[\"cls2_dropout\"]),\n            nn.Linear(kwargs[\"cls2_channels\"], n_classes)\n        )\n    \n    def residual_se_cnn_block(self, in_channels, out_channels, num_layers, pool_size=2, drop=0.3, wd=1e-4):\n        return nn.Sequential(\n            *[ResNetSEBlock(in_channels=in_channels, out_channels=in_channels) for i in range(num_layers)],\n            ResNetSEBlock(in_channels, out_channels, wd=wd),\n            nn.MaxPool1d(pool_size),\n            nn.Dropout(drop)\n        )\n    \n    def forward(self, imu, thm, tof):\n        imu_feat = self.imu_branch(imu.permute(0, 2, 1))\n        thm_feat = self.thm_branch(thm.permute(0, 2, 1))\n        tof_feat = self.tof_branch(tof.permute(0, 2, 1))\n        \n        bert_input = torch.cat([imu_feat, thm_feat, tof_feat], dim=-1).permute(0, 2, 1)\n        cls_token = self.cls_token.expand(bert_input.size(0), -1, -1)  # (B,1,H)\n        bert_input = torch.cat([cls_token, bert_input], dim=1)  # (B,T+1,H)\n        outputs = self.bert(inputs_embeds=bert_input)\n        pred_cls = outputs.last_hidden_state[:, 0, :]\n\n        return self.classifier(pred_cls)\n\n\nCUDA0 = \"cuda:0\"\nseed = 0\nbatch_size = 64\nnum_workers = 4\nn_folds = 5\n\nuniverse_csv_path = Path(\"/kaggle/input/cmi-precompute/pytorch/all/1/tof-1_raw.csv\")\n\ndeterministic = kagglehub.package_import('wasupandceacar/deterministic').deterministic\ndeterministic.init_all(seed)\ndef init_dataset():\n    dataset_config = {\n        \"percent\": 95,\n        \"scaler_function\": StandardScaler(),\n        \"nan_ratio\": {\n            \"imu\": 0,\n            \"thm\": 0,\n            \"tof\": 0,\n        },\n        \"fbfill\": {\n            \"imu\": True,\n            \"thm\": True,\n            \"tof\": True,\n        },\n        \"one_scale\": True,\n        \"tof_raw\": True,\n        \"tof_mode\": 16,\n        \"save_precompute\": False,\n    }\n    dataset = CMIFoldDataset(universe_csv_path, dataset_config,\n                             n_folds=n_folds, random_seed=seed, full_dataset_function=CMIFeDataset)\n    dataset.print_fold_stats()\n    return dataset\n\ndef get_fold_dataset(dataset, fold):\n    _, valid_dataset = dataset.get_fold_datasets(fold)\n    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n    return valid_loader\n\ndataset = init_dataset()\n\nmodel_function = CMIModel\nmodel_args = {\"feat_dim\": 500,\n              \"imu1_channels\": 219, \"imu1_dropout\": 0.2946731587132302, \"imu2_dropout\": 0.2697745571929592,\n              \"imu1_weight_decay\": 0.0014824054650601245, \"imu2_weight_decay\": 0.002742543773142381,\n              \"imu1_layers\": 0, \"imu2_layers\": 0,\n              \"thm1_channels\": 82, \"thm1_dropout\": 0.2641274454844602, \"thm2_dropout\": 0.302896343020985, \n              \"tof1_channels\": 82, \"tof1_dropout\": 0.2641274454844602, \"tof2_dropout\": 0.3028963430209852, \n              \"bert_layers\": 8, \"bert_heads\": 10,\n              \"cls1_channels\": 937, \"cls2_channels\": 303, \"cls1_dropout\": 0.2281834512100508, \"cls2_dropout\": 0.22502521933558461}\nmodel_args.update({\n    \"imu_dim\": dataset.full_dataset.imu_dim, \n    \"thm_dim\": dataset.full_dataset.thm_dim,\n    \"tof_dim\": dataset.full_dataset.tof_dim,\n    \"n_classes\": dataset.full_dataset.class_num})\nmodel_dir = Path(\"/kaggle/input/cmi-models-public/pytorch/train_fold_model05_tof16_raw/1\")\n\nmodel_dicts = [\n    {\n        \"model_function\": model_function,\n        \"model_args\": model_args,\n        \"model_path\": model_dir / f\"fold{fold}/best_ema.pt\",\n    } for fold in range(n_folds)\n]\n\nmodels2 = list()\nfor model_dict in model_dicts:\n    model_function = model_dict[\"model_function\"]\n    model_args = model_dict[\"model_args\"]\n    model_path = model_dict[\"model_path\"]\n    model = model_function(**model_args).to(CUDA0)\n    state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in torch.load(model_path).items()}\n    model.load_state_dict(state_dict)\n    model = model.eval()\n    models2.append(model)\n\n\nmetric_package = kagglehub.package_import('wasupandceacar/cmi-metric')\n\nmetric = metric_package.Metric()\nimu_only_metric = metric_package.Metric()\n\ndef to_cuda(*tensors):\n    return [tensor.to(CUDA0) for tensor in tensors]\n\ndef predict_valid(model, imu, thm, tof):\n    pred = model(imu, thm, tof)\n    return pred\n\ndef valid(model, valid_bar):\n    with torch.no_grad():\n        for imu, thm, tof, y in valid_bar:\n            imu, thm, tof, y = to_cuda(imu, thm, tof, y)\n            with autocast(device_type='cuda', dtype=torch.bfloat16): \n                logits = predict_valid(model, imu, thm, tof)\n            metric.add(dataset.le.classes_[y.argmax(dim=1).cpu()], dataset.le.classes_[logits.argmax(dim=1).cpu()])\n            _, thm, tof = dataset.full_dataset.get_scaled_nan_tensors(imu, thm, tof)\n            with autocast(device_type='cuda', dtype=torch.bfloat16): \n                logits = model(imu, thm, tof)\n            imu_only_metric.add(dataset.le.classes_[y.argmax(dim=1).cpu()], dataset.le.classes_[logits.argmax(dim=1).cpu()])\n\n# for fold, model in enumerate(models2):\n#     valid_loader = get_fold_dataset(dataset, fold)\n#     valid_bar = tqdm(valid_loader, desc=f\"Valid\", position=0, leave=False)\n#     valid(model, valid_bar)\n\n# print(f\"\"\"\n# Normal score: {metric.score()}\n# IMU only score: {imu_only_metric.score()}\n# \"\"\")\n\ndef avg_predict(models, imu, thm, tof):\n    outputs = []\n    with autocast(device_type='cuda'):\n        for model in models:\n            logits = model(imu, thm, tof)\n        outputs.append(logits)\n    return torch.mean(torch.stack(outputs), dim=0)","metadata":{"_cell_guid":"80dac13f-ca07-4786-b31d-0f0c72694ebe","_uuid":"8e6b8a61-6c7d-4277-9465-f4b25b02c4f1","execution":{"iopub.status.busy":"2025-08-13T02:53:32.370210Z","iopub.execute_input":"2025-08-13T02:53:32.370546Z","iopub.status.idle":"2025-08-13T02:56:33.065379Z","shell.execute_reply.started":"2025-08-13T02:53:32.370504Z","shell.execute_reply":"2025-08-13T02:56:33.064703Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":165.71182,"end_time":"2025-07-25T09:36:09.256732","exception":false,"start_time":"2025-07-25T09:33:23.544912","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[{"name":"stdout","text":"Have precomputed, skip compute.\n\n交叉验证折叠统计:\n\nFold 1:\n类别                                                 训练集        验证集       \nAbove ear - pull hair                              511        127       \nCheek - pinch skin                                 509        128       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                510        128       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     128        33        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          381        96        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         382        96        \nWrite name in air                                  382        95        \nWrite name on leg                                  129        32        \n\nFold 2:\n类别                                                 训练集        验证集       \nAbove ear - pull hair                              511        127       \nCheek - pinch skin                                 509        128       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                510        128       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          381        96        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         382        96        \nWrite name in air                                  382        95        \nWrite name on leg                                  129        32        \n\nFold 3:\n类别                                                 训练集        验证集       \nAbove ear - pull hair                              510        128       \nCheek - pinch skin                                 510        127       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                511        127       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                128        33        \nPull air toward your face                          382        95        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         382        96        \nWrite name in air                                  382        95        \nWrite name on leg                                  128        33        \n\nFold 4:\n类别                                                 训练集        验证集       \nAbove ear - pull hair                              510        128       \nCheek - pinch skin                                 510        127       \nDrink from bottle/cup                              129        32        \nEyebrow - pull hair                                511        127       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         128        33        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          382        95        \nScratch knee/leg skin                              128        33        \nText on phone                                      512        128       \nWave hello                                         383        95        \nWrite name in air                                  381        96        \nWrite name on leg                                  129        32        \n\nFold 5:\n类别                                                 训练集        验证集       \nAbove ear - pull hair                              510        128       \nCheek - pinch skin                                 510        127       \nDrink from bottle/cup                              128        33        \nEyebrow - pull hair                                510        128       \nEyelash - pull hair                                512        128       \nFeel around in tray and pull out an object         129        32        \nForehead - pull hairline                           512        128       \nForehead - scratch                                 512        128       \nGlasses on/off                                     129        32        \nNeck - pinch skin                                  512        128       \nNeck - scratch                                     512        128       \nPinch knee/leg skin                                129        32        \nPull air toward your face                          382        95        \nScratch knee/leg skin                              129        32        \nText on phone                                      512        128       \nWave hello                                         383        95        \nWrite name in air                                  381        96        \nWrite name on leg                                  129        32        \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# predict_2\n\ndef predict2(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    imu, thm, tof = dataset.full_dataset.inference_process(sequence)\n    with torch.no_grad():\n        imu, thm, tof = to_cuda(imu, thm, tof)\n        logits = avg_predict(models2, imu, thm, tof)\n        probabilities = F.softmax(logits, dim=1).cpu().numpy()\n    return probabilities # logits.cpu().numpy()\n    # return dataset.le.classes_[logits.argmax(dim=1).cpu()]","metadata":{"_cell_guid":"4ec7ba83-bd38-4944-acc5-c569d0b22991","_uuid":"9ee5932b-ffff-47c4-b5b3-abb1efdfab5c","execution":{"iopub.status.busy":"2025-08-13T02:56:33.067370Z","iopub.execute_input":"2025-08-13T02:56:33.067624Z","iopub.status.idle":"2025-08-13T02:56:33.072671Z","shell.execute_reply.started":"2025-08-13T02:56:33.067604Z","shell.execute_reply":"2025-08-13T02:56:33.071873Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.011687,"end_time":"2025-07-25T09:36:09.27422","exception":false,"start_time":"2025-07-25T09:36:09.262533","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Model_3","metadata":{"_cell_guid":"395b6b7b-0575-4570-9835-c8f7598b30cf","_uuid":"12e1abaa-c410-43c2-9d09-cb25e7a3a6c0","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.005147,"end_time":"2025-07-25T09:36:09.285098","exception":false,"start_time":"2025-07-25T09:36:09.279951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"gated-gru-hybrid-ensemble-v02.ipynb\n\nAutomatically generated by Colab.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/15f-PUIU6Tc6qYWYP6g7trekz1LypFFwW\n\"\"\"\n\nimport os\nimport json\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport warnings\nimport random\nimport math\nimport matplotlib.pyplot as plt\nimport polars as pl\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, GRU, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate\n)\nfrom tensorflow.keras.optimizers import Adam as AdamTF\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers.schedules import CosineDecay\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam as AdamTorch\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom scipy.spatial.transform import Rotation as R\nfrom scipy.signal import firwin\n\n# 評価メトリクスはローカル検証/学習時にのみインポート\ntry:\n    from cmi_2025_metric_copy_for_import import CompetitionMetric\nexcept ImportError:\n    CompetitionMetric = None\n    print(\"CompetitionMetric could not be imported. OOF/CV score will not be calculated.\")\n\ndef seed_everything(seed=42):\n    \"\"\"\n    実行環境の乱数シードを統一的に設定する関数。\n    \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(2025)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    # torch.backends.cudnn.deterministic = True # パフォーマンスが低下する可能性があるためコメントアウト\n    # torch.backends.cudnn.benchmark = False\n\nseed_everything(seed=42)\nwarnings.filterwarnings(\"ignore\")\n\nTRAIN = False\n\n# --- パス設定 ---\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\n# YOUR_MODELS_DIRは自分の学習済みモデルが格納されているKaggleデータセットのパスに設定してください\nYOUR_MODELS_DIR = Path(\"/kaggle/input/cmi-data-gated-gru\") # ★★★ 自分のモデルパスに変更 ★★★\nPUBLIC_TF_MODEL_DIR = Path(\"/kaggle/input/lb-0-78-quaternions-tf-bilstm-gru-attention\")\nPUBLIC_PT_MODEL_DIR = Path(\"/kaggle/input/cmi3-models-p\")\nEXPORT_DIR = Path(\"./\") # 学習済みモデルやアーティファクトの保存先\n\n# --- モデル学習ハイパーパラメータ ---\nBATCH_SIZE = 64          # バッチサイズ\nPAD_PERCENTILE = 95      # シーケンス長のパディングを決めるためのパーセンタイル値\nLR_INIT = 4e-4           # 学習率の初期値 (微調整)\nWD = 3e-3                # Weight Decay（L2正則化）の係数\nMIXUP_ALPHA = 0.4        # Mixupのα値\nEPOCHS = 360             # 最大エポック数 (増加)\nPATIENCE = 50            # EarlyStoppingのpatience (増加)\nN_SPLITS = 10             # クロスバリデーションの分割数\nMASKING_PROB = 0.25      # 学習時にTOF/THMデータをマスクする確率\nGATE_LOSS_WEIGHT = 0.2   # Gatedモデルのゲート損失に対する重み\n\nprint(f\"▶ ライブラリのインポート完了\")\nprint(f\"  - TensorFlow: {tf.__version__}\")\nprint(f\"  - PyTorch: {torch.__version__}\")\nprint(f\"▶ TRAINモード: {TRAIN}\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# PyTorchモデル用の標準化パラメータ\nmean_pt = torch.tensor([\n    0, 0, 0, 0, 0, 0, 9.0319e-03, 1.0849e+00, -2.6186e-03, 3.7651e-03,\n    -5.3660e-03, -2.8177e-03, 1.3318e-03, -1.5876e-04, 6.3495e-01,\n    6.2877e-01, 6.0607e-01, 6.2142e-01, 6.3808e-01, 6.5420e-01,\n    7.4102e-03, -3.4159e-03, -7.5237e-03, -2.6034e-02, 2.9704e-02,\n    -3.1546e-02, -2.0610e-03, -4.6986e-03, -4.7216e-03, -2.6281e-02,\n    1.5799e-02, 1.0016e-02\n], dtype=torch.float32).view(1, -1, 1).to(device)\n\nstd_pt = torch.tensor([\n    1, 1, 1, 1, 1, 1, 0.2067, 0.8583, 0.3162,\n    0.2668, 0.2917, 0.2341, 0.3023, 0.3281, 1.0264, 0.8838, 0.8686, 1.0973,\n    1.0267, 0.9018, 0.4658, 0.2009, 0.2057, 1.2240, 0.9535, 0.6655, 0.2941,\n    0.3421, 0.8156, 0.6565, 1.1034, 1.5577\n], dtype=torch.float32).view(1, -1, 1).to(device) + 1e-8\n\nclass ImuFeatureExtractor(nn.Module):\n    \"\"\"\n    ★★★ PyTorchモデル用の特徴量抽出器 ★★★\n    公開モデルの重みと一致させるため、元の正しい定義に修正。\n    \"\"\"\n    def __init__(self, fs=100., add_quaternion=False):\n        super().__init__()\n        self.fs = fs\n        self.add_quaternion = add_quaternion\n\n        k = 15\n\n        # ▼▼▼【ここが修正点】▼▼▼\n        # 公開モデルの重みファイルに存在する 'self.lpf' 層を再度追加する\n        self.lpf = nn.Conv1d(6, 6, kernel_size=k, padding=k//2,\n                                 groups=6, bias=False)\n        nn.init.kaiming_uniform_(self.lpf.weight, a=math.sqrt(5))\n        # ▲▲▲【ここまでが修正点】▲▲▲\n\n        self.lpf_acc  = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n        self.lpf_gyro = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n\n    def forward(self, imu):\n        acc  = imu[:, 0:3, :]\n        gyro = imu[:, 3:6, :]\n\n        # 1) magnitude\n        acc_mag  = torch.norm(acc,  dim=1, keepdim=True)\n        gyro_mag = torch.norm(gyro, dim=1, keepdim=True)\n\n        # 2) jerk\n        jerk = F.pad(acc[:, :, 1:] - acc[:, :, :-1], (1,0))\n        gyro_delta = F.pad(gyro[:, :, 1:] - gyro[:, :, :-1], (1,0))\n\n        # 3) energy\n        acc_pow  = acc ** 2\n        gyro_pow = gyro ** 2\n\n        # 4) LPF / HPF\n        # self.lpf は forwardパスでは使われていないが、重み読み込みのために定義が必要\n        acc_lpf  = self.lpf_acc(acc)\n        acc_hpf  = acc - acc_lpf\n        gyro_lpf = self.lpf_gyro(gyro)\n        gyro_hpf = gyro - gyro_lpf\n\n        features = [\n            acc, gyro,\n            acc_mag, gyro_mag,\n            jerk, gyro_delta,\n            acc_pow, gyro_pow,\n            acc_lpf, acc_hpf,\n            gyro_lpf, gyro_hpf,\n        ]\n        return torch.cat(features, dim=1)\n\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=8):\n        super().__init__()\n        self.squeeze = nn.AdaptiveAvgPool1d(1)\n        self.excitation = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False), nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False), nn.Sigmoid()\n        )\n    def forward(self, x):\n        b, c, _ = x.size()\n        y = self.squeeze(x).view(b, c)\n        y = self.excitation(y).view(b, c, 1)\n        return x * y.expand_as(x)\n\nclass ResidualSECNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, pool_size=2, dropout=0.3):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        self.se = SEBlock(out_channels)\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(nn.Conv1d(in_channels, out_channels, 1, bias=False), nn.BatchNorm1d(out_channels))\n        self.pool = nn.MaxPool1d(pool_size)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.se(out)\n        out += self.shortcut(x)\n        return self.dropout(self.pool(F.relu(out)))\n\nclass AttentionLayer(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.attention = nn.Linear(hidden_dim, 1)\n    def forward(self, x):\n        scores = torch.tanh(self.attention(x))\n        weights = F.softmax(scores.squeeze(-1), dim=1)\n        return torch.sum(x * weights.unsqueeze(-1), dim=1)\n\nclass TwoBranchModel(nn.Module):\n    def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], feature_engineering=True, **kwargs):\n        super().__init__()\n        self.feature_engineering = feature_engineering\n        imu_dim = 32 if feature_engineering else imu_dim_raw\n        self.imu_fe = ImuFeatureExtractor(**kwargs) if feature_engineering else nn.Identity()\n        self.fir_nchan = 7\n        numtaps = 33\n        fir_kernel = torch.tensor(firwin(numtaps, cutoff=1.0, fs=10.0, pass_zero=False), dtype=torch.float32).view(1, 1, -1).repeat(self.fir_nchan, 1, 1)\n        self.register_buffer(\"fir_kernel\", fir_kernel)\n        self.imu_block1 = ResidualSECNNBlock(imu_dim, 64, 3, dropout=dropouts[0])\n        self.imu_block2 = ResidualSECNNBlock(64, 128, 5, dropout=dropouts[1])\n        self.tof_conv1 = nn.Conv1d(tof_dim, 64, 3, padding=1, bias=False)\n        self.tof_bn1, self.tof_pool1, self.tof_drop1 = nn.BatchNorm1d(64), nn.MaxPool1d(2), nn.Dropout(dropouts[2])\n        self.tof_conv2 = nn.Conv1d(64, 128, 3, padding=1, bias=False)\n        self.tof_bn2, self.tof_pool2, self.tof_drop2 = nn.BatchNorm1d(128), nn.MaxPool1d(2), nn.Dropout(dropouts[3])\n        self.bilstm = nn.LSTM(256, 128, bidirectional=True, batch_first=True)\n        self.lstm_dropout = nn.Dropout(dropouts[4])\n        self.attention = AttentionLayer(256)\n        self.dense1, self.bn_dense1, self.drop1 = nn.Linear(256, 256, bias=False), nn.BatchNorm1d(256), nn.Dropout(dropouts[5])\n        self.dense2, self.bn_dense2, self.drop2 = nn.Linear(256, 128, bias=False), nn.BatchNorm1d(128), nn.Dropout(dropouts[6])\n        self.classifier = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        imu_raw = x[:, :, :self.fir_nchan].transpose(1, 2)\n        tof = x[:, :, self.fir_nchan:].transpose(1, 2)\n        imu_fe = self.imu_fe(imu_raw)\n        filtered = F.conv1d(imu_fe[:, :self.fir_nchan, :], self.fir_kernel, padding=self.fir_kernel.shape[-1] // 2, groups=self.fir_nchan)\n        imu = (torch.cat([filtered, imu_fe[:, self.fir_nchan:, :]], dim=1) - mean_pt) / std_pt\n        x1 = self.imu_block1(imu); x1 = self.imu_block2(x1)\n        x2 = self.tof_drop1(self.tof_pool1(F.relu(self.tof_bn1(self.tof_conv1(tof)))))\n        x2 = self.tof_drop2(self.tof_pool2(F.relu(self.tof_bn2(self.tof_conv2(x2)))))\n        merged = torch.cat([x1, x2], dim=1).transpose(1, 2)\n        lstm_out, _ = self.bilstm(merged); lstm_out = self.lstm_dropout(lstm_out)\n        attended = self.attention(lstm_out)\n        x = self.drop1(F.relu(self.bn_dense1(self.dense1(attended))))\n        x = self.drop2(F.relu(self.bn_dense2(self.dense2(x))))\n        return self.classifier(x)\n\nclass PublicTwoBranchModel(nn.Module):\n    \"\"\"\n    ★★★ 公開されているPyTorchモデル（モデル群C）を読み込むための、元のアーキテクチャを持つクラス ★★★\n    \"\"\"\n    def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], feature_engineering=True, **kwargs):\n        super().__init__()\n        self.feature_engineering = feature_engineering\n        imu_dim = 32 if feature_engineering else imu_dim_raw\n        self.imu_fe = ImuFeatureExtractor(**kwargs) if feature_engineering else nn.Identity()\n        self.fir_nchan = 7\n        numtaps = 33\n        fir_kernel = torch.tensor(firwin(numtaps, cutoff=1.0, fs=10.0, pass_zero=False), dtype=torch.float32).view(1, 1, -1).repeat(self.fir_nchan, 1, 1)\n        self.register_buffer(\"fir_kernel\", fir_kernel)\n        self.imu_block1 = ResidualSECNNBlock(imu_dim, 64, 3, dropout=dropouts[0])\n        self.imu_block2 = ResidualSECNNBlock(64, 128, 5, dropout=dropouts[1])\n        self.tof_conv1 = nn.Conv1d(tof_dim, 64, 3, padding=1, bias=False)\n        self.tof_bn1, self.tof_pool1, self.tof_drop1 = nn.BatchNorm1d(64), nn.MaxPool1d(2), nn.Dropout(dropouts[2])\n        self.tof_conv2 = nn.Conv1d(64, 128, 3, padding=1, bias=False)\n        self.tof_bn2, self.tof_pool2, self.tof_drop2 = nn.BatchNorm1d(128), nn.MaxPool1d(2), nn.Dropout(dropouts[3])\n        self.bilstm = nn.LSTM(256, 128, bidirectional=True, batch_first=True) # GRUではなくLSTM\n        self.lstm_dropout = nn.Dropout(dropouts[4])\n        self.attention = AttentionLayer(256) # 128*2 for bidirectional\n        self.dense1, self.bn_dense1, self.drop1 = nn.Linear(256, 256, bias=False), nn.BatchNorm1d(256), nn.Dropout(dropouts[5])\n        self.dense2, self.bn_dense2, self.drop2 = nn.Linear(256, 128, bias=False), nn.BatchNorm1d(128), nn.Dropout(dropouts[6])\n        self.classifier = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        imu_raw = x[:, :, :self.fir_nchan].transpose(1, 2)\n        tof = x[:, :, self.fir_nchan:].transpose(1, 2)\n        imu_fe = self.imu_fe(imu_raw)\n        filtered = F.conv1d(imu_fe[:, :self.fir_nchan, :], self.fir_kernel, padding=self.fir_kernel.shape[-1] // 2, groups=self.fir_nchan)\n        # mean_pt, std_pt は事前に定義されているグローバル変数\n        imu = (torch.cat([filtered, imu_fe[:, self.fir_nchan:, :]], dim=1) - mean_pt) / std_pt\n        x1 = self.imu_block1(imu); x1 = self.imu_block2(x1)\n        x2 = self.tof_drop1(self.tof_pool1(F.relu(self.tof_bn1(self.tof_conv1(tof)))))\n        x2 = self.tof_drop2(self.tof_pool2(F.relu(self.tof_bn2(self.tof_conv2(x2)))))\n        merged = torch.cat([x1, x2], dim=1).transpose(1, 2)\n        lstm_out, _ = self.bilstm(merged); lstm_out = self.lstm_dropout(lstm_out)\n        attended = self.attention(lstm_out)\n        x = self.drop1(F.relu(self.bn_dense1(self.dense1(attended))))\n        x = self.drop2(F.relu(self.bn_dense2(self.dense2(x))))\n        return self.classifier(x)\n\ndef pad_sequences_torch3(sequences, maxlen, padding='post', truncating='post', value=0.0):\n    result = []\n    for seq in sequences:\n        if len(seq) >= maxlen: seq = seq[:maxlen] if truncating == 'post' else seq[-maxlen:]\n        else:\n            pad_len = maxlen - len(seq)\n            pad_array = np.full((pad_len, seq.shape[1]), value)\n            seq = np.concatenate([seq, pad_array]) if padding == 'post' else np.concatenate([pad_array, seq])\n        result.append(seq)\n    return np.array(result, dtype=np.float32)\n\n# =============================================================================\n# ## 特徴量エンジニアリング関数\n# =============================================================================\ndef remove_gravity_from_acc3(acc_data, rot_data):\n    \"\"\"加速度データから重力成分を除去する\"\"\"\n    acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    linear_accel = np.zeros_like(acc_values)\n    gravity_world = np.array([0, 0, 9.81])\n    for i in range(len(acc_values)):\n        if np.all(np.isnan(quat_values[i])):\n            linear_accel[i, :] = acc_values[i, :]\n            continue\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except (ValueError, IndexError):\n            linear_accel[i, :] = acc_values[i, :]\n    return linear_accel\n\ndef calculate_angular_velocity_from_quat3(rot_data, time_delta=1/200):\n    \"\"\"クォータニオンから角速度を計算する\"\"\"\n    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    angular_vel = np.zeros((len(quat_values), 3))\n    for i in range(len(quat_values) - 1):\n        q_t, q_t_plus_dt = quat_values[i], quat_values[i+1]\n        if np.all(np.isnan(q_t)) or np.all(np.isnan(q_t_plus_dt)): continue\n        try:\n            rot_t = R.from_quat(q_t)\n            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n            delta_rot = rot_t.inv() * rot_t_plus_dt\n            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n        except (ValueError, IndexError): pass\n    return angular_vel\n\ndef calculate_angular_distance3(rot_data):\n    \"\"\"クォータニオンから角距離を計算する\"\"\"\n    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    angular_dist = np.zeros(len(quat_values))\n    for i in range(len(quat_values) - 1):\n        q1, q2 = quat_values[i], quat_values[i+1]\n        if np.all(np.isnan(q1)) or np.all(np.isnan(q2)): continue\n        try:\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n            relative_rotation = r1.inv() * r2\n            angular_dist[i] = np.linalg.norm(relative_rotation.as_rotvec())\n        except (ValueError, IndexError): pass\n    return angular_dist\n\ndef time_sum(x): return K.sum(x, axis=1)\ndef squeeze_last_axis(x): return tf.squeeze(x, axis=-1)\ndef expand_last_axis(x): return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    \"\"\"Squeeze-and-Excitationブロック\"\"\"\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    \"\"\"Residual SE-CNNブロック\"\"\"\n    shortcut = x\n    # 2層のConv1D\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    # SEブロック\n    x = se_block(x)\n    # ショートカット接続\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False, kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    \"\"\"アテンション層\"\"\"\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context\n\nclass GatedMixupGenerator(Sequence):\n    \"\"\"Mixupとセンサーマスキングを適用するデータジェネレータ\"\"\"\n    def __init__(self, X, y, batch_size, imu_dim, class_weight=None, alpha=0.2, masking_prob=0.0):\n        self.X, self.y, self.batch, self.imu_dim = X, y, batch_size, imu_dim\n        self.class_weight, self.alpha, self.masking_prob = class_weight, alpha, masking_prob\n        self.indices = np.arange(len(X))\n\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx].copy(), self.y[idx].copy()\n\n        sample_weights = np.ones(len(Xb), dtype='float32')\n        if self.class_weight:\n            sample_weights = np.array([self.class_weight.get(i, 1.0) for i in yb.argmax(axis=1)])\n\n        gate_target = np.ones(len(Xb), dtype='float32')\n        if self.masking_prob > 0:\n            for j in range(len(Xb)):\n                if np.random.rand() < self.masking_prob:\n                    Xb[j, :, self.imu_dim:] = 0\n                    gate_target[j] = 0.0\n\n        if self.alpha > 0:\n            lam = np.random.beta(self.alpha, self.alpha)\n            perm = np.random.permutation(len(Xb))\n            X_mix = lam * Xb + (1 - lam) * Xb[perm]\n            y_mix = lam * yb + (1 - lam) * yb[perm]\n            gate_target_mix = lam * gate_target + (1 - lam) * gate_target[perm]\n            sample_weights_mix = lam * sample_weights + (1 - lam) * sample_weights[perm]\n            return X_mix, {'main_output': y_mix, 'tof_gate': gate_target_mix}, sample_weights_mix\n\n        return Xb, {'main_output': yb, 'tof_gate': gate_target}, sample_weights\n\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)\n\ndef build_gated_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    \"\"\"\n    自作のGated Two-Branchモデルを構築する関数。\n    [改良点] LSTMをGRUに変更、全結合層を1層追加。\n    \"\"\"\n    inp = Input(shape=(pad_len, imu_dim + tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMUブランチ (Deep)\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n\n    # TOF/THMブランチ (Light) with Gating\n    x2_base = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n    x2_base = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2_base)\n    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n\n    # Gating機構\n    gate_input = GlobalAveragePooling1D()(tof)\n    gate_input = Dense(16, activation='relu')(gate_input)\n    gate = Dense(1, activation='sigmoid', name='tof_gate')(gate_input)\n    x2 = Multiply()([x2_base, gate])\n\n    # ブランチのマージと後続層\n    merged = Concatenate()([x1, x2])\n    # ★改良点: LSTM -> GRU\n    x = Bidirectional(GRU(256, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    x = Dropout(0.45)(x)\n    x = attention_layer(x)\n\n    # ★改良点: 全結合層を1層追加して表現力を向上\n    for units, drop in [(512, 0.5), (256, 0.4), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n\n    return Model(inputs=inp, outputs=[out, gate])\n\n# -----------------------------------------------------------------------------\n# ### 推論モード (`TRAIN = False`)\n# -----------------------------------------------------------------------------\n\nprint(\"▶ 推論モード開始 – 学習済みモデルとアーティファクトを読み込みます...\")\n\n# --- モデル群A (自作TF/Kerasモデル) の読み込み ---\nprint(\"  モデル群A (自作5-Fold Gated GRUモデル) を読み込み中...\")\nfinal_feature_cols_A = np.load(YOUR_MODELS_DIR / \"final_feature_cols.npy\", allow_pickle=True).tolist()\npad_len_A = int(np.load(YOUR_MODELS_DIR / \"sequence_maxlen.npy\"))\nscaler_A = joblib.load(YOUR_MODELS_DIR / \"scaler.pkl\")\ngesture_classes = np.load(YOUR_MODELS_DIR / \"gesture_classes.npy\", allow_pickle=True)\ncustom_objs_A = {'time_sum': time_sum, 'squeeze_last_axis': squeeze_last_axis, 'expand_last_axis': expand_last_axis,\n                 'se_block': se_block, 'residual_se_cnn_block': residual_se_cnn_block, 'attention_layer': attention_layer}\nmodels_A = [load_model(YOUR_MODELS_DIR / f\"final_model_fold_{f}.h5\", compile=False, custom_objects=custom_objs_A) for f in range(N_SPLITS)]\nprint(f\"  > {len(models_A)}個のモデルを正常に読み込みました。\")\n\n# --- モデル群B (公開TF/Kerasモデル) の読み込み ---\nprint(\"\\n  モデル群B (公開TF/Kerasモデル) を読み込み中...\")\nfinal_feature_cols_B = np.load(PUBLIC_TF_MODEL_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\npad_len_B = int(np.load(PUBLIC_TF_MODEL_DIR / \"sequence_maxlen.npy\"))\nscaler_B = joblib.load(PUBLIC_TF_MODEL_DIR / \"scaler.pkl\")\ncustom_objs_B = custom_objs_A # public modelも同じカスタムオブジェクトを使用\nmodel_B = load_model(PUBLIC_TF_MODEL_DIR / \"gesture_two_branch_mixup.h5\", compile=False, custom_objects=custom_objs_B)\nprint(\"  > 1個のモデルを正常に読み込みました。\")\n\n# --- モデル群C (公開PyTorchモデル) の読み込み ---\nprint(\"\\n  モデル群C (公開PyTorchモデル) を読み込み中...\")\nfinal_feature_cols_C = np.load(PUBLIC_PT_MODEL_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\npad_len_C = int(np.load(PUBLIC_PT_MODEL_DIR / \"sequence_maxlen.npy\"))\nscaler_C = joblib.load(PUBLIC_PT_MODEL_DIR / \"scaler.pkl\")\n\npt_models = []\nfor f in range(5):\n    checkpoint = torch.load(PUBLIC_PT_MODEL_DIR / f\"gesture_two_branch_fold{f}.pth\", map_location=device)\n    cfg = {'pad_len': checkpoint['pad_len'], 'imu_dim_raw': checkpoint['imu_dim'],\n           'tof_dim': checkpoint['tof_dim'], 'n_classes': checkpoint['n_classes']}\n    m = PublicTwoBranchModel(**cfg).to(device)\n    m.load_state_dict(checkpoint['model_state_dict'])\n    m.eval()\n    pt_models.append(m)\nprint(f\"  > {len(pt_models)}個のモデルを正常に読み込みました。\")","metadata":{"execution":{"iopub.status.busy":"2025-08-13T02:56:33.073908Z","iopub.execute_input":"2025-08-13T02:56:33.074140Z","iopub.status.idle":"2025-08-13T02:56:40.398719Z","shell.execute_reply.started":"2025-08-13T02:56:33.074123Z","shell.execute_reply":"2025-08-13T02:56:40.397914Z"},"papermill":{"duration":6.187024,"end_time":"2025-07-25T09:36:15.477351","exception":false,"start_time":"2025-07-25T09:36:09.290327","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"▶ ライブラリのインポート完了\n  - TensorFlow: 2.18.0\n  - PyTorch: 2.6.0+cu124\n▶ TRAINモード: False\n▶ 推論モード開始 – 学習済みモデルとアーティファクトを読み込みます...\n  モデル群A (自作5-Fold Gated GRUモデル) を読み込み中...\n  > 10個のモデルを正常に読み込みました。\n\n  モデル群B (公開TF/Kerasモデル) を読み込み中...\n  > 1個のモデルを正常に読み込みました。\n\n  モデル群C (公開PyTorchモデル) を読み込み中...\n  > 5個のモデルを正常に読み込みました。\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# predict_3\n\n# --- `predict`関数の定義 ---\ndef predict3(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    df_seq_orig = sequence.to_pandas()\n    df_seq_A = df_seq_orig.copy()\n    \n    linear_accel_A = remove_gravity_from_acc3(df_seq_A[['acc_x','acc_y','acc_z']], df_seq_A[['rot_x','rot_y','rot_z','rot_w']])\n    df_seq_A['linear_acc_x'], df_seq_A['linear_acc_y'], df_seq_A['linear_acc_z'] = linear_accel_A[:,0], linear_accel_A[:,1], linear_accel_A[:,2]\n    df_seq_A['linear_acc_mag'] = np.linalg.norm(linear_accel_A, axis=1)\n    df_seq_A['linear_acc_mag_jerk'] = df_seq_A['linear_acc_mag'].diff().fillna(0)\n    angular_vel_A = calculate_angular_velocity_from_quat3(df_seq_A[['rot_x','rot_y','rot_z','rot_w']])\n    df_seq_A['angular_vel_x'], df_seq_A['angular_vel_y'], df_seq_A['angular_vel_z'] = angular_vel_A[:,0], angular_vel_A[:,1], angular_vel_A[:,2]\n    df_seq_A['angular_distance'] = calculate_angular_distance3(df_seq_A[['rot_x','rot_y','rot_z','rot_w']])\n    for col in ['rot_x', 'rot_y', 'rot_z', 'rot_w']:\n        df_seq_A[f'{col}_diff'] = df_seq_A[col].diff().fillna(0)\n    cols_for_stats=['linear_acc_mag','linear_acc_mag_jerk','angular_distance']\n    for col in cols_for_stats:\n        df_seq_A[f'{col}_skew'], df_seq_A[f'{col}_kurt'] = df_seq_A[col].skew(), df_seq_A[col].kurtosis()\n    for i in range(1,6):\n        if f'tof_{i}_v0' in df_seq_A.columns:\n            pixel_cols=[f\"tof_{i}_v{p}\" for p in range(64)]; tof_data=df_seq_A[pixel_cols].replace(-1,np.nan)\n            df_seq_A[f'tof_{i}_mean'], df_seq_A[f'tof_{i}_std'], df_seq_A[f'tof_{i}_min'], df_seq_A[f'tof_{i}_max'] = tof_data.mean(axis=1),tof_data.std(axis=1),tof_data.min(axis=1),tof_data.max(axis=1)\n    tof_mean_cols=[f'tof_{i}_mean' for i in range(1,6) if f'tof_{i}_mean' in df_seq_A.columns]\n    if tof_mean_cols:\n        df_seq_A['tof_std_across_sensors']=df_seq_A[tof_mean_cols].std(axis=1)\n        df_seq_A['tof_range_across_sensors']=df_seq_A[tof_mean_cols].max(axis=1)-df_seq_A[tof_mean_cols].min(axis=1)\n    thm_cols=[f'thm_{i}' for i in range(1,6) if f'thm_{i}' in df_seq_A.columns]\n    if thm_cols:\n        df_seq_A['thm_std_across_sensors']=df_seq_A[thm_cols].std(axis=1)\n        df_seq_A['thm_range_across_sensors']=df_seq_A[thm_cols].max(axis=1)-df_seq_A[thm_cols].min(axis=1)\n    # (推論 A)\n    mat_A = df_seq_A[final_feature_cols_A].ffill().bfill().fillna(0).values.astype('float32')\n    mat_A = scaler_A.transform(mat_A)\n    pad_input_A = pad_sequences([mat_A], maxlen=pad_len_A, padding='post', dtype='float32')\n    preds_A_folds = [model.predict(pad_input_A, verbose=0)[0] for model in models_A]\n    avg_pred_A = np.mean(preds_A_folds, axis=0)\n\n    # --- 2. モデル群B (公開TFモデル) の予測 ---\n    df_seq_B = df_seq_orig.copy()\n    # (特徴量生成 B)\n    df_seq_B['acc_mag']=np.sqrt(df_seq_B['acc_x']**2+df_seq_B['acc_y']**2+df_seq_B['acc_z']**2)\n    df_seq_B['rot_angle']=2*np.arccos(df_seq_B['rot_w'].clip(-1,1))\n    df_seq_B['acc_mag_jerk']=df_seq_B['acc_mag'].diff().fillna(0)\n    df_seq_B['rot_angle_vel']=df_seq_B['rot_angle'].diff().fillna(0)\n    linear_accel_B=remove_gravity_from_acc3(df_seq_B,df_seq_B)\n    df_seq_B['linear_acc_x'],df_seq_B['linear_acc_y'],df_seq_B['linear_acc_z']=linear_accel_B[:,0],linear_accel_B[:,1],linear_accel_B[:,2]\n    df_seq_B['linear_acc_mag']=np.sqrt(df_seq_B['linear_acc_x']**2+df_seq_B['linear_acc_y']**2+df_seq_B['linear_acc_z']**2)\n    df_seq_B['linear_acc_mag_jerk']=df_seq_B['linear_acc_mag'].diff().fillna(0)\n    angular_vel_B=calculate_angular_velocity_from_quat3(df_seq_B)\n    df_seq_B['angular_vel_x'],df_seq_B['angular_vel_y'],df_seq_B['angular_vel_z']=angular_vel_B[:,0],angular_vel_B[:,1],angular_vel_B[:,2]\n    df_seq_B['angular_distance']=calculate_angular_distance3(df_seq_B)\n    for i in range(1,6):\n        if f'tof_{i}_v0' in df_seq_B.columns:\n            pixel_cols=[f\"tof_{i}_v{p}\" for p in range(64)]; tof_data=df_seq_B[pixel_cols].replace(-1,np.nan)\n            df_seq_B[f\"tof_{i}_mean\"],df_seq_B[f\"tof_{i}_std\"],df_seq_B[f\"tof_{i}_min\"],df_seq_B[f\"tof_{i}_max\"]=tof_data.mean(axis=1),tof_data.std(axis=1),tof_data.min(axis=1),tof_data.max(axis=1)\n    # (推論 B)\n    mat_B = df_seq_B[final_feature_cols_B].ffill().bfill().fillna(0).values.astype('float32')\n    mat_B = scaler_B.transform(mat_B)\n    pad_input_B = pad_sequences([mat_B], maxlen=pad_len_B, padding='post', dtype='float32')\n    pred_B = model_B.predict(pad_input_B, verbose=0)\n    if isinstance(pred_B, list): pred_B = pred_B[0]\n\n    # --- 3. モデル群C (公開PyTorchモデル) の予測 ---\n    df_seq_C = df_seq_orig.copy() # Cは特徴量生成が不要なため、コピーのみ\n    mat_C = df_seq_C[final_feature_cols_C].ffill().bfill().fillna(0).values.astype('float32')\n    mat_C = scaler_C.transform(mat_C)\n    pad_input_C = pad_sequences_torch3([mat_C], maxlen=pad_len_C, padding='pre', truncating='pre')\n    with torch.no_grad():\n        pt_input = torch.from_numpy(pad_input_C).to(device)\n        preds_C_folds = [model(pt_input) for model in pt_models]\n        avg_pred_C_logits = torch.mean(torch.stack(preds_C_folds), dim=0)\n        avg_pred_C = torch.softmax(avg_pred_C_logits, dim=1).cpu().numpy()\n\n    # --- 4. 加重平均による最終決定 ---\n\n    weights = {'A': 0.60, 'B': 0.15, 'C': 0.25}\n\n    final_pred_proba = (weights['A'] * avg_pred_A + weights['B'] * pred_B + weights['C'] * avg_pred_C)\n\n    return final_pred_proba","metadata":{"execution":{"iopub.status.busy":"2025-08-13T02:56:40.399652Z","iopub.execute_input":"2025-08-13T02:56:40.400192Z","iopub.status.idle":"2025-08-13T02:56:40.419300Z","shell.execute_reply.started":"2025-08-13T02:56:40.400173Z","shell.execute_reply":"2025-08-13T02:56:40.418701Z"},"papermill":{"duration":0.027888,"end_time":"2025-07-25T09:36:15.511527","exception":false,"start_time":"2025-07-25T09:36:15.483639","status":"completed"},"tags":[],"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Model_4","metadata":{}},{"cell_type":"code","source":"\"\"\"gated-gru-hybrid-ensemble-v02.ipynb\n\nAutomatically generated by Colab.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/15f-PUIU6Tc6qYWYP6g7trekz1LypFFwW\n\"\"\"\n\nimport os\nimport json\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport warnings\nimport random\nimport math\nimport matplotlib.pyplot as plt\nimport polars as pl\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, GRU, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate\n)\nfrom tensorflow.keras.optimizers import Adam as AdamTF\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers.schedules import CosineDecay\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam as AdamTorch\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom scipy.spatial.transform import Rotation as R\nfrom scipy.signal import firwin\n\n# 評価メトリクスはローカル検証/学習時にのみインポート\ntry:\n    from cmi_2025_metric_copy_for_import import CompetitionMetric\nexcept ImportError:\n    CompetitionMetric = None\n    print(\"CompetitionMetric could not be imported. OOF/CV score will not be calculated.\")\n\ndef seed_everything(seed=42):\n    \"\"\"\n    実行環境の乱数シードを統一的に設定する関数。\n    \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(2025)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    # torch.backends.cudnn.deterministic = True # パフォーマンスが低下する可能性があるためコメントアウト\n    # torch.backends.cudnn.benchmark = False\n\nseed_everything(seed=42)\nwarnings.filterwarnings(\"ignore\")\n\nTRAIN = False\n\n# --- パス設定 ---\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\n# YOUR_MODELS_DIRは自分の学習済みモデルが格納されているKaggleデータセットのパスに設定してください\nYOUR_MODELS_DIR = Path(\"/kaggle/input/cmi-data-gated-gru\") # ★★★ 自分のモデルパスに変更 ★★★\nPUBLIC_TF_MODEL_DIR = Path(\"/kaggle/input/lb-0-78-quaternions-tf-bilstm-gru-attention\")\nPUBLIC_PT_MODEL_DIR = Path(\"/kaggle/input/cmi3-models-p\")\nEXPORT_DIR = Path(\"./\") # 学習済みモデルやアーティファクトの保存先\n\n# --- モデル学習ハイパーパラメータ ---\nBATCH_SIZE = 64          # バッチサイズ\nPAD_PERCENTILE = 95      # シーケンス長のパディングを決めるためのパーセンタイル値\nLR_INIT = 4e-4           # 学習率の初期値 (微調整)\nWD = 3e-3                # Weight Decay（L2正則化）の係数\nMIXUP_ALPHA = 0.4        # Mixupのα値\nEPOCHS = 360             # 最大エポック数 (増加)\nPATIENCE = 50            # EarlyStoppingのpatience (増加)\nN_SPLITS = 10             # クロスバリデーションの分割数\nMASKING_PROB = 0.25      # 学習時にTOF/THMデータをマスクする確率\nGATE_LOSS_WEIGHT = 0.2   # Gatedモデルのゲート損失に対する重み\n\nprint(f\"▶ ライブラリのインポート完了\")\nprint(f\"  - TensorFlow: {tf.__version__}\")\nprint(f\"  - PyTorch: {torch.__version__}\")\nprint(f\"▶ TRAINモード: {TRAIN}\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# PyTorchモデル用の標準化パラメータ\nmean_pt = torch.tensor([\n    0, 0, 0, 0, 0, 0, 9.0319e-03, 1.0849e+00, -2.6186e-03, 3.7651e-03,\n    -5.3660e-03, -2.8177e-03, 1.3318e-03, -1.5876e-04, 6.3495e-01,\n    6.2877e-01, 6.0607e-01, 6.2142e-01, 6.3808e-01, 6.5420e-01,\n    7.4102e-03, -3.4159e-03, -7.5237e-03, -2.6034e-02, 2.9704e-02,\n    -3.1546e-02, -2.0610e-03, -4.6986e-03, -4.7216e-03, -2.6281e-02,\n    1.5799e-02, 1.0016e-02\n], dtype=torch.float32).view(1, -1, 1).to(device)\n\nstd_pt = torch.tensor([\n    1, 1, 1, 1, 1, 1, 0.2067, 0.8583, 0.3162,\n    0.2668, 0.2917, 0.2341, 0.3023, 0.3281, 1.0264, 0.8838, 0.8686, 1.0973,\n    1.0267, 0.9018, 0.4658, 0.2009, 0.2057, 1.2240, 0.9535, 0.6655, 0.2941,\n    0.3421, 0.8156, 0.6565, 1.1034, 1.5577\n], dtype=torch.float32).view(1, -1, 1).to(device) + 1e-8\n\nclass ImuFeatureExtractor(nn.Module):\n    \"\"\"\n    ★★★ PyTorchモデル用の特徴量抽出器 ★★★\n    公開モデルの重みと一致させるため、元の正しい定義に修正。\n    \"\"\"\n    def __init__(self, fs=100., add_quaternion=False):\n        super().__init__()\n        self.fs = fs\n        self.add_quaternion = add_quaternion\n\n        k = 15\n\n        # ▼▼▼【ここが修正点】▼▼▼\n        # 公開モデルの重みファイルに存在する 'self.lpf' 層を再度追加する\n        self.lpf = nn.Conv1d(6, 6, kernel_size=k, padding=k//2,\n                                 groups=6, bias=False)\n        nn.init.kaiming_uniform_(self.lpf.weight, a=math.sqrt(5))\n        # ▲▲▲【ここまでが修正点】▲▲▲\n\n        self.lpf_acc  = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n        self.lpf_gyro = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n\n    def forward(self, imu):\n        acc  = imu[:, 0:3, :]\n        gyro = imu[:, 3:6, :]\n\n        # 1) magnitude\n        acc_mag  = torch.norm(acc,  dim=1, keepdim=True)\n        gyro_mag = torch.norm(gyro, dim=1, keepdim=True)\n\n        # 2) jerk\n        jerk = F.pad(acc[:, :, 1:] - acc[:, :, :-1], (1,0))\n        gyro_delta = F.pad(gyro[:, :, 1:] - gyro[:, :, :-1], (1,0))\n\n        # 3) energy\n        acc_pow  = acc ** 2\n        gyro_pow = gyro ** 2\n\n        # 4) LPF / HPF\n        # self.lpf は forwardパスでは使われていないが、重み読み込みのために定義が必要\n        acc_lpf  = self.lpf_acc(acc)\n        acc_hpf  = acc - acc_lpf\n        gyro_lpf = self.lpf_gyro(gyro)\n        gyro_hpf = gyro - gyro_lpf\n\n        features = [\n            acc, gyro,\n            acc_mag, gyro_mag,\n            jerk, gyro_delta,\n            acc_pow, gyro_pow,\n            acc_lpf, acc_hpf,\n            gyro_lpf, gyro_hpf,\n        ]\n        return torch.cat(features, dim=1)\n\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=8):\n        super().__init__()\n        self.squeeze = nn.AdaptiveAvgPool1d(1)\n        self.excitation = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False), nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False), nn.Sigmoid()\n        )\n    def forward(self, x):\n        b, c, _ = x.size()\n        y = self.squeeze(x).view(b, c)\n        y = self.excitation(y).view(b, c, 1)\n        return x * y.expand_as(x)\n\nclass ResidualSECNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, pool_size=2, dropout=0.3):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        self.se = SEBlock(out_channels)\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(nn.Conv1d(in_channels, out_channels, 1, bias=False), nn.BatchNorm1d(out_channels))\n        self.pool = nn.MaxPool1d(pool_size)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.se(out)\n        out += self.shortcut(x)\n        return self.dropout(self.pool(F.relu(out)))\n\nclass AttentionLayer(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.attention = nn.Linear(hidden_dim, 1)\n    def forward(self, x):\n        scores = torch.tanh(self.attention(x))\n        weights = F.softmax(scores.squeeze(-1), dim=1)\n        return torch.sum(x * weights.unsqueeze(-1), dim=1)\n\nclass TwoBranchModel(nn.Module):\n    def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], feature_engineering=True, **kwargs):\n        super().__init__()\n        self.feature_engineering = feature_engineering\n        imu_dim = 32 if feature_engineering else imu_dim_raw\n        self.imu_fe = ImuFeatureExtractor(**kwargs) if feature_engineering else nn.Identity()\n        self.fir_nchan = 7\n        numtaps = 33\n        fir_kernel = torch.tensor(firwin(numtaps, cutoff=1.0, fs=10.0, pass_zero=False), dtype=torch.float32).view(1, 1, -1).repeat(self.fir_nchan, 1, 1)\n        self.register_buffer(\"fir_kernel\", fir_kernel)\n        self.imu_block1 = ResidualSECNNBlock(imu_dim, 64, 3, dropout=dropouts[0])\n        self.imu_block2 = ResidualSECNNBlock(64, 128, 5, dropout=dropouts[1])\n        self.tof_conv1 = nn.Conv1d(tof_dim, 64, 3, padding=1, bias=False)\n        self.tof_bn1, self.tof_pool1, self.tof_drop1 = nn.BatchNorm1d(64), nn.MaxPool1d(2), nn.Dropout(dropouts[2])\n        self.tof_conv2 = nn.Conv1d(64, 128, 3, padding=1, bias=False)\n        self.tof_bn2, self.tof_pool2, self.tof_drop2 = nn.BatchNorm1d(128), nn.MaxPool1d(2), nn.Dropout(dropouts[3])\n        self.bilstm = nn.LSTM(256, 128, bidirectional=True, batch_first=True)\n        self.lstm_dropout = nn.Dropout(dropouts[4])\n        self.attention = AttentionLayer(256)\n        self.dense1, self.bn_dense1, self.drop1 = nn.Linear(256, 256, bias=False), nn.BatchNorm1d(256), nn.Dropout(dropouts[5])\n        self.dense2, self.bn_dense2, self.drop2 = nn.Linear(256, 128, bias=False), nn.BatchNorm1d(128), nn.Dropout(dropouts[6])\n        self.classifier = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        imu_raw = x[:, :, :self.fir_nchan].transpose(1, 2)\n        tof = x[:, :, self.fir_nchan:].transpose(1, 2)\n        imu_fe = self.imu_fe(imu_raw)\n        filtered = F.conv1d(imu_fe[:, :self.fir_nchan, :], self.fir_kernel, padding=self.fir_kernel.shape[-1] // 2, groups=self.fir_nchan)\n        imu = (torch.cat([filtered, imu_fe[:, self.fir_nchan:, :]], dim=1) - mean_pt) / std_pt\n        x1 = self.imu_block1(imu); x1 = self.imu_block2(x1)\n        x2 = self.tof_drop1(self.tof_pool1(F.relu(self.tof_bn1(self.tof_conv1(tof)))))\n        x2 = self.tof_drop2(self.tof_pool2(F.relu(self.tof_bn2(self.tof_conv2(x2)))))\n        merged = torch.cat([x1, x2], dim=1).transpose(1, 2)\n        lstm_out, _ = self.bilstm(merged); lstm_out = self.lstm_dropout(lstm_out)\n        attended = self.attention(lstm_out)\n        x = self.drop1(F.relu(self.bn_dense1(self.dense1(attended))))\n        x = self.drop2(F.relu(self.bn_dense2(self.dense2(x))))\n        return self.classifier(x)\n\nclass PublicTwoBranchModel(nn.Module):\n    \"\"\"\n    ★★★ 公開されているPyTorchモデル（モデル群C）を読み込むための、元のアーキテクチャを持つクラス ★★★\n    \"\"\"\n    def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], feature_engineering=True, **kwargs):\n        super().__init__()\n        self.feature_engineering = feature_engineering\n        imu_dim = 32 if feature_engineering else imu_dim_raw\n        self.imu_fe = ImuFeatureExtractor(**kwargs) if feature_engineering else nn.Identity()\n        self.fir_nchan = 7\n        numtaps = 33\n        fir_kernel = torch.tensor(firwin(numtaps, cutoff=1.0, fs=10.0, pass_zero=False), dtype=torch.float32).view(1, 1, -1).repeat(self.fir_nchan, 1, 1)\n        self.register_buffer(\"fir_kernel\", fir_kernel)\n        self.imu_block1 = ResidualSECNNBlock(imu_dim, 64, 3, dropout=dropouts[0])\n        self.imu_block2 = ResidualSECNNBlock(64, 128, 5, dropout=dropouts[1])\n        self.tof_conv1 = nn.Conv1d(tof_dim, 64, 3, padding=1, bias=False)\n        self.tof_bn1, self.tof_pool1, self.tof_drop1 = nn.BatchNorm1d(64), nn.MaxPool1d(2), nn.Dropout(dropouts[2])\n        self.tof_conv2 = nn.Conv1d(64, 128, 3, padding=1, bias=False)\n        self.tof_bn2, self.tof_pool2, self.tof_drop2 = nn.BatchNorm1d(128), nn.MaxPool1d(2), nn.Dropout(dropouts[3])\n        self.bilstm = nn.LSTM(256, 128, bidirectional=True, batch_first=True) # GRUではなくLSTM\n        self.lstm_dropout = nn.Dropout(dropouts[4])\n        self.attention = AttentionLayer(256) # 128*2 for bidirectional\n        self.dense1, self.bn_dense1, self.drop1 = nn.Linear(256, 256, bias=False), nn.BatchNorm1d(256), nn.Dropout(dropouts[5])\n        self.dense2, self.bn_dense2, self.drop2 = nn.Linear(256, 128, bias=False), nn.BatchNorm1d(128), nn.Dropout(dropouts[6])\n        self.classifier = nn.Linear(128, n_classes)\n\n    def forward(self, x):\n        imu_raw = x[:, :, :self.fir_nchan].transpose(1, 2)\n        tof = x[:, :, self.fir_nchan:].transpose(1, 2)\n        imu_fe = self.imu_fe(imu_raw)\n        filtered = F.conv1d(imu_fe[:, :self.fir_nchan, :], self.fir_kernel, padding=self.fir_kernel.shape[-1] // 2, groups=self.fir_nchan)\n        # mean_pt, std_pt は事前に定義されているグローバル変数\n        imu = (torch.cat([filtered, imu_fe[:, self.fir_nchan:, :]], dim=1) - mean_pt) / std_pt\n        x1 = self.imu_block1(imu); x1 = self.imu_block2(x1)\n        x2 = self.tof_drop1(self.tof_pool1(F.relu(self.tof_bn1(self.tof_conv1(tof)))))\n        x2 = self.tof_drop2(self.tof_pool2(F.relu(self.tof_bn2(self.tof_conv2(x2)))))\n        merged = torch.cat([x1, x2], dim=1).transpose(1, 2)\n        lstm_out, _ = self.bilstm(merged); lstm_out = self.lstm_dropout(lstm_out)\n        attended = self.attention(lstm_out)\n        x = self.drop1(F.relu(self.bn_dense1(self.dense1(attended))))\n        x = self.drop2(F.relu(self.bn_dense2(self.dense2(x))))\n        return self.classifier(x)\n\ndef pad_sequences_torch3(sequences, maxlen, padding='post', truncating='post', value=0.0):\n    result = []\n    for seq in sequences:\n        if len(seq) >= maxlen: seq = seq[:maxlen] if truncating == 'post' else seq[-maxlen:]\n        else:\n            pad_len = maxlen - len(seq)\n            pad_array = np.full((pad_len, seq.shape[1]), value)\n            seq = np.concatenate([seq, pad_array]) if padding == 'post' else np.concatenate([pad_array, seq])\n        result.append(seq)\n    return np.array(result, dtype=np.float32)\n\n# =============================================================================\n# ## 特徴量エンジニアリング関数\n# =============================================================================\ndef remove_gravity_from_acc3(acc_data, rot_data):\n    \"\"\"加速度データから重力成分を除去する\"\"\"\n    acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    linear_accel = np.zeros_like(acc_values)\n    gravity_world = np.array([0, 0, 9.81])\n    for i in range(len(acc_values)):\n        if np.all(np.isnan(quat_values[i])):\n            linear_accel[i, :] = acc_values[i, :]\n            continue\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except (ValueError, IndexError):\n            linear_accel[i, :] = acc_values[i, :]\n    return linear_accel\n\ndef calculate_angular_velocity_from_quat3(rot_data, time_delta=1/200):\n    \"\"\"クォータニオンから角速度を計算する\"\"\"\n    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    angular_vel = np.zeros((len(quat_values), 3))\n    for i in range(len(quat_values) - 1):\n        q_t, q_t_plus_dt = quat_values[i], quat_values[i+1]\n        if np.all(np.isnan(q_t)) or np.all(np.isnan(q_t_plus_dt)): continue\n        try:\n            rot_t = R.from_quat(q_t)\n            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n            delta_rot = rot_t.inv() * rot_t_plus_dt\n            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n        except (ValueError, IndexError): pass\n    return angular_vel\n\ndef calculate_angular_distance3(rot_data):\n    \"\"\"クォータニオンから角距離を計算する\"\"\"\n    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    angular_dist = np.zeros(len(quat_values))\n    for i in range(len(quat_values) - 1):\n        q1, q2 = quat_values[i], quat_values[i+1]\n        if np.all(np.isnan(q1)) or np.all(np.isnan(q2)): continue\n        try:\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n            relative_rotation = r1.inv() * r2\n            angular_dist[i] = np.linalg.norm(relative_rotation.as_rotvec())\n        except (ValueError, IndexError): pass\n    return angular_dist\n\ndef time_sum(x): return K.sum(x, axis=1)\ndef squeeze_last_axis(x): return tf.squeeze(x, axis=-1)\ndef expand_last_axis(x): return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    \"\"\"Squeeze-and-Excitationブロック\"\"\"\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    \"\"\"Residual SE-CNNブロック\"\"\"\n    shortcut = x\n    # 2層のConv1D\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    # SEブロック\n    x = se_block(x)\n    # ショートカット接続\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False, kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    \"\"\"アテンション層\"\"\"\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context\n\nclass GatedMixupGenerator(Sequence):\n    \"\"\"Mixupとセンサーマスキングを適用するデータジェネレータ\"\"\"\n    def __init__(self, X, y, batch_size, imu_dim, class_weight=None, alpha=0.2, masking_prob=0.0):\n        self.X, self.y, self.batch, self.imu_dim = X, y, batch_size, imu_dim\n        self.class_weight, self.alpha, self.masking_prob = class_weight, alpha, masking_prob\n        self.indices = np.arange(len(X))\n\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx].copy(), self.y[idx].copy()\n\n        sample_weights = np.ones(len(Xb), dtype='float32')\n        if self.class_weight:\n            sample_weights = np.array([self.class_weight.get(i, 1.0) for i in yb.argmax(axis=1)])\n\n        gate_target = np.ones(len(Xb), dtype='float32')\n        if self.masking_prob > 0:\n            for j in range(len(Xb)):\n                if np.random.rand() < self.masking_prob:\n                    Xb[j, :, self.imu_dim:] = 0\n                    gate_target[j] = 0.0\n\n        if self.alpha > 0:\n            lam = np.random.beta(self.alpha, self.alpha)\n            perm = np.random.permutation(len(Xb))\n            X_mix = lam * Xb + (1 - lam) * Xb[perm]\n            y_mix = lam * yb + (1 - lam) * yb[perm]\n            gate_target_mix = lam * gate_target + (1 - lam) * gate_target[perm]\n            sample_weights_mix = lam * sample_weights + (1 - lam) * sample_weights[perm]\n            return X_mix, {'main_output': y_mix, 'tof_gate': gate_target_mix}, sample_weights_mix\n\n        return Xb, {'main_output': yb, 'tof_gate': gate_target}, sample_weights\n\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)\n\ndef build_gated_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    \"\"\"\n    自作のGated Two-Branchモデルを構築する関数。\n    [改良点] LSTMをGRUに変更、全結合層を1層追加。\n    \"\"\"\n    inp = Input(shape=(pad_len, imu_dim + tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMUブランチ (Deep)\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n\n    # TOF/THMブランチ (Light) with Gating\n    x2_base = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n    x2_base = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2_base)\n    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n\n    # Gating機構\n    gate_input = GlobalAveragePooling1D()(tof)\n    gate_input = Dense(16, activation='relu')(gate_input)\n    gate = Dense(1, activation='sigmoid', name='tof_gate')(gate_input)\n    x2 = Multiply()([x2_base, gate])\n\n    # ブランチのマージと後続層\n    merged = Concatenate()([x1, x2])\n    # ★改良点: LSTM -> GRU\n    x = Bidirectional(GRU(256, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    x = Dropout(0.45)(x)\n    x = attention_layer(x)\n\n    # ★改良点: 全結合層を1層追加して表現力を向上\n    for units, drop in [(512, 0.5), (256, 0.4), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n\n    return Model(inputs=inp, outputs=[out, gate])\n\n# -----------------------------------------------------------------------------\n# ### 推論モード (`TRAIN = False`)\n# -----------------------------------------------------------------------------\n\nprint(\"▶ 推論モード開始 – 学習済みモデルとアーティファクトを読み込みます...\")\n\n# --- モデル群A (自作TF/Kerasモデル) の読み込み ---\nprint(\"  モデル群A (自作5-Fold Gated GRUモデル) を読み込み中...\")\nfinal_feature_cols_A = np.load(YOUR_MODELS_DIR / \"final_feature_cols.npy\", allow_pickle=True).tolist()\npad_len_A = int(np.load(YOUR_MODELS_DIR / \"sequence_maxlen.npy\"))\nscaler_A = joblib.load(YOUR_MODELS_DIR / \"scaler.pkl\")\ngesture_classes = np.load(YOUR_MODELS_DIR / \"gesture_classes.npy\", allow_pickle=True)\ncustom_objs_A = {'time_sum': time_sum, 'squeeze_last_axis': squeeze_last_axis, 'expand_last_axis': expand_last_axis,\n                 'se_block': se_block, 'residual_se_cnn_block': residual_se_cnn_block, 'attention_layer': attention_layer}\nmodels_A = [load_model(YOUR_MODELS_DIR / f\"final_model_fold_{f}.h5\", compile=False, custom_objects=custom_objs_A) for f in range(N_SPLITS)]\nprint(f\"  > {len(models_A)}個のモデルを正常に読み込みました。\")\n\n# --- モデル群B (公開TF/Kerasモデル) の読み込み ---\nprint(\"\\n  モデル群B (公開TF/Kerasモデル) を読み込み中...\")\nfinal_feature_cols_B = np.load(PUBLIC_TF_MODEL_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\npad_len_B = int(np.load(PUBLIC_TF_MODEL_DIR / \"sequence_maxlen.npy\"))\nscaler_B = joblib.load(PUBLIC_TF_MODEL_DIR / \"scaler.pkl\")\ncustom_objs_B = custom_objs_A # public modelも同じカスタムオブジェクトを使用\nmodel_B = load_model(PUBLIC_TF_MODEL_DIR / \"gesture_two_branch_mixup.h5\", compile=False, custom_objects=custom_objs_B)\nprint(\"  > 1個のモデルを正常に読み込みました。\")\n\n# --- モデル群C (公開PyTorchモデル) の読み込み ---\nprint(\"\\n  モデル群C (公開PyTorchモデル) を読み込み中...\")\nfinal_feature_cols_C = np.load(PUBLIC_PT_MODEL_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\npad_len_C = int(np.load(PUBLIC_PT_MODEL_DIR / \"sequence_maxlen.npy\"))\nscaler_C = joblib.load(PUBLIC_PT_MODEL_DIR / \"scaler.pkl\")\n\npt_models = []\nfor f in range(5):\n    checkpoint = torch.load(PUBLIC_PT_MODEL_DIR / f\"gesture_two_branch_fold{f}.pth\", map_location=device)\n    cfg = {'pad_len': checkpoint['pad_len'], 'imu_dim_raw': checkpoint['imu_dim'],\n           'tof_dim': checkpoint['tof_dim'], 'n_classes': checkpoint['n_classes']}\n    m = PublicTwoBranchModel(**cfg).to(device)\n    m.load_state_dict(checkpoint['model_state_dict'])\n    m.eval()\n    pt_models.append(m)\nprint(f\"  > {len(pt_models)}個のモデルを正常に読み込みました。\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-08-13T02:56:40.420817Z","iopub.execute_input":"2025-08-13T02:56:40.421095Z","iopub.status.idle":"2025-08-13T02:56:47.996730Z","shell.execute_reply.started":"2025-08-13T02:56:40.421079Z","shell.execute_reply":"2025-08-13T02:56:47.996020Z"}},"outputs":[{"name":"stdout","text":"▶ ライブラリのインポート完了\n  - TensorFlow: 2.18.0\n  - PyTorch: 2.6.0+cu124\n▶ TRAINモード: False\n▶ 推論モード開始 – 学習済みモデルとアーティファクトを読み込みます...\n  モデル群A (自作5-Fold Gated GRUモデル) を読み込み中...\n  > 10個のモデルを正常に読み込みました。\n\n  モデル群B (公開TF/Kerasモデル) を読み込み中...\n  > 1個のモデルを正常に読み込みました。\n\n  モデル群C (公開PyTorchモデル) を読み込み中...\n  > 5個のモデルを正常に読み込みました。\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# predict_4\n\n# --- `predict`関数の定義 ---\ndef predict4(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    df_seq_orig = sequence.to_pandas()\n    df_seq_A = df_seq_orig.copy()\n    \n    linear_accel_A = remove_gravity_from_acc3(df_seq_A[['acc_x','acc_y','acc_z']], df_seq_A[['rot_x','rot_y','rot_z','rot_w']])\n    df_seq_A['linear_acc_x'], df_seq_A['linear_acc_y'], df_seq_A['linear_acc_z'] = linear_accel_A[:,0], linear_accel_A[:,1], linear_accel_A[:,2]\n    df_seq_A['linear_acc_mag'] = np.linalg.norm(linear_accel_A, axis=1)\n    df_seq_A['linear_acc_mag_jerk'] = df_seq_A['linear_acc_mag'].diff().fillna(0)\n    angular_vel_A = calculate_angular_velocity_from_quat3(df_seq_A[['rot_x','rot_y','rot_z','rot_w']])\n    df_seq_A['angular_vel_x'], df_seq_A['angular_vel_y'], df_seq_A['angular_vel_z'] = angular_vel_A[:,0], angular_vel_A[:,1], angular_vel_A[:,2]\n    df_seq_A['angular_distance'] = calculate_angular_distance3(df_seq_A[['rot_x','rot_y','rot_z','rot_w']])\n    for col in ['rot_x', 'rot_y', 'rot_z', 'rot_w']:\n        df_seq_A[f'{col}_diff'] = df_seq_A[col].diff().fillna(0)\n    cols_for_stats=['linear_acc_mag','linear_acc_mag_jerk','angular_distance']\n    for col in cols_for_stats:\n        df_seq_A[f'{col}_skew'], df_seq_A[f'{col}_kurt'] = df_seq_A[col].skew(), df_seq_A[col].kurtosis()\n    for i in range(1,6):\n        if f'tof_{i}_v0' in df_seq_A.columns:\n            pixel_cols=[f\"tof_{i}_v{p}\" for p in range(64)]; tof_data=df_seq_A[pixel_cols].replace(-1,np.nan)\n            df_seq_A[f'tof_{i}_mean'], df_seq_A[f'tof_{i}_std'], df_seq_A[f'tof_{i}_min'], df_seq_A[f'tof_{i}_max'] = tof_data.mean(axis=1),tof_data.std(axis=1),tof_data.min(axis=1),tof_data.max(axis=1)\n    tof_mean_cols=[f'tof_{i}_mean' for i in range(1,6) if f'tof_{i}_mean' in df_seq_A.columns]\n    if tof_mean_cols:\n        df_seq_A['tof_std_across_sensors']=df_seq_A[tof_mean_cols].std(axis=1)\n        df_seq_A['tof_range_across_sensors']=df_seq_A[tof_mean_cols].max(axis=1)-df_seq_A[tof_mean_cols].min(axis=1)\n    thm_cols=[f'thm_{i}' for i in range(1,6) if f'thm_{i}' in df_seq_A.columns]\n    if thm_cols:\n        df_seq_A['thm_std_across_sensors']=df_seq_A[thm_cols].std(axis=1)\n        df_seq_A['thm_range_across_sensors']=df_seq_A[thm_cols].max(axis=1)-df_seq_A[thm_cols].min(axis=1)\n    # (推論 A)\n    mat_A = df_seq_A[final_feature_cols_A].ffill().bfill().fillna(0).values.astype('float32')\n    mat_A = scaler_A.transform(mat_A)\n    pad_input_A = pad_sequences([mat_A], maxlen=pad_len_A, padding='post', dtype='float32')\n    preds_A_folds = [model.predict(pad_input_A, verbose=0)[0] for model in models_A]\n    avg_pred_A = np.mean(preds_A_folds, axis=0)\n\n    # --- 2. モデル群B (公開TFモデル) の予測 ---\n    df_seq_B = df_seq_orig.copy()\n    # (特徴量生成 B)\n    df_seq_B['acc_mag']=np.sqrt(df_seq_B['acc_x']**2+df_seq_B['acc_y']**2+df_seq_B['acc_z']**2)\n    df_seq_B['rot_angle']=2*np.arccos(df_seq_B['rot_w'].clip(-1,1))\n    df_seq_B['acc_mag_jerk']=df_seq_B['acc_mag'].diff().fillna(0)\n    df_seq_B['rot_angle_vel']=df_seq_B['rot_angle'].diff().fillna(0)\n    linear_accel_B=remove_gravity_from_acc3(df_seq_B,df_seq_B)\n    df_seq_B['linear_acc_x'],df_seq_B['linear_acc_y'],df_seq_B['linear_acc_z']=linear_accel_B[:,0],linear_accel_B[:,1],linear_accel_B[:,2]\n    df_seq_B['linear_acc_mag']=np.sqrt(df_seq_B['linear_acc_x']**2+df_seq_B['linear_acc_y']**2+df_seq_B['linear_acc_z']**2)\n    df_seq_B['linear_acc_mag_jerk']=df_seq_B['linear_acc_mag'].diff().fillna(0)\n    angular_vel_B=calculate_angular_velocity_from_quat3(df_seq_B)\n    df_seq_B['angular_vel_x'],df_seq_B['angular_vel_y'],df_seq_B['angular_vel_z']=angular_vel_B[:,0],angular_vel_B[:,1],angular_vel_B[:,2]\n    df_seq_B['angular_distance']=calculate_angular_distance3(df_seq_B)\n    for i in range(1,6):\n        if f'tof_{i}_v0' in df_seq_B.columns:\n            pixel_cols=[f\"tof_{i}_v{p}\" for p in range(64)]; tof_data=df_seq_B[pixel_cols].replace(-1,np.nan)\n            df_seq_B[f\"tof_{i}_mean\"],df_seq_B[f\"tof_{i}_std\"],df_seq_B[f\"tof_{i}_min\"],df_seq_B[f\"tof_{i}_max\"]=tof_data.mean(axis=1),tof_data.std(axis=1),tof_data.min(axis=1),tof_data.max(axis=1)\n    # (推論 B)\n    mat_B = df_seq_B[final_feature_cols_B].ffill().bfill().fillna(0).values.astype('float32')\n    mat_B = scaler_B.transform(mat_B)\n    pad_input_B = pad_sequences([mat_B], maxlen=pad_len_B, padding='post', dtype='float32')\n    pred_B = model_B.predict(pad_input_B, verbose=0)\n    if isinstance(pred_B, list): pred_B = pred_B[0]\n\n    # --- 3. モデル群C (公開PyTorchモデル) の予測 ---\n    df_seq_C = df_seq_orig.copy() # Cは特徴量生成が不要なため、コピーのみ\n    mat_C = df_seq_C[final_feature_cols_C].ffill().bfill().fillna(0).values.astype('float32')\n    mat_C = scaler_C.transform(mat_C)\n    pad_input_C = pad_sequences_torch3([mat_C], maxlen=pad_len_C, padding='pre', truncating='pre')\n    with torch.no_grad():\n        pt_input = torch.from_numpy(pad_input_C).to(device)\n        preds_C_folds = [model(pt_input) for model in pt_models]\n        avg_pred_C_logits = torch.mean(torch.stack(preds_C_folds), dim=0)\n        avg_pred_C = torch.softmax(avg_pred_C_logits, dim=1).cpu().numpy()\n\n    # --- 4. 加重平均による最終決定 ---\n\n    weights = {'A': 0.50, 'B': 0.20, 'C': 0.30}\n\n    final_pred_proba = (weights['A'] * avg_pred_A + weights['B'] * pred_B + weights['C'] * avg_pred_C)\n\n    return final_pred_proba","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-13T02:56:47.997627Z","iopub.execute_input":"2025-08-13T02:56:47.997885Z","iopub.status.idle":"2025-08-13T02:56:48.019092Z","shell.execute_reply.started":"2025-08-13T02:56:47.997865Z","shell.execute_reply":"2025-08-13T02:56:48.018379Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Archive\n\n\n# help func.1\n\n# pred0,pred1,pred2, ws, cws, aws = 1,2,3, [0.274,0.342,0.382], [+0.011, -0.004, -0.007], [0.99, 0.01]\n\n# lp = [{ 'w':ws[0], 'p':pred0, 'n':'p0' },\n#       { 'w':ws[1], 'p':pred1, 'n':'p1' },\n#       { 'w':ws[2], 'p':pred2, 'n':'p2' }] \n\n# lps_asc  = [{'w':p['w'], 'p':p['p'], 'n':p['n']} for p in lp]\n# lps_desc = [{'w':p['w'], 'p':p['p'], 'n':p['n']} for p in lp]\n\n# lps_asc  = sorted(lps_asc,  key=lambda k:k['p'],reverse=False)\n# lps_desc = sorted(lps_desc, key=lambda k:k['p'],reverse=True)\n\n# print(lps_asc, \"\\n\\n\", lps_desc, \"\") #------------------------\n\n# for p,cw in zip(lps_asc,  cws): p['w'] += cw\n# for p,cw in zip(lps_desc, cws): p['w'] += cw\n    \n# print(\"-\"*11)\n# print(lps_asc, \"\\n\\n\", lps_desc)     #------------------------\n\n# lps_asc  = sorted(lps_asc,  key=lambda k:k['n'],reverse=False)\n# lps_desc = sorted(lps_desc, key=lambda k:k['n'],reverse=False)\n\n# print(\"-\"*11)\n# print(lps_asc, \"\\n\\n\", lps_desc)     #------------------------\n\n# lps = []\n\n# for a,d in zip(lps_asc, lps_desc):\n#     one_dict = {\n#         'w':a['w']* aws[0]+aws[1] *d['w'],\n#         'p':a['p'],\n#         'n':a['n']\n#     }\n#     lps.append(one_dict)\n\n# print(\"-\"*11)                        #------------------------\n# print(lps)\n\n# wps = [ps[\"w\"]*ps[\"p\"] for ps in lps]\n\n# print(\"-\"*11)                        #------------------------\n# print(wps)\n\n# help func.2\n\n# def equ(_a,_b,_c,_k):\n#     _o = 0.999985\n#     if _a == _b and _a != _c: return [_k, _k, _o]\n#     if _a == _c and _b != _c: return [_k, _o, _k]\n#     if _b == _c and _a != _b: return [_o, _k, _k]\n#     return [1,1,1]\n\n# def corr(li):\n#     v2,v1 = min(li),     max(li)\n#     j2,j1 = li.index(v2),li.index(v1)                   \n#     v3,j3 = 1-(v1-1/v2), 3-(j1+j2)\n#     a = [_,_,_];\n#     a[j1],a[j2],a[j3] = v1,v2,v3\n#     return np.asarray(a)\n\n# s,_,f = 0.9974, 1, 1.0041\n\n# li = [f,s,_]\n\n# v2,v1 = min(li),max(li)\n# j2 = li.index(v2)\n# j1 = li.index(v1)\n# print(f'value.s = {v2}, index.s = {j2}')\n# print(f'value.f = {v1}, index.f = {j1}')\n\n# '''\n#                        2     1     0     : index.(j3)\n# indexes.(j1,j2) :  0,1,    0, 2    ,1,2\n\n# j3 = 3 - (j2 + j1)\n# ''' \n\n# j3 = 3 - (j2 + j1)\n\n# li = corr([f,s,_])\n\n# v3 = li[j3]\n\n# print(f'value.v3 = {v3}, index.v3 = {j3}',\"   \", li)\n\n\n# import numpy as np\n\n# def predict(sequence, demographics):\n\n#     pred0 = predict1(sequence, demographics)[0]\n#     pred1 = predict2(sequence, demographics)[0]\n#     pred2 = predict3(sequence, demographics)[0]                                \n\n#     wts1, s,_,f = np.asarray([0.271, 0.349, 0.380]),    0.9974,  1, 1.0041\n#     #--------------------------------------------\n#     c1_123 = corr([f,s,_])\n#     c1_132 = corr([f,_,s])\n#     #--------------------------------------------\n#     c1_213 = corr([s,f,_])\n#     c1_231 = corr([_,f,s])\n#     #--------------------------------------------\n#     c1_312 = corr([s,_,f])\n#     c1_321 = corr([_,s,f])\n#     #--------------------------------------------\n                                        \n#     wts2, s,_,f = np.asarray([0.2705, 0.3495, 0.380]),  0.99744, 1, 1.00404 \n#     #--------------------------------------------\n#     c2_123 = corr([f,s,_])\n#     c2_132 = corr([f,_,s])\n#     #--------------------------------------------\n#     c2_213 = corr([s,f,_])\n#     c2_231 = corr([_,f,s])\n#     #--------------------------------------------\n#     c2_312 = corr([s,_,f])\n#     c2_321 = corr([_,s,f])\n#     #--------------------------------------------\n\n#     # r =       5\n#     # k = 1.00005\n#     #-------------\n#     _r  =         7\n#     _k  = 1.0000007 \n\n#     def equ(_a,_b,_c,_k=_k):\n#         if _a == _b and _a != _c: return [_k, _k,  1]\n#         if _a == _c and _b != _c: return [_k,  1, _k]\n#         if _b == _c and _a != _b: return [ 1, _k, _k]\n#         return [1,1,1]\n\n#     preds = []\n    \n#     for _a,_b,_c in zip(pred0,pred1,pred2):\n        \n#         a,b,c = round(_a,_r),round(_b,_r),round(_c,_r)\n        \n#         if   a <= b <= c: _wts1 = wts1 * c1_123\n#         elif a <= c <= b: _wts1 = wts1 * c1_132\n#         elif b <= a <= c: _wts1 = wts1 * c1_213\n#         elif b <= c <= a: _wts1 = wts1 * c1_231\n#         elif c <= a <= b: _wts1 = wts1 * c1_312\n#         elif c <= b <= a: _wts1 = wts1 * c1_321\n\n#         _equ = equ(a,b,c)\n\n#         if equ == [1,1,1]:\n\n#             if   a <  b <  c: _wts2 = wts2 * c2_123\n#             elif a <  c <  b: _wts2 = wts2 * c2_132\n#             elif b <  a <  c: _wts2 = wts2 * c2_213\n#             elif b <  c <  a: _wts2 = wts2 * c2_231\n#             elif c <  a <  b: _wts2 = wts2 * c2_312\n#             elif c <  b <  a: _wts2 = wts2 * c2_321\n#             else:             _wts2 = wts2;\n\n#             __wts = _wts2 *0.7 +\\\n#                     _wts1 *0.3\n#         else:\n#             __wts = _wts1\n        \n#         p = _a *__wts[0] *_equ[0] +\\\n#             _b *__wts[1] *_equ[1] +\\\n#             _c *__wts[2] *_equ[2]\n        \n#         preds.append(p)\n        \n\n#     avg_pred =  np.asarray(preds)\n                \n#     return dataset.le.classes_[avg_pred.argmax()]\n\n\n\n# 2\n\n# def predict(sequence, demographics):\n\n#     pred0 = predict1(sequence, demographics)[0]\n#     pred1 = predict2(sequence, demographics)[0]\n#     pred2 = predict3(sequence, demographics)[0]    \n\n#     #wts1, s,_,f = np.asarray([0.271,  0.349,  0.380 ]),  0.9974,  1, 1.0041   # Lb=0.850 # v11\n#     #wts1, s,_,f = np.asarray([0.2711, 0.3494, 0.3795]),  0.99744, 1, 1.0039   # Lb=0.850 # v12\n#     №wts1, s,_,f = np.asarray([0.271,  0.349,  0.380 ]),  0.9974,  1, 1.00405  # Lb=0.850 v13\n#     wts1, s,_,f = np.asarray([0.271,  0.349,  0.380 ]),  0.99855, 1, 1.00404  # Lb=0.850 v14\n    \n#     #----------------------\n#     c1_123 = corr([f,s,_])\n#     c1_132 = corr([f,_,s])\n#     #----------------------\n#     c1_213 = corr([s,f,_])\n#     c1_231 = corr([_,f,s])\n#     #----------------------\n#     c1_312 = corr([s,_,f])\n#     c1_321 = corr([_,s,f])\n#     #----------------------\n\n#     r =      4\n#     k = 1.0004     \n\n#     preds = []\n    \n#     for _a,_b,_c in zip(pred0,pred1,pred2):\n        \n#         a,b,c = round(_a,r),round(_b,r),round(_c,r)\n        \n#         if   a <= b <= c: _wts1 = wts1 * c1_123\n#         elif a <= c <= b: _wts1 = wts1 * c1_132\n#         elif b <= a <= c: _wts1 = wts1 * c1_213\n#         elif b <= c <= a: _wts1 = wts1 * c1_231\n#         elif c <= a <= b: _wts1 = wts1 * c1_312\n#         elif c <= b <= a: _wts1 = wts1 * c1_321\n\n#         _equ = equ(a,b,c, k)\n\n#         __wts = _wts1\n        \n#         p = _a *__wts[0] *_equ[0] +\\\n#             _b *__wts[1] *_equ[1] +\\\n#             _c *__wts[2] *_equ[2]\n\n#         # p = a *__wts[0] *_equ[0] +\\\n#         #     b *__wts[1] *_equ[1] +\\\n#         #     c *__wts[2] *_equ[2]\n        \n#         preds.append(p)\n        \n\n#     avg_pred =  np.asarray(preds)\n                \n#     return dataset.le.classes_[avg_pred.argmax()]\n\n\n\n# Japan solution\n\n# def predict(sequence, demographics):\n#     import numpy as np\n\n#     # --- 3モデルの確率 ---\n#     pred0 = predict1(sequence, demographics)[0]\n#     pred1 = predict2(sequence, demographics)[0]\n#     pred2 = predict3(sequence, demographics)[0]\n\n#     # --- ① 温度シャープニング（ほんの少し尖らせる） ---\n#     def _sharpen(p, gamma=1.10, eps=1e-12):\n#         p = np.clip(p, eps, 1.0)\n#         p = p ** gamma\n#         return p / p.sum()\n\n#     pred0 = _sharpen(pred0, 1.10)\n#     pred1 = _sharpen(pred1, 1.10)\n#     pred2 = _sharpen(pred2, 1.10)\n\n#     # --- ② 自信（エントロピー）でベース重みを微調整 ---\n#     def _entropy(p, eps=1e-12):\n#         p = np.clip(p, eps, 1.0)\n#         return -np.sum(p * np.log(p))\n\n#     H0, H1, H2 = _entropy(pred0), _entropy(pred1), _entropy(pred2)\n#     conf = np.exp(-np.array([H0, H1, H2]))   # 低H=高自信→大きい\n#     conf = conf / conf.mean()                 # 平均1に正規化\n#     beta = 0.35                               # 効き具合（0.2〜0.5で軽くCV）\n#     w_base = np.asarray([0.271, 0.347, 0.382])  # 固定ベース\n#     wts = (w_base * (conf ** beta))\n#     wts = wts / wts.sum()                     # 合計1に\n\n#     # --- ③ ランクに応じた微調整係数 ---\n#     c123 = np.asarray([1.0041, 0.9974, 0.9985])\n#     c132 = np.asarray([1.0041, 0.9985, 0.9974])\n#     c213 = np.asarray([0.9974, 1.0041, 0.9985])\n#     c231 = np.asarray([0.9985, 1.0041, 0.9974])\n#     c312 = np.asarray([0.9974, 0.9985, 1.0041])\n#     c321 = np.asarray([0.9985, 0.9974, 1.0041])\n\n#     # --- ④ クラスごとの加重ログ合算（幾何平均の重み付き版） ---\n#     scores = []\n#     eps = 1e-12\n#     for a, b, c in zip(pred0, pred1, pred2):\n#         if   a <= b <= c: _w = c123 * wts\n#         elif a <= c <= b: _w = c132 * wts\n#         elif b <= a <= c: _w = c213 * wts\n#         elif b <= c <= a: _w = c231 * wts\n#         elif c <= a <= b: _w = c312 * wts\n#         else:             _w = c321 * wts  # c <= b <= a\n\n#         s = _w[0]*np.log(a + eps) + _w[1]*np.log(b + eps) + _w[2]*np.log(c + eps)\n#         scores.append(s)\n\n#     scores = np.asarray(scores)\n#     return dataset.le.classes_[int(np.argmax(scores))]\n\n# # 3 + Japanese added\n\n# import numpy as np\n\n# def predict(sequence, demographics):\n\n#     pred0 = predict1(sequence, demographics)[0]\n#     pred1 = predict2(sequence, demographics)[0]\n#     pred2 = predict3(sequence, demographics)[0]\n\n#     # --- ① Temperature sharpening (slightly sharpen) ---\n#     def _sharpen(p, gamma=1.10, eps=1e-12):\n#         p = np.clip(p, eps, 1.0)\n#         p = p ** gamma\n#         return p / p.sum()\n\n    \n#     pred0 = _sharpen(pred0, 1.10)\n#     pred1 = _sharpen(pred1, 1.10)\n#     pred2 = _sharpen(pred2, 1.10)\n\n\n#     # --- ② Fine-tune base weights with confidence (entropy) ---\n#     def _entropy(p, eps=1e-12):\n#         p = np.clip(p, eps, 1.0)\n#         return -np.sum(p * np.log(p))\n\n\n#     H0, H1, H2 = _entropy(pred0), _entropy(pred1), _entropy(pred2)\n    \n#     conf = np.exp(-np.array([H0, H1, H2]))          # Low H = high confidence → large\n#     conf = conf / conf.mean()                       # Normalized to mean 1\n#     beta = 0.35                                     # Effectiveness (light CV between 0.2 and 0.5)\n    \n#     w_base = np.asarray([0.271,  0.347,  0.382])    # Fixed base\n#     wts = (w_base * (conf ** beta))\n#     wts_J1 = wts / wts.sum()                        # Total to 1\n\n#     w_base2 = np.asarray([0.2705, 0.3474, 0.3821])  # Fixed base\n#     wts2 = (w_base2 * (conf ** 0.374))\n#     wts_J2 = wts2 / wts2.sum()                      # Total to 1\n    \n\n#     wts1, s,_,f = wts_J1,  0.9974, 1, 1.0041\n#     #--------------------------------------------------\n#     c1_123 = corr([f,s,_])\n#     c1_132 = corr([f,_,s])\n#     #----------------------------------------\n#     c1_213 = corr([s,f,_])\n#     c1_231 = corr([_,f,s])\n#     #------------------------------\n#     c1_312 = corr([s,_,f])\n#     c1_321 = corr([_,s,f])\n#     #----------------------\n                                        \n#     wts2, s,_,f = wts_J2,  0.9977, 1, 1.0038\n#     #--------------------------------------------------\n#     c2_123 = corr([f,s,_])\n#     c2_132 = corr([f,_,s])\n#     #----------------------------------------\n#     c2_213 = corr([s,f,_])\n#     c2_231 = corr([_,f,s])\n#     #------------------------------\n#     c2_312 = corr([s,_,f])\n#     c2_321 = corr([_,s,f])\n#     #----------------------\n\n#     _r1,k1 = 7,1.000001\n#     _r2,k2 = 7,1.000002\n\n#     # --- ④ Weighted log sum by class (weighted version of geometric mean) ---\n\n#     preds = []\n#     eps = 1e-12\n#     for _a,_b,_c in zip(pred0,pred1,pred2):\n        \n#         a1,b1,c1 = _a,_b,_c\n#         _a1,_b1,_c1 = round(_a,_r1),round(_b,_r1),round(_c,_r1)\n#         if   a1 <= b1 <= c1: _w1 = wts1 * c1_123\n#         elif a1 <= c1 <= b1: _w1 = wts1 * c1_132\n#         elif b1 <= a1 <= c1: _w1 = wts1 * c1_213\n#         elif b1 <= c1 <= a1: _w1 = wts1 * c1_231\n#         elif c1 <= a1 <= b1: _w1 = wts1 * c1_312\n#         else:                _w1 = wts1 * c1_321 # c1 <= b1 <= a1:\n            \n#         _equ1 = equ(a1,b1,c1,k1)    \n        \n#         p1 = _w1[0]*np.log(a + eps) *_equ1[0] +\\\n#              _w1[1]*np.log(b + eps) *_equ1[1] +\\\n#              _w1[2]*np.log(c + eps) *_equ1[2]\n#         # -----------------------------------------\n\n#         a2,b2,c2 = _a,_b,_c\n#         _a2,_b2,_c2 = round(_a,_r2),round(_b,_r2),round(_c,_r2)\n#         if   c2 <= a2 <= b2: _w2 = wts2 * c2_312\n#         elif c2 <= b2 <= a2: _wts2 = wts2 * c2_321\n#         elif b2 <= a2 <= c2: _wts2 = wts2 * c2_213\n#         elif b2 <= c2 <= a2: _wts2 = wts2 * c2_231\n#         elif a2 <= b2 <= c2: _wts2 = wts2 * c2_123\n#         else               : _wts2 = wts2 * c2_132\n            \n#         _equ2 = equ(a2,b2,c2,k2)\n        \n#         p2 = _w2[0]*np.log(a2 + eps) *_equ2[0] +\\\n#              _w2[1]*np.log(b2 + eps) *_equ2[1] +\\\n#              _w2[2]*np.log(c2 + eps) *_equ2[2]\n#         # -----------------------------------------\n\n#         p = (p1 + p2) / 2\n        \n#         preds.append(p)\n        \n\n#     avg_pred =  np.asarray(preds)\n                \n#     return dataset.le.classes_[avg_pred.argmax()]\n\n\n# # 4 Japanese added code -> LB increase -> 0.850 -> 0.851\n\n# # # Let's try adding h-blend to this 'common kitchen'.. \n\n# import copy\n\n# def predict(sequence, demographics):\n#     import numpy as np\n\n#     # --- Probability of 3 models ---\n#     pred0 = predict1(sequence, demographics)[0]\n#     pred1 = predict2(sequence, demographics)[0]\n#     pred2 = predict3(sequence, demographics)[0]\n\n#     # --- Temperature sharpening (slightly sharpening) ---\n#     def _sharpen(p, gamma=1.10, eps=1e-12):\n#         p = np.clip(p, eps, 1.0)\n#         p = p ** gamma\n#         return p / p.sum()\n\n#     pred0 = _sharpen(pred0, 1.10)\n#     pred1 = _sharpen(pred1, 1.10)\n#     pred2 = _sharpen(pred2, 1.10)\n\n#     # --- Fine-tune base weights with confidence (entropy) ---\n#     def _entropy(p, eps=1e-12):\n#         p = np.clip(p, eps, 1.0)\n#         return -np.sum(p * np.log(p))\n\n#     H0, H1, H2 = _entropy(pred0), _entropy(pred1), _entropy(pred2)\n#     conf = np.exp(-np.array([H0, H1, H2]))          # Low H = high confidence → large\n#     conf = conf / conf.mean()                       # Normalized to mean 1\n#     # ---------------------------------------------------------------------------------------------\n#     beta = 0.35                                     # Effectiveness (light CV between 0.2 and 0.5)\n#     w_base = np.asarray([0.271, 0.347, 0.382])      # Fixed base\n#     wts = (w_base * (conf ** beta))                 #                         wts_J1\n#     wts_J1 = wts / wts.sum()                        # Total to 1\n#     # ---------------------------------------------------------------------------------------------\n#     beta = 0.374                                    # Effectiveness (light CV between 0.2 and 0.5)\n#     w_base2 = np.asarray([0.2705, 0.3474, 0.3821])  # Fixed base\n#     wts2 = (w_base2 * (conf ** beta))               #                         wts_J2\n#     wts_J2 = wts2 / wts2.sum()                      # Total to 1\n\n\n#     wts1, s,_,f = wts_J1,  0.9974, 1, 1.0041\n#     #-------------------------------------------------\n#     c1_123 = corr([f,s,_])\n#     c1_132 = corr([f,_,s])\n#     #---------------------------------------\n#     c1_213 = corr([s,f,_])\n#     c1_231 = corr([_,f,s])\n#     #-----------------------------\n#     c1_312 = corr([s,_,f])\n#     c1_321 = corr([_,s,f])\n#     #----------------------\n\n#     wts2, s,_,f = wts_J2,  0.9977, 1, 1.0038\n#     #-------------------------------------------------\n#     c2_123 = corr([f,s,_])\n#     c2_132 = corr([f,_,s])\n#     #---------------------------------------\n#     c2_213 = corr([s,f,_])\n#     c2_231 = corr([_,f,s])\n#     #-----------------------------\n#     c2_312 = corr([s,_,f])\n#     c2_321 = corr([_,s,f])\n#     #----------------------\n\n#     correct_wts_1, asc_desc_wts_1 = [+0.0021, -0.0007, -0.0014], [0.70, 0.30]\n#     correct_wts_2, asc_desc_wts_2 = [+0.0027, -0.0009, -0.0018], [0.74, 0.26]\n    \n#     preds = []\n#     eps = 1e-12\n#     for _a, _b, _c in zip(pred0, pred1, pred2):\n#         a1,b1,c1 = _a,_b,_c\n#         if   a1 <= b1 <= c1: _w1 = wts1 * c1_123\n#         elif a1 <= c1 <= b1: _w1 = wts1 * c1_132\n#         elif b1 <= a1 <= c1: _w1 = wts1 * c1_213\n#         elif b1 <= c1 <= a1: _w1 = wts1 * c1_231\n#         elif c1 <= a1 <= b1: _w1 = wts1 * c1_312\n#         else:                _w1 = wts1 * c1_321\n        \n#         # p1 = _w1[0]*np.log(a1 + eps) +\\\n#         #      _w1[1]*np.log(b1 + eps) +\\\n#         #      _w1[2]*np.log(c1 + eps)\n#         # ----------------------------------------- h-blend:\n#         l_abc = [\n#             { 'wts':_w1[0], 'pred':a1, 'result':0, 'n':'pred0' },\n#             { 'wts':_w1[1], 'pred':b1, 'result':0, 'n':'pred1' },\n#             { 'wts':_w1[2], 'pred':c1, 'result':0, 'n':'pred2' }]\n#         lps_asc  = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=False)\n#         lps_desc = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=True)\n#         for asc,correct_wt  in zip(lps_asc,  correct_wts_1): asc ['wts'] += correct_wt\n#         for desc,correct_wt in zip(lps_desc, correct_wts_1): desc['wts'] += correct_wt\n#         for asc  in lps_asc:  asc ['result'] = np.log(asc ['pred'] +eps) * asc ['wts']\n#         for desc in lps_desc: desc['result'] = np.log(desc['pred'] +eps) * desc['wts']\n#         result_asc  = sum([asc ['result'] for asc in lps_asc])\n#         result_desc = sum([desc['result'] for asc in lps_desc])\n#         result_1 =\\\n#             result_asc  * asc_desc_wts_1[0] + \\\n#             result_desc * asc_desc_wts_1[1]\n#         # =========================================\n\n#         a2,b2,c2 = _a,_b,_c\n#         if   c2 <= a2 <= b2: _w2 = wts2 * c2_312\n#         elif c2 <= b2 <= a2: _w2 = wts2 * c2_321\n#         elif b2 <= a2 <= c2: _w2 = wts2 * c2_213\n#         elif b2 <= c2 <= a2: _w2 = wts2 * c2_231\n#         elif a2 <= b2 <= c2: _w2 = wts2 * c2_123\n#         else               : _w2 = wts2 * c2_132\n        \n#         # p2 = _w2[0]*np.log(a2 + eps) +\\\n#         #      _w2[1]*np.log(b2 + eps) +\\\n#         #      _w2[2]*np.log(c2 + eps)\n#         # ----------------------------------------- h-blend\n#         l_abc = [\n#             { 'wts':_w2[0], 'pred':a2, 'result':0, 'n':'pred0' },\n#             { 'wts':_w2[1], 'pred':b2, 'result':0, 'n':'pred1' },\n#             { 'wts':_w2[2], 'pred':c2, 'result':0, 'n':'pred2' }]\n#         lps_asc  = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=False)\n#         lps_desc = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=True)\n#         for asc,correct_wt  in zip(lps_asc,  correct_wts_2): asc ['wts'] += correct_wt\n#         for desc,correct_wt in zip(lps_desc, correct_wts_2): desc['wts'] += correct_wt\n#         for asc  in lps_asc:  asc ['result'] = np.log(asc ['pred'] +eps) * asc ['wts']\n#         for desc in lps_desc: desc['result'] = np.log(desc['pred'] +eps) * desc['wts']\n#         result_asc  = sum([asc ['result'] for asc in lps_asc])\n#         result_desc = sum([desc['result'] for asc in lps_desc])\n#         result_2 =\\\n#             result_asc  * asc_desc_wts_2[0] + \\\n#             result_desc * asc_desc_wts_2[1]\n#         # =========================================\n\n#         result = (result_1 + result_2) / 2\n        \n#         preds.append(result)\n\n#     avg_pred = np.asarray(preds)\n\n#     return dataset.le.classes_[avg_pred.argmax()]\n\n\n# 5\n\n# import copy\n\n# def predict(sequence, demographics):\n    \n#     pred0 = predict1(sequence, demographics)[0]\n#     pred1 = predict2(sequence, demographics)[0]\n#     pred2 = predict3(sequence, demographics)[0]\n\n#     m_w,da_w,c_w = [0.271, 0.347, 0.382], [0.70, 0.30], [+0.0021,-0.0007,-0.0014]\n\n#     s,_,f = 0.9974, 1, 1.0041\n#     #-------------------------\n#     c1_123 = corr([f,s,_])\n#     c1_132 = corr([f,_,s])\n#     #------------------------\n#     c1_213 = corr([s,f,_])\n#     c1_231 = corr([_,f,s])\n#     #-----------------------\n#     c1_312 = corr([s,_,f])\n#     c1_321 = corr([_,s,f])\n#     #----------------------\n    \n#     wts1, preds = np.asarray(m_w), []\n    \n#     for _a, _b, _c in zip(pred0, pred1, pred2):\n#         a1,b1,c1 = _a,_b,_c\n#         if   a1 <= b1 <= c1: _w1 = wts1 * c1_123\n#         elif a1 <= c1 <= b1: _w1 = wts1 * c1_132\n#         elif b1 <= a1 <= c1: _w1 = wts1 * c1_213\n#         elif b1 <= c1 <= a1: _w1 = wts1 * c1_231\n#         elif c1 <= a1 <= b1: _w1 = wts1 * c1_312\n#         elif c1 <= b1 <= a1: _w1 = wts1 * c1_321\n\n#         l_abc = [\n#             { 'wts':_w1[0], 'pred':a1, 'res':0 },\n#             { 'wts':_w1[1], 'pred':b1, 'res':0 },\n#             { 'wts':_w1[2], 'pred':c1, 'res':0 },\n#         ]\n#         l_asc  = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=False)\n#         l_desc = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=True)\n        \n#         for asc, c_wts in zip(l_asc, c_w): asc ['res'] = asc ['pred'] * (asc ['wts'] +c_wts)\n#         for desc,c_wts in zip(l_desc,c_w): desc['res'] = desc['pred'] * (desc['wts'] +c_wts)\n\n#         result_asc  = sum([asc ['res'] for asc in l_asc])\n#         result_desc = sum([desc['res'] for asc in l_desc])\n\n#         result = result_asc * da_w[0] + da_w[1] * result_desc\n \n#         preds.append(result)\n#     avg_pred = np.asarray(preds)\n\n#     return dataset.le.classes_[avg_pred.argmax()]","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-13T02:56:48.020492Z","iopub.execute_input":"2025-08-13T02:56:48.020785Z","iopub.status.idle":"2025-08-13T02:56:48.051695Z","shell.execute_reply.started":"2025-08-13T02:56:48.020765Z","shell.execute_reply":"2025-08-13T02:56:48.051103Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## predict\n\nenumeration","metadata":{"papermill":{"duration":0.005605,"end_time":"2025-07-25T09:36:15.523281","exception":false,"start_time":"2025-07-25T09:36:15.517676","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import copy\n\ndef predict(sequence, demographics):\n    pred1 = predict1(sequence, demographics)[0]\n    pred2 = predict2(sequence, demographics)[0]\n    pred3 = predict3(sequence, demographics)[0]\n    pred4 = predict4(sequence, demographics)[0]\n    #------------------------------------------------\n    # main_wts     = [0.211, 0.248, 0.267, 0.274]  \n    # correct_wts  = [+0.0021,-0.0002,-0.0007,-0.0012]\t#  v33,  Lb=0.852  < prev.version\n    # asc_desc_wts = [0.70, 0.30]\n    \n    #------------------------------------------------\n    # main_wts     = [0.19, 0.25, 0.27, 0.29]  \n    # correct_wts  = [+0.0031,-0.0003,-0.0007,-0.0021]  #  v35,  Lb= ?\n    # asc_desc_wts = [0.70, 0.30]\n    #------------------------------------------------\n    main_wts     = [0.20, 0.25, 0.27, 0.28]  \n    correct_wts  = [+0.0041,-0.0004,-0.0012,-0.0025]  #  v36,  Lb= ?\n    asc_desc_wts = [0.70, 0.30]\n    #------------------------------------------------\n    # main_wts     = [0.22, 0.25, 0.27, 0.26]  \n    # correct_wts  = [+0.0051,-0.0005,-0.0017,-0.0029]  #  v37,  Lb= ?\n    # asc_desc_wts = [0.70, 0.30]\n    #------------------------------------------------\n\n    main_wts, preds = np.asarray(main_wts), []\n    \n    for a,b,c,d in zip(pred1,pred2,pred3,pred4):    \n        l_abc = [\n            { 'wts':main_wts[0], 'pred':a, 'result':0 },\n            { 'wts':main_wts[1], 'pred':b, 'result':0 },\n            { 'wts':main_wts[2], 'pred':c, 'result':0 },\n            { 'wts':main_wts[3], 'pred':d, 'result':0 },]\n\n        lps_asc  = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=False)\n        lps_desc = sorted(copy.deepcopy(l_abc), key=lambda _:_['pred'],reverse=True)\n        for asc, correct_wt in zip(lps_asc,  correct_wts): asc ['wts'] += correct_wt\n        for desc,correct_wt in zip(lps_desc, correct_wts): desc['wts'] += correct_wt \n        for asc  in lps_asc:  asc ['result'] = asc ['pred'] * asc ['wts']\n        for desc in lps_desc: desc['result'] = desc['pred'] * desc['wts']\n        result_asc  = sum([asc ['result'] for asc in lps_asc])\n        result_desc = sum([desc['result'] for asc in lps_desc])\n\n        result =\\\n            result_asc  * asc_desc_wts[0] + \\\n            result_desc * asc_desc_wts[1]\n        \n        preds.append(result)\n        \n    avg_pred =  np.asarray(preds)\n                \n    return dataset.le.classes_[avg_pred.argmax()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:56:48.054073Z","iopub.execute_input":"2025-08-13T02:56:48.054677Z","iopub.status.idle":"2025-08-13T02:56:48.076463Z","shell.execute_reply.started":"2025-08-13T02:56:48.054651Z","shell.execute_reply":"2025-08-13T02:56:48.075861Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2025-08-13T02:56:48.077334Z","iopub.execute_input":"2025-08-13T02:56:48.077537Z","iopub.status.idle":"2025-08-13T02:56:48.097853Z","shell.execute_reply.started":"2025-08-13T02:56:48.077521Z","shell.execute_reply":"2025-08-13T02:56:48.097214Z"},"papermill":{"duration":0.010567,"end_time":"2025-07-25T09:36:15.556256","exception":false,"start_time":"2025-07-25T09:36:15.545689","status":"completed"},"tags":[],"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import kaggle_evaluation.cmi_inference_server\ninference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        data_paths=(\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n        )\n    )","metadata":{"_cell_guid":"d950fdf3-997f-4502-92ff-83a5d2014717","_uuid":"46f1f772-fc94-4243-b3bd-d7b91e64b825","papermill":{"duration":35.841647,"end_time":"2025-07-25T09:36:51.403367","exception":false,"start_time":"2025-07-25T09:36:15.56172","status":"completed"},"tags":[],"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-08-13T02:56:48.098708Z","iopub.execute_input":"2025-08-13T02:56:48.098924Z","iopub.status.idle":"2025-08-13T02:57:30.027655Z","shell.execute_reply.started":"2025-08-13T02:56:48.098907Z","shell.execute_reply":"2025-08-13T02:57:30.026716Z"}},"outputs":[{"name":"stderr","text":"2025-08-13 02:56:49.718910: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\nI0000 00:00:1755053810.974594      96 cuda_dnn.cc:529] Loaded cuDNN version 90300\n2025-08-13 02:56:55.268073: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n2025-08-13 02:57:00.865444: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n2025-08-13 02:57:06.462404: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n2025-08-13 02:57:13.899047: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n2025-08-13 02:57:19.419247: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n2025-08-13 02:57:24.437201: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n2025-08-13 02:57:29.495023: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(pd.read_parquet(\"submission.parquet\"))","metadata":{"_cell_guid":"ea6c2fad-c06f-4df6-b86c-5338a51caa03","_uuid":"98acb9ec-5d49-4d58-9dac-a77f817acb3b","execution":{"iopub.status.busy":"2025-08-13T02:57:30.029151Z","iopub.execute_input":"2025-08-13T02:57:30.029523Z","iopub.status.idle":"2025-08-13T02:57:30.234345Z","shell.execute_reply.started":"2025-08-13T02:57:30.029503Z","shell.execute_reply":"2025-08-13T02:57:30.233500Z"},"papermill":{"duration":0.116493,"end_time":"2025-07-25T09:36:51.526358","exception":false,"start_time":"2025-07-25T09:36:51.409865","status":"completed"},"tags":[],"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"outputs":[{"name":"stdout","text":"  sequence_id              gesture\n0  SEQ_000011  Eyelash - pull hair\n1  SEQ_000001  Eyebrow - pull hair\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Result:\n\nScore: 0.852\n\nRank: 224 (2025-0813-16:00, JST)\n\nYour Best Entry!\nYour most recent submission scored 0.852, which is an improvement over your previous score of 0.851. Great job!\n\nRank 224. A small price to pay for my social life. #kaggle - https://kaggle.com/competitions/cmi-detect-behavior-with-sensor-data ","metadata":{}},{"cell_type":"markdown","source":"Laura Newman, David LoBue, Arianna Zuanazzi, Florian Rupprecht, Luke Mears, Roxanne McAdams, Erin Brown, Yanyi Wang, Camilla Strauss, Arno Klein, Lauren Hendrix, Maki Koyama, Josh To, Curt White, Yuki Kotani, Michelle Freund, Michael Milham, Gregory Kiar, Martyna Plomecka, Sohier Dane, and Maggie Demkin. CMI - Detect Behavior with Sensor Data. https://kaggle.com/competitions/cmi-detect-behavior-with-sensor-data, 2025. Kaggle.\n\n\n","metadata":{}}]}