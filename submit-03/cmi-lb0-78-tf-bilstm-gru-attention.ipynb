{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":12247490,"sourceType":"datasetVersion","datasetId":7717023},{"sourceId":242954653,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Original Notobook: \n\nhttps://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention","metadata":{}},{"cell_type":"markdown","source":"# Enhanced Features for Sensor Data Analysis\n\nHello everyone! I've managed to find four new features that significantly improve my model's score. Huge thanks to @rktqwe https://www.kaggle.com/code/rktqwe/lb-0-77-linear-accel-tf-bilstm-gru-attention for their previous work, which served as an excellent starting point.\n\n---\n\n## New Feature: Angular Velocity from Quaternion Derivatives\nI've added a new function, `calculate_angular_velocity_from_quat`, which computes **angular velocity ($\\omega$)** based on quaternion data (`rot_x`, `rot_y`, `rot_z`, `rot_w`).\n\n**Why is this needed?**\nWhile gyroscopes directly measure angular velocity, deriving it from quaternion data provides a smoother and more generalized estimate, especially when IMU filters are applied within the system. This metric helps to more accurately capture subtle differences in rotational movements, which is crucial for detailed analysis and gesture recognition in human-computer interaction applications.\n\n**How it works:**\n* **Input Data:** The function takes a sequence of quaternions (`rot_x`, `rot_y`, `rot_z`, `rot_w`) and a time step (`time_delta`, defaulting to 1/200 seconds, corresponding to a 200 Hz sampling rate).\n* **Step-by-step calculation:** For each pair of consecutive quaternions ($$q(t)$$ and $$q(t+\\Delta t)$$), the function:\n    * Converts the quaternions into `scipy.spatial.transform.Rotation` objects.\n    * Calculates the relative rotation between $$q(t)$$ and $$q(t+\\Delta t)$$ as $$\\Delta rot = q(t)^{-1} \\cdot q(t+\\Delta t)$$.\n    * Converts this relative rotation into a rotation vector, which represents the axis of rotation multiplied by the angle of rotation.\n    * Divides the resulting rotation vector by `time_delta` to obtain the angular velocity.\n\nThree new features have been included in the `imu_engineered_features` list:\n* `angular_vel_x`\n* `angular_vel_y`\n* `angular_vel_z`\n\n---\n\n## New Feature: Angular Distance/Displacement Between Quaternions\nThis is a metric that quantitatively defines the shortest angular separation between two orientations represented by quaternions. For two quaternions $$p$$ and $$q$$, the angular distance $$\\theta_z$$ can be calculated as $$\\theta_z = 2 \\cdot \\arccos(|real(p \\cdot q^*)|)$$.\n\n**Why is this needed?**\nThis feature is useful for measuring orientation change over a specific period or for comparing orientations, providing a direct representation of the magnitude of angular change. It complements angular velocity by showing not only the rate of change but also the total \"distance\" traveled between two points.\n\n**How it works:**\n* **Input Data:** The function takes a sequence of quaternions (`rot_x`, `rot_y`, `rot_z`, `rot_w`).\n* **Step-by-step calculation:** For each pair of consecutive quaternions ($$q_1$$ and $$q_2$$), the function:\n    * Converts the quaternions into `scipy.spatial.transform.Rotation` objects.\n    * Calculates the relative rotation between $$q_1$$ and $$q_2$$ (e.g., $$q_1^{-1} \\cdot q_2$$).\n    * Extracts the angle of this relative rotation, which represents the shortest angular distance between the two orientations.\n\nA new feature has been included in the `imu_engineered_features` list:\n* `angular_distance`\n\n---\n\nI hope this addition proves useful to the community!\n\nPlease upvote this notebook if you find it helpful!","metadata":{}},{"cell_type":"markdown","source":"### 》》》**Importing the necessary Libraries**","metadata":{}},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n    Lambda, Concatenate, GRU, GaussianNoise\n)\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport polars as pl\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom scipy.spatial.transform import Rotation as R\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:30.981497Z","iopub.execute_input":"2025-06-24T14:42:30.981748Z","iopub.status.idle":"2025-06-24T14:42:46.860008Z","shell.execute_reply.started":"2025-06-24T14:42:30.981725Z","shell.execute_reply":"2025-06-24T14:42:46.859477Z"}},"outputs":[{"name":"stderr","text":"2025-06-24 14:42:34.958239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750776155.166922      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750776155.221840      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 》》》**Fix Seed**","metadata":{}},{"cell_type":"code","source":"import random\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nseed_everything(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.860704Z","iopub.execute_input":"2025-06-24T14:42:46.861178Z","iopub.status.idle":"2025-06-24T14:42:46.865787Z","shell.execute_reply.started":"2025-06-24T14:42:46.861158Z","shell.execute_reply":"2025-06-24T14:42:46.865090Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### 》》》**Configuration**","metadata":{}},{"cell_type":"code","source":"# (Competition metric will only be imported when TRAINing)\nTRAIN = True                     # ← set to True when you want to train\nRAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\nPRETRAINED_DIR = Path(\"/kaggle/input/yoga-dist-quat\")  # used when TRAIN=False\nEXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\nBATCH_SIZE = 64\nPAD_PERCENTILE = 95\nLR_INIT = 5e-4\nWD = 3e-3\nMIXUP_ALPHA = 0.4\nEPOCHS = 160\nPATIENCE = 40\n\n\nprint(\"▶ imports ready · tensorflow\", tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.867526Z","iopub.execute_input":"2025-06-24T14:42:46.867726Z","iopub.status.idle":"2025-06-24T14:42:46.889893Z","shell.execute_reply.started":"2025-06-24T14:42:46.867710Z","shell.execute_reply":"2025-06-24T14:42:46.889210Z"}},"outputs":[{"name":"stdout","text":"▶ imports ready · tensorflow 2.18.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 》》》**Utility Functions**","metadata":{}},{"cell_type":"code","source":"#Tensor Manipulations\ndef time_sum(x):\n    return K.sum(x, axis=1)\n\ndef squeeze_last_axis(x):\n    return tf.squeeze(x, axis=-1)\n\ndef expand_last_axis(x):\n    return tf.expand_dims(x, axis=-1)\n\ndef se_block(x, reduction=8):\n    ch = x.shape[-1]\n    se = GlobalAveragePooling1D()(x)\n    se = Dense(ch // reduction, activation='relu')(se)\n    se = Dense(ch, activation='sigmoid')(se)\n    se = Reshape((1, ch))(se)\n    return Multiply()([x, se])\n\n# Residual CNN Block with SE\ndef residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n    shortcut = x\n    for _ in range(2):\n        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n                   kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n    x = se_block(x)\n    if shortcut.shape[-1] != filters:\n        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n                          kernel_regularizer=l2(wd))(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n    x = add([x, shortcut])\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size)(x)\n    x = Dropout(drop)(x)\n    return x\n\ndef attention_layer(inputs):\n    score = Dense(1, activation='tanh')(inputs)\n    score = Lambda(squeeze_last_axis)(score)\n    weights = Activation('softmax')(score)\n    weights = Lambda(expand_last_axis)(weights)\n    context = Multiply()([inputs, weights])\n    context = Lambda(time_sum)(context)\n    return context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.890624Z","iopub.execute_input":"2025-06-24T14:42:46.890895Z","iopub.status.idle":"2025-06-24T14:42:46.905986Z","shell.execute_reply.started":"2025-06-24T14:42:46.890877Z","shell.execute_reply":"2025-06-24T14:42:46.905365Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 》》》**Data Helpers**","metadata":{}},{"cell_type":"code","source":"# Normalizes and cleans the time series sequence. \n\ndef preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n    return scaler.transform(mat).astype('float32')\n\n# MixUp the data argumentation in order to regularize the neural network. \n\nclass MixupGenerator(Sequence):\n    def __init__(self, X, y, batch_size, alpha=0.2):\n        self.X, self.y = X, y\n        self.batch = batch_size\n        self.alpha = alpha\n        self.indices = np.arange(len(X))\n    def __len__(self):\n        return int(np.ceil(len(self.X) / self.batch))\n    def __getitem__(self, i):\n        idx = self.indices[i*self.batch:(i+1)*self.batch]\n        Xb, yb = self.X[idx], self.y[idx]\n        lam = np.random.beta(self.alpha, self.alpha)\n        perm = np.random.permutation(len(Xb))\n        X_mix = lam * Xb + (1-lam) * Xb[perm]\n        y_mix = lam * yb + (1-lam) * yb[perm]\n        return X_mix, y_mix\n    def on_epoch_end(self):\n        np.random.shuffle(self.indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.906680Z","iopub.execute_input":"2025-06-24T14:42:46.906896Z","iopub.status.idle":"2025-06-24T14:42:46.927048Z","shell.execute_reply.started":"2025-06-24T14:42:46.906882Z","shell.execute_reply":"2025-06-24T14:42:46.926545Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def remove_gravity_from_acc(acc_data, rot_data):\n\n    if isinstance(acc_data, pd.DataFrame):\n        acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n    else:\n        acc_values = acc_data\n\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = acc_values.shape[0]\n    linear_accel = np.zeros_like(acc_values)\n    \n    gravity_world = np.array([0, 0, 9.81])\n\n    for i in range(num_samples):\n        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n            linear_accel[i, :] = acc_values[i, :] \n            continue\n\n        try:\n            rotation = R.from_quat(quat_values[i])\n            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n        except ValueError:\n             linear_accel[i, :] = acc_values[i, :]\n             \n    return linear_accel\n\ndef calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = quat_values.shape[0]\n    angular_vel = np.zeros((num_samples, 3))\n\n    for i in range(num_samples - 1):\n        q_t = quat_values[i]\n        q_t_plus_dt = quat_values[i+1]\n\n        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n            continue\n\n        try:\n            rot_t = R.from_quat(q_t)\n            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n\n            # Calculate the relative rotation\n            delta_rot = rot_t.inv() * rot_t_plus_dt\n            \n            # Convert delta rotation to angular velocity vector\n            # The rotation vector (Euler axis * angle) scaled by 1/dt\n            # is a good approximation for small delta_rot\n            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n        except ValueError:\n            # If quaternion is invalid, angular velocity remains zero\n            pass\n            \n    return angular_vel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.927827Z","iopub.execute_input":"2025-06-24T14:42:46.928063Z","iopub.status.idle":"2025-06-24T14:42:46.947088Z","shell.execute_reply.started":"2025-06-24T14:42:46.928044Z","shell.execute_reply":"2025-06-24T14:42:46.946469Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def calculate_angular_distance(rot_data):\n    if isinstance(rot_data, pd.DataFrame):\n        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n    else:\n        quat_values = rot_data\n\n    num_samples = quat_values.shape[0]\n    angular_dist = np.zeros(num_samples)\n\n    for i in range(num_samples - 1):\n        q1 = quat_values[i]\n        q2 = quat_values[i+1]\n\n        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n            continue\n        try:\n            # Преобразование кватернионов в объекты Rotation\n            r1 = R.from_quat(q1)\n            r2 = R.from_quat(q2)\n\n            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n            # где p* - сопряженный кватернион q\n            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n            # Угол этого относительного вращения - это и есть угловое расстояние.\n            relative_rotation = r1.inv() * r2\n            \n            # Угол rotation vector соответствует угловому расстоянию\n            # Норма rotation vector - это угол в радианах\n            angle = np.linalg.norm(relative_rotation.as_rotvec())\n            angular_dist[i] = angle\n        except ValueError:\n            angular_dist[i] = 0 # В случае недействительных кватернионов\n            pass\n            \n    return angular_dist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.947683Z","iopub.execute_input":"2025-06-24T14:42:46.947885Z","iopub.status.idle":"2025-06-24T14:42:46.965109Z","shell.execute_reply.started":"2025-06-24T14:42:46.947867Z","shell.execute_reply":"2025-06-24T14:42:46.964533Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### 》》》**Model Definition - Two Branch Architecture**","metadata":{}},{"cell_type":"code","source":"def build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n\n    # IMU deep branch\n    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n\n    # TOF/Thermal lighter branch\n    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n\n    merged = Concatenate()([x1, x2])\n\n    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n    xc = GaussianNoise(0.09)(merged)\n    xc = Dense(16, activation='elu')(xc)\n    \n    x = Concatenate()([xa, xb, xc])\n    x = Dropout(0.4)(x)\n    x = attention_layer(x)\n\n    for units, drop in [(256, 0.5), (128, 0.3)]:\n        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n        x = BatchNormalization()(x); x = Activation('relu')(x)\n        x = Dropout(drop)(x)\n\n    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n    return Model(inp, out)\n\ntmp_model = build_two_branch_model(127,7,325,18)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:46.965711Z","iopub.execute_input":"2025-06-24T14:42:46.965973Z","iopub.status.idle":"2025-06-24T14:42:49.931035Z","shell.execute_reply.started":"2025-06-24T14:42:46.965950Z","shell.execute_reply":"2025-06-24T14:42:49.930272Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1750776168.048564      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 》》》**Training / Inference Pipeline**","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    print(\"▶ TRAIN MODE – loading dataset …\")\n    df = pd.read_csv(RAW_DIR / \"train.csv\")\n\n    train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n    df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n\n    le = LabelEncoder()\n    df['gesture_int'] = le.fit_transform(df['gesture'])\n    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n    gesture_classes = le.classes_\n\n    print(\"  Calculating base engineered IMU features (magnitude, angle)...\")\n    df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n    df['rot_angle'] = 2 * np.arccos(df['rot_w'].clip(-1, 1))\n    \n    print(\"  Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag...\")\n    df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n    df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n\n    print(\"  Removing gravity and calculating linear acceleration features...\")\n    \n    linear_accel_list = []\n    for _, group in df.groupby('sequence_id'):\n        acc_data_group = group[['acc_x', 'acc_y', 'acc_z']]\n        rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n        linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n        linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index))\n    \n    df_linear_accel = pd.concat(linear_accel_list)\n    df = pd.concat([df, df_linear_accel], axis=1)\n\n    df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n    df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n\n    print(\"  Calculating angular velocity from quaternion derivatives...\")\n    angular_vel_list = []\n    for _, group in df.groupby('sequence_id'):\n        rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n        angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n        angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index))\n    \n    df_angular_vel = pd.concat(angular_vel_list)\n    df = pd.concat([df, df_angular_vel], axis=1)\n\n    print(\"  Calculating angular distance between successive quaternions...\")\n    angular_distance_list = []\n    for _, group in df.groupby('sequence_id'):\n        rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]\n        angular_dist_group = calculate_angular_distance(rot_data_group)\n        angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['angular_distance'], index=group.index))\n    \n    df_angular_distance = pd.concat(angular_distance_list)\n    df = pd.concat([df, df_angular_distance], axis=1)\n\n    meta_cols = { } # This was an empty dict in your provided code, keeping it as is.\n\n    imu_cols_base = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n    imu_cols_base.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n    \n    imu_engineered_features = [\n        'acc_mag', 'rot_angle',\n        'acc_mag_jerk', 'rot_angle_vel',\n        'linear_acc_mag', 'linear_acc_mag_jerk',\n        'angular_vel_x', 'angular_vel_y', 'angular_vel_z', # Existing new features\n        'angular_distance' # Added new feature\n    ]\n    imu_cols = imu_cols_base + imu_engineered_features\n    imu_cols = list(dict.fromkeys(imu_cols)) # Для удаления дубликатов\n\n    thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n    \n    tof_aggregated_cols_template = []\n    for i in range(1, 6):\n        tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n\n    final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n    imu_dim_final = len(imu_cols)\n    tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n    \n    print(f\"  IMU (incl. engineered & derivatives) {imu_dim_final} | THM + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n\n    print(\"  Building sequences with aggregated TOF and preparing data for scaler...\")\n    seq_gp = df.groupby('sequence_id') \n    \n    all_steps_for_scaler_list = []\n    X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n\n    for seq_id, seq_df_orig in seq_gp:\n        seq_df = seq_df_orig.copy()\n\n        for i in range(1, 6):\n            pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n            tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n            seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n            seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n            seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n            seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n        \n        mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n        \n        all_steps_for_scaler_list.append(mat_unscaled)\n        X_list_unscaled.append(mat_unscaled)\n        y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n        lens.append(len(mat_unscaled))\n\n    print(\"  Fitting StandardScaler...\")\n    all_steps_concatenated = np.concatenate(all_steps_for_scaler_list, axis=0)\n    scaler = StandardScaler().fit(all_steps_concatenated)\n    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n    del all_steps_for_scaler_list, all_steps_concatenated\n\n    print(\"  Scaling and padding sequences...\")\n    X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n    del X_list_unscaled\n\n    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n    np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n    \n    X = pad_sequences(X_scaled_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    del X_scaled_list\n    \n    y_int_for_stratify = np.array(y_list_int_for_stratify)\n    y = to_categorical(y_int_for_stratify, num_classes=len(le.classes_))\n\n    print(\"  Splitting data and preparing for training...\")\n    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=82, stratify=y_int_for_stratify)\n\n    cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_int_for_stratify)\n    class_weight = dict(enumerate(cw_vals))\n\n    model = build_two_branch_model(pad_len, imu_dim_final, tof_thm_aggregated_dim_final, len(le.classes_), wd=WD)\n    \n    steps = len(X_tr) // BATCH_SIZE\n    lr_sched = tf.keras.optimizers.schedules.CosineDecayRestarts(5e-4, first_decay_steps=15 * steps) \n    \n    model.compile(optimizer=Adam(lr_sched),\n                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n                  metrics=['accuracy'])\n\n    train_gen = MixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, alpha=MIXUP_ALPHA)\n    cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_accuracy', mode='max')\n    \n    print(\"  Starting model training...\")\n    model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val),\n              class_weight=class_weight, callbacks=[cb], verbose=1)\n\n    model.save(EXPORT_DIR / \"gesture_two_branch_mixup.h5\")\n    print(\"✔ Training done – artefacts saved in\", EXPORT_DIR)\n\n    from cmi_2025_metric_copy_for_import import CompetitionMetric\n    preds_val = model.predict(X_val).argmax(1)\n    true_val_int  = y_val.argmax(1)\n    \n    h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n        pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n        pd.DataFrame({'gesture': le.classes_[preds_val]}))\n    print(\"Hold‑out H‑F1 =\", round(h_f1, 4))\nelse:\n    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n    pad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n    scaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n\n    # Re-calculate imu_dim_final based on the actual features that will be used\n    # Убедитесь, что 'angular_distance' учитывается здесь при инференсе\n    imu_features_in_final_cols = [c for c in final_feature_cols if any(c.startswith(prefix) for prefix in ['linear_acc_', 'acc_', 'rot_', 'angular_vel_', 'angular_distance'])]\n    imu_dim_final = len(imu_features_in_final_cols)\n\n    tof_thm_aggregated_dim_final = len(final_feature_cols) - imu_dim_final\n\n    custom_objs = {\n        'time_sum': time_sum,\n        'squeeze_last_axis': squeeze_last_axis,\n        'expand_last_axis': expand_last_axis,\n        'se_block': se_block,\n        'residual_se_cnn_block': residual_se_cnn_block,\n        'attention_layer': attention_layer,\n    }\n    model = load_model(PRETRAINED_DIR / \"gesture_two_branch_mixup.h5\",\n                       compile=False, custom_objects=custom_objs)\n    print(\"  Model, scaler, feature_cols, pad_len loaded – ready for evaluation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:42:49.933463Z","iopub.execute_input":"2025-06-24T14:42:49.933675Z","iopub.status.idle":"2025-06-24T14:58:50.573682Z","shell.execute_reply.started":"2025-06-24T14:42:49.933659Z","shell.execute_reply":"2025-06-24T14:58:50.572899Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"▶ TRAIN MODE – loading dataset …\n  Calculating base engineered IMU features (magnitude, angle)...\n  Calculating engineered IMU derivatives (jerk, angular velocity) for original acc_mag...\n  Removing gravity and calculating linear acceleration features...\n  Calculating angular velocity from quaternion derivatives...\n  Calculating angular distance between successive quaternions...\n  IMU (incl. engineered & derivatives) 17 | THM + Aggregated TOF 25 | total 42 features\n  Building sequences with aggregated TOF and preparing data for scaler...\n  Fitting StandardScaler...\n  Scaling and padding sequences...\n  Splitting data and preparing for training...\n  Starting model training...\nEpoch 1/160\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750776537.180390      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m101/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1137 - loss: 9.7810","output_type":"stream"},{"name":"stderr","text":"2025-06-24 14:49:03.797798: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 56ms/step - accuracy: 0.1145 - loss: 9.7683 - val_accuracy: 0.3519 - val_loss: 7.9653\nEpoch 2/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.2737 - loss: 7.5257 - val_accuracy: 0.4525 - val_loss: 6.3210\nEpoch 3/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.3551 - loss: 6.3136 - val_accuracy: 0.4972 - val_loss: 5.3221\nEpoch 4/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4234 - loss: 5.4389 - val_accuracy: 0.5297 - val_loss: 4.6254\nEpoch 5/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4608 - loss: 4.8216 - val_accuracy: 0.5438 - val_loss: 4.1509\nEpoch 6/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4854 - loss: 4.4133 - val_accuracy: 0.5506 - val_loss: 3.8155\nEpoch 7/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4869 - loss: 4.1468 - val_accuracy: 0.5794 - val_loss: 3.5640\nEpoch 8/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5031 - loss: 3.9067 - val_accuracy: 0.5794 - val_loss: 3.3978\nEpoch 9/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5304 - loss: 3.6905 - val_accuracy: 0.5855 - val_loss: 3.2637\nEpoch 10/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5384 - loss: 3.5719 - val_accuracy: 0.6150 - val_loss: 3.1252\nEpoch 11/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5562 - loss: 3.4962 - val_accuracy: 0.6217 - val_loss: 3.0692\nEpoch 12/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5599 - loss: 3.4211 - val_accuracy: 0.6321 - val_loss: 3.0075\nEpoch 13/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5938 - loss: 3.3145 - val_accuracy: 0.6487 - val_loss: 2.9698\nEpoch 14/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5795 - loss: 3.3274 - val_accuracy: 0.6407 - val_loss: 2.9591\nEpoch 15/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5910 - loss: 3.2619 - val_accuracy: 0.5874 - val_loss: 3.0312\nEpoch 16/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5187 - loss: 3.3808 - val_accuracy: 0.5812 - val_loss: 2.8865\nEpoch 17/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5767 - loss: 3.0981 - val_accuracy: 0.5776 - val_loss: 2.7056\nEpoch 18/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5517 - loss: 2.9735 - val_accuracy: 0.5966 - val_loss: 2.5193\nEpoch 19/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5773 - loss: 2.8073 - val_accuracy: 0.5855 - val_loss: 2.4774\nEpoch 20/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5783 - loss: 2.6477 - val_accuracy: 0.6033 - val_loss: 2.3261\nEpoch 21/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5800 - loss: 2.6225 - val_accuracy: 0.6217 - val_loss: 2.2378\nEpoch 22/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.6142 - loss: 2.4137 - val_accuracy: 0.6248 - val_loss: 2.1477\nEpoch 23/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6437 - loss: 2.2992 - val_accuracy: 0.6413 - val_loss: 2.0456\nEpoch 24/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6365 - loss: 2.2905 - val_accuracy: 0.6413 - val_loss: 1.9755\nEpoch 25/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6478 - loss: 2.2294 - val_accuracy: 0.6487 - val_loss: 1.9405\nEpoch 26/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6465 - loss: 2.1245 - val_accuracy: 0.6327 - val_loss: 1.9224\nEpoch 27/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6264 - loss: 2.2419 - val_accuracy: 0.6750 - val_loss: 1.8284\nEpoch 28/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6754 - loss: 2.0803 - val_accuracy: 0.6763 - val_loss: 1.8471\nEpoch 29/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6834 - loss: 1.9891 - val_accuracy: 0.6879 - val_loss: 1.7707\nEpoch 30/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6685 - loss: 2.0173 - val_accuracy: 0.6983 - val_loss: 1.6891\nEpoch 31/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6858 - loss: 2.0083 - val_accuracy: 0.7094 - val_loss: 1.6721\nEpoch 32/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6804 - loss: 2.0164 - val_accuracy: 0.7045 - val_loss: 1.6476\nEpoch 33/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6962 - loss: 1.9944 - val_accuracy: 0.7204 - val_loss: 1.6322\nEpoch 34/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7005 - loss: 1.8968 - val_accuracy: 0.7174 - val_loss: 1.6523\nEpoch 35/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7029 - loss: 1.8846 - val_accuracy: 0.7315 - val_loss: 1.5880\nEpoch 36/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7585 - loss: 1.7763 - val_accuracy: 0.7247 - val_loss: 1.5823\nEpoch 37/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7609 - loss: 1.7183 - val_accuracy: 0.7278 - val_loss: 1.5390\nEpoch 38/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7463 - loss: 1.7707 - val_accuracy: 0.7456 - val_loss: 1.5235\nEpoch 39/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7710 - loss: 1.6820 - val_accuracy: 0.7480 - val_loss: 1.5090\nEpoch 40/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7670 - loss: 1.6975 - val_accuracy: 0.7468 - val_loss: 1.5056\nEpoch 41/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7771 - loss: 1.6656 - val_accuracy: 0.7505 - val_loss: 1.4974\nEpoch 42/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7670 - loss: 1.7253 - val_accuracy: 0.7486 - val_loss: 1.4935\nEpoch 43/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7563 - loss: 1.8074 - val_accuracy: 0.7541 - val_loss: 1.4930\nEpoch 44/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7491 - loss: 1.7901 - val_accuracy: 0.7548 - val_loss: 1.4907\nEpoch 45/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7590 - loss: 1.7869 - val_accuracy: 0.5254 - val_loss: 2.0749\nEpoch 46/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6349 - loss: 2.0479 - val_accuracy: 0.6665 - val_loss: 1.7082\nEpoch 47/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6308 - loss: 2.0669 - val_accuracy: 0.6757 - val_loss: 1.6850\nEpoch 48/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6662 - loss: 1.9645 - val_accuracy: 0.6358 - val_loss: 1.7582\nEpoch 49/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6583 - loss: 1.9970 - val_accuracy: 0.6033 - val_loss: 1.8424\nEpoch 50/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6747 - loss: 1.9103 - val_accuracy: 0.6677 - val_loss: 1.7603\nEpoch 51/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6945 - loss: 1.8670 - val_accuracy: 0.6855 - val_loss: 1.6563\nEpoch 52/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7132 - loss: 1.8322 - val_accuracy: 0.6879 - val_loss: 1.7061\nEpoch 53/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6975 - loss: 1.9201 - val_accuracy: 0.6842 - val_loss: 1.6527\nEpoch 54/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6907 - loss: 1.8409 - val_accuracy: 0.6211 - val_loss: 1.7315\nEpoch 55/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7080 - loss: 1.7846 - val_accuracy: 0.6941 - val_loss: 1.6187\nEpoch 56/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7197 - loss: 1.8420 - val_accuracy: 0.6824 - val_loss: 1.6763\nEpoch 57/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7093 - loss: 1.8290 - val_accuracy: 0.6824 - val_loss: 1.6256\nEpoch 58/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6974 - loss: 1.8873 - val_accuracy: 0.6855 - val_loss: 1.6279\nEpoch 59/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7129 - loss: 1.8091 - val_accuracy: 0.7057 - val_loss: 1.5452\nEpoch 60/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7213 - loss: 1.8033 - val_accuracy: 0.6818 - val_loss: 1.6271\nEpoch 61/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7047 - loss: 1.8061 - val_accuracy: 0.6591 - val_loss: 1.6264\nEpoch 62/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7071 - loss: 1.8135 - val_accuracy: 0.6867 - val_loss: 1.5900\nEpoch 63/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7275 - loss: 1.7858 - val_accuracy: 0.7259 - val_loss: 1.4987\nEpoch 64/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7359 - loss: 1.7479 - val_accuracy: 0.7026 - val_loss: 1.5103\nEpoch 65/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7339 - loss: 1.7528 - val_accuracy: 0.7174 - val_loss: 1.5525\nEpoch 66/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7391 - loss: 1.7131 - val_accuracy: 0.7216 - val_loss: 1.5024\nEpoch 67/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7510 - loss: 1.7103 - val_accuracy: 0.6996 - val_loss: 1.5388\nEpoch 68/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7613 - loss: 1.6988 - val_accuracy: 0.7333 - val_loss: 1.4823\nEpoch 69/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7446 - loss: 1.7347 - val_accuracy: 0.7149 - val_loss: 1.4881\nEpoch 70/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7711 - loss: 1.6322 - val_accuracy: 0.7075 - val_loss: 1.5181\nEpoch 71/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7581 - loss: 1.6467 - val_accuracy: 0.7437 - val_loss: 1.4653\nEpoch 72/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7326 - loss: 1.7642 - val_accuracy: 0.7449 - val_loss: 1.4257\nEpoch 73/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7813 - loss: 1.6549 - val_accuracy: 0.7357 - val_loss: 1.4544\nEpoch 74/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7379 - loss: 1.7311 - val_accuracy: 0.7327 - val_loss: 1.4602\nEpoch 75/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7867 - loss: 1.6056 - val_accuracy: 0.7578 - val_loss: 1.4050\nEpoch 76/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7930 - loss: 1.5402 - val_accuracy: 0.6554 - val_loss: 1.6637\nEpoch 77/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7792 - loss: 1.6559 - val_accuracy: 0.7394 - val_loss: 1.4019\nEpoch 78/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7760 - loss: 1.6133 - val_accuracy: 0.7468 - val_loss: 1.4204\nEpoch 79/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7671 - loss: 1.6151 - val_accuracy: 0.7676 - val_loss: 1.3681\nEpoch 80/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8006 - loss: 1.5686 - val_accuracy: 0.7492 - val_loss: 1.3886\nEpoch 81/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8101 - loss: 1.5539 - val_accuracy: 0.7621 - val_loss: 1.3887\nEpoch 82/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8246 - loss: 1.5284 - val_accuracy: 0.7615 - val_loss: 1.3488\nEpoch 83/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8161 - loss: 1.4934 - val_accuracy: 0.7486 - val_loss: 1.3729\nEpoch 84/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8176 - loss: 1.5491 - val_accuracy: 0.7738 - val_loss: 1.3549\nEpoch 85/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8287 - loss: 1.5055 - val_accuracy: 0.7781 - val_loss: 1.3391\nEpoch 86/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8461 - loss: 1.4453 - val_accuracy: 0.7781 - val_loss: 1.3467\nEpoch 87/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7981 - loss: 1.5240 - val_accuracy: 0.7676 - val_loss: 1.3619\nEpoch 88/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8330 - loss: 1.5229 - val_accuracy: 0.7866 - val_loss: 1.3042\nEpoch 89/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8126 - loss: 1.5101 - val_accuracy: 0.7964 - val_loss: 1.2728\nEpoch 90/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8146 - loss: 1.5514 - val_accuracy: 0.7817 - val_loss: 1.3090\nEpoch 91/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8576 - loss: 1.4090 - val_accuracy: 0.7731 - val_loss: 1.3258\nEpoch 92/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8566 - loss: 1.4356 - val_accuracy: 0.7774 - val_loss: 1.3073\nEpoch 93/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8671 - loss: 1.4587 - val_accuracy: 0.7842 - val_loss: 1.2931\nEpoch 94/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8198 - loss: 1.5198 - val_accuracy: 0.7842 - val_loss: 1.3025\nEpoch 95/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8104 - loss: 1.5375 - val_accuracy: 0.7903 - val_loss: 1.2780\nEpoch 96/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8660 - loss: 1.4251 - val_accuracy: 0.7977 - val_loss: 1.2784\nEpoch 97/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8321 - loss: 1.5130 - val_accuracy: 0.7995 - val_loss: 1.2753\nEpoch 98/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8422 - loss: 1.4617 - val_accuracy: 0.7922 - val_loss: 1.2843\nEpoch 99/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8406 - loss: 1.4800 - val_accuracy: 0.7977 - val_loss: 1.2750\nEpoch 100/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8661 - loss: 1.4538 - val_accuracy: 0.8007 - val_loss: 1.2649\nEpoch 101/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8645 - loss: 1.3816 - val_accuracy: 0.8020 - val_loss: 1.2675\nEpoch 102/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8720 - loss: 1.4273 - val_accuracy: 0.8038 - val_loss: 1.2676\nEpoch 103/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8269 - loss: 1.5726 - val_accuracy: 0.8001 - val_loss: 1.2677\nEpoch 104/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8683 - loss: 1.4307 - val_accuracy: 0.7198 - val_loss: 1.4581\nEpoch 105/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7629 - loss: 1.5805 - val_accuracy: 0.6708 - val_loss: 1.6658\nEpoch 106/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7287 - loss: 1.8119 - val_accuracy: 0.6505 - val_loss: 1.7094\nEpoch 107/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6827 - loss: 1.8772 - val_accuracy: 0.6726 - val_loss: 1.6808\nEpoch 108/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6892 - loss: 1.8527 - val_accuracy: 0.6272 - val_loss: 1.7964\nEpoch 109/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7407 - loss: 1.7348 - val_accuracy: 0.6879 - val_loss: 1.6719\nEpoch 110/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7263 - loss: 1.7189 - val_accuracy: 0.7174 - val_loss: 1.5307\nEpoch 111/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7182 - loss: 1.8079 - val_accuracy: 0.7063 - val_loss: 1.5780\nEpoch 112/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7615 - loss: 1.6349 - val_accuracy: 0.7241 - val_loss: 1.5481\nEpoch 113/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7630 - loss: 1.6508 - val_accuracy: 0.6842 - val_loss: 1.6089\nEpoch 114/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7492 - loss: 1.6793 - val_accuracy: 0.7088 - val_loss: 1.5016\nEpoch 115/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7673 - loss: 1.6307 - val_accuracy: 0.6861 - val_loss: 1.6039\nEpoch 116/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7560 - loss: 1.7138 - val_accuracy: 0.7376 - val_loss: 1.4859\nEpoch 117/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7689 - loss: 1.6492 - val_accuracy: 0.6977 - val_loss: 1.5762\nEpoch 118/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7612 - loss: 1.6893 - val_accuracy: 0.7223 - val_loss: 1.4973\nEpoch 119/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7685 - loss: 1.6084 - val_accuracy: 0.7094 - val_loss: 1.5326\nEpoch 120/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7408 - loss: 1.7149 - val_accuracy: 0.7253 - val_loss: 1.5215\nEpoch 121/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7761 - loss: 1.6633 - val_accuracy: 0.7382 - val_loss: 1.4653\nEpoch 122/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7488 - loss: 1.6951 - val_accuracy: 0.7486 - val_loss: 1.4266\nEpoch 123/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7459 - loss: 1.7161 - val_accuracy: 0.7364 - val_loss: 1.4938\nEpoch 124/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7510 - loss: 1.6617 - val_accuracy: 0.7045 - val_loss: 1.5543\nEpoch 125/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8080 - loss: 1.5641 - val_accuracy: 0.7155 - val_loss: 1.5335\nEpoch 126/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7929 - loss: 1.5057 - val_accuracy: 0.7327 - val_loss: 1.4926\nEpoch 127/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8028 - loss: 1.5248 - val_accuracy: 0.7339 - val_loss: 1.4902\nEpoch 128/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7607 - loss: 1.7108 - val_accuracy: 0.6812 - val_loss: 1.5853\nEpoch 129/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7943 - loss: 1.6138 - val_accuracy: 0.7039 - val_loss: 1.5179\nEpoch 130/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7974 - loss: 1.5467 - val_accuracy: 0.7204 - val_loss: 1.5387\nEpoch 131/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7862 - loss: 1.6477 - val_accuracy: 0.6861 - val_loss: 1.5862\nEpoch 132/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7699 - loss: 1.6442 - val_accuracy: 0.7204 - val_loss: 1.5245\nEpoch 133/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8004 - loss: 1.5679 - val_accuracy: 0.7615 - val_loss: 1.4102\nEpoch 134/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7882 - loss: 1.5997 - val_accuracy: 0.7566 - val_loss: 1.4425\nEpoch 135/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8031 - loss: 1.5354 - val_accuracy: 0.7327 - val_loss: 1.4734\nEpoch 136/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7765 - loss: 1.6635 - val_accuracy: 0.7094 - val_loss: 1.5562\nEpoch 137/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8192 - loss: 1.5453 - val_accuracy: 0.7174 - val_loss: 1.4709\nEpoch 138/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8002 - loss: 1.6537 - val_accuracy: 0.7216 - val_loss: 1.5148\nEpoch 139/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8120 - loss: 1.5854 - val_accuracy: 0.7474 - val_loss: 1.4309\nEpoch 140/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7648 - loss: 1.6857 - val_accuracy: 0.7186 - val_loss: 1.5024\nEpoch 141/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8051 - loss: 1.6129 - val_accuracy: 0.7523 - val_loss: 1.4295\nEpoch 142/160\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8086 - loss: 1.5627 - val_accuracy: 0.7492 - val_loss: 1.4598\nEpoch 142: early stopping\nRestoring model weights from the end of the best epoch: 102.\n✔ Training done – artefacts saved in .\n","output_type":"stream"},{"name":"stderr","text":"2025-06-24 14:58:47.992029: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step\nHold‑out H‑F1 = 0.878\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 》》》**Predict**","metadata":{}},{"cell_type":"code","source":"def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n    df_seq = sequence.to_pandas()\n\n    df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2)\n    df_seq['rot_angle'] = 2 * np.arccos(df_seq['rot_w'].clip(-1, 1))\n    df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0)\n    df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0)\n\n    acc_cols_for_gravity_removal = ['acc_x', 'acc_y', 'acc_z']\n    rot_cols_for_gravity_removal = ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n\n    if not all(col in df_seq.columns for col in acc_cols_for_gravity_removal + rot_cols_for_gravity_removal):\n        print(f\"Warning: Missing raw acc/rot columns for gravity removal in predict for sequence. Using raw acc as linear.\")\n        df_seq['linear_acc_x'] = df_seq.get('acc_x', 0)\n        df_seq['linear_acc_y'] = df_seq.get('acc_y', 0)\n        df_seq['linear_acc_z'] = df_seq.get('acc_z', 0)\n    else:\n        acc_data_seq = df_seq[acc_cols_for_gravity_removal]\n        rot_data_seq = df_seq[rot_cols_for_gravity_removal]\n        linear_accel_seq_arr = remove_gravity_from_acc(acc_data_seq, rot_data_seq)\n        \n        df_seq['linear_acc_x'] = linear_accel_seq_arr[:, 0]\n        df_seq['linear_acc_y'] = linear_accel_seq_arr[:, 1]\n        df_seq['linear_acc_z'] = linear_accel_seq_arr[:, 2]\n    \n    df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n    df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n    \n    # Calculate angular velocity from quaternions in predict function\n    if all(col in df_seq.columns for col in rot_cols_for_gravity_removal):\n        angular_vel_seq_arr = calculate_angular_velocity_from_quat(df_seq[rot_cols_for_gravity_removal])\n        df_seq['angular_vel_x'] = angular_vel_seq_arr[:, 0]\n        df_seq['angular_vel_y'] = angular_vel_seq_arr[:, 1]\n        df_seq['angular_vel_z'] = angular_vel_seq_arr[:, 2]\n    else:\n        print(f\"Warning: Missing quaternion columns for angular velocity calculation in predict. Filling with 0.\")\n        df_seq['angular_vel_x'] = 0\n        df_seq['angular_vel_y'] = 0\n        df_seq['angular_vel_z'] = 0\n\n    # Calculate angular distance from quaternions in predict function\n    if all(col in df_seq.columns for col in rot_cols_for_gravity_removal):\n        angular_dist_seq_arr = calculate_angular_distance(df_seq[rot_cols_for_gravity_removal])\n        df_seq['angular_distance'] = angular_dist_seq_arr\n    else:\n        print(f\"Warning: Missing quaternion columns for angular distance calculation in predict. Filling with 0.\")\n        df_seq['angular_distance'] = 0\n\n\n    for i in range(1, 6): \n        pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n        if not all(col in df_seq.columns for col in pixel_cols_tof):\n            print(f\"Warning: Missing some TOF pixel columns for tof_{i} in predict. Filling aggregates with 0.\")\n            df_seq[f'tof_{i}_mean'] = 0\n            df_seq[f'tof_{i}_std']  = 0\n            df_seq[f'tof_{i}_min']  = 0\n            df_seq[f'tof_{i}_max']  = 0\n            continue\n\n        tof_sensor_data = df_seq[pixel_cols_tof].replace(-1, np.nan)\n        df_seq[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n        df_seq[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n        df_seq[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n        df_seq[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n        \n    if 'tof_range_across_sensors' in final_feature_cols:\n        tof_mean_cols_for_contrast = [f'tof_{i}_mean' for i in range(1, 6) if f'tof_{i}_mean' in df_seq.columns]\n        thm_cols_for_contrast = [f'thm_{i}' for i in range(1, 6) if f'thm_{i}' in df_seq.columns]\n\n        if tof_mean_cols_for_contrast:\n            tof_values_for_contrast = df_seq[tof_mean_cols_for_contrast]\n            df_seq['tof_range_across_sensors'] = tof_values_for_contrast.max(axis=1) - tof_values_for_contrast.min(axis=1)\n            df_seq['tof_std_across_sensors'] = tof_values_for_contrast.std(axis=1)\n        else:\n            df_seq['tof_range_across_sensors'] = 0\n            df_seq['tof_std_across_sensors'] = 0\n\n        if thm_cols_for_contrast:\n            thm_values_for_contrast = df_seq[thm_cols_for_contrast]\n            df_seq['thm_range_across_sensors'] = thm_values_for_contrast.max(axis=1) - thm_values_for_contrast.min(axis=1)\n            df_seq['thm_std_across_sensors'] = thm_values_for_contrast.std(axis=1)\n        else:\n            df_seq['thm_range_across_sensors'] = 0\n            df_seq['thm_std_across_sensors'] = 0\n        \n    df_seq_final_features = pd.DataFrame(index=df_seq.index)\n    for col_name in final_feature_cols:\n        if col_name in df_seq.columns:\n            df_seq_final_features[col_name] = df_seq[col_name]\n        else:\n            print(f\"CRITICAL ERROR IN PREDICT: Feature '{col_name}' expected by model (from final_feature_cols) was NOT generated in df_seq. Filling with 0. THIS IS LIKELY A BUG.\")\n            df_seq_final_features[col_name] = 0 \n            \n    mat_unscaled = df_seq_final_features.ffill().bfill().fillna(0).values.astype('float32')\n    \n    mat_scaled = scaler.transform(mat_unscaled)\n    \n    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n    \n    idx = int(model.predict(pad_input, verbose=0).argmax(1)[0])\n    return str(gesture_classes[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:58:50.574524Z","iopub.execute_input":"2025-06-24T14:58:50.574832Z","iopub.status.idle":"2025-06-24T14:58:50.589665Z","shell.execute_reply.started":"2025-06-24T14:58:50.574814Z","shell.execute_reply":"2025-06-24T14:58:50.589049Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### 》》》**Submit Inference server**","metadata":{}},{"cell_type":"code","source":"import kaggle_evaluation.cmi_inference_server\ninference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        data_paths=(\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T14:58:50.590754Z","iopub.execute_input":"2025-06-24T14:58:50.591029Z","iopub.status.idle":"2025-06-24T14:58:52.403134Z","shell.execute_reply.started":"2025-06-24T14:58:50.591007Z","shell.execute_reply":"2025-06-24T14:58:52.402388Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}